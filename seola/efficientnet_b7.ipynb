{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d734db-7e90-4397-bd9f-b33e40d3106d",
   "metadata": {},
   "source": [
    "## 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9113a78-174d-4809-b91c-48e831349cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torchvision==0.11.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10820d91-a4c9-4ffa-9585-7a6b5ec7dbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils\n",
    "import random\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95461161-42b3-48a9-8f65-ce5eb2e31cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/opt/ml/input/data/train'\n",
    "train_image_dir_path = os.path.join(train_path, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32acba16-9b1e-4374-a59e-f705d8f9fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    동일한 조건으로 학습을 할 때, 동일한 결과를 얻기 위해 seed를 고정시킵니다.\n",
    "    \n",
    "    Args:\n",
    "        seed: seed 정수값\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed) # pytorch의 random seed 고정\n",
    "    torch.cuda.manual_seed(seed) # GPU 에서 사용하는 난수 생성 시드 고정\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True # CuDNN 부분고정\n",
    "    torch.backends.cudnn.benchmark = False # CuDNN 부분고정\n",
    "    np.random.seed(seed) # Numpy 부분\n",
    "    random.seed(seed) # transforms에서 random 라이브러리를 사용하기 때문에 random 라이브러리를 불러서 고정\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f5aa8-1fb0-4240-abfa-5441582a11e2",
   "metadata": {},
   "source": [
    "## dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d915fe8-2105-4a7e-85d1-6f5ddd4e3990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(dirname, result):  # 하위목록의 모든 파일을 찾는 함수\n",
    "    try:\n",
    "        filenames = os.listdir(dirname)\n",
    "        for filename in filenames:\n",
    "            if filename[0] == '.':  # .으로 시작하는 파일명 거름\n",
    "                continue\n",
    "            full_filename = os.path.join(dirname, filename)\n",
    "            if os.path.isdir(full_filename):\n",
    "                search(full_filename, result)\n",
    "            else:\n",
    "                ext = os.path.splitext(full_filename)[-1]  # 확장자 체크\n",
    "                if ext:\n",
    "                    result.append(full_filename)\n",
    "    except PermissionError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba45af04-0e7b-4ec9-b28a-800d813a2d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_path = []\n",
    "search(train_image_dir_path, all_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ff20be-a042-40b4-82f4-de999625e1f0",
   "metadata": {},
   "source": [
    "train 데이터의 디렉토리는 2700개로 각각의 7개의 이미지 파일을 곱한 갯수가 나옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3cd2365-0896-4622-aea8-bb377f904df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18900"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_path) # 2700*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b25397fa-a6e1-44a8-874d-43bbcdaa0083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/opt/ml/input/data/train/images/003554_female_Asian_59/mask3.jpg',\n",
       " '/opt/ml/input/data/train/images/003554_female_Asian_59/mask5.jpg',\n",
       " '/opt/ml/input/data/train/images/003554_female_Asian_59/incorrect_mask.jpg',\n",
       " '/opt/ml/input/data/train/images/003554_female_Asian_59/mask4.jpg',\n",
       " '/opt/ml/input/data/train/images/003554_female_Asian_59/mask1.jpg',\n",
       " '/opt/ml/input/data/train/images/003554_female_Asian_59/normal.jpg',\n",
       " '/opt/ml/input/data/train/images/003554_female_Asian_59/mask2.jpg',\n",
       " '/opt/ml/input/data/train/images/003845_female_Asian_56/mask3.jpg',\n",
       " '/opt/ml/input/data/train/images/003845_female_Asian_56/mask5.jpg',\n",
       " '/opt/ml/input/data/train/images/003845_female_Asian_56/incorrect_mask.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_path[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f4dfd6-fb61-4d95-829c-ae1291c05317",
   "metadata": {},
   "source": [
    "파일 확장자는 jpg, png, jpeg로 3종류가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f3f9cc7-ee91-4ce4-a040-af9045d0be9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.jpg', '.png', '.jpeg']\n"
     ]
    }
   ],
   "source": [
    "exts = []\n",
    "for i in all_path:\n",
    "    ext = os.path.splitext(i)[-1]\n",
    "    if ext not in exts:\n",
    "        exts.append(ext)\n",
    "print(exts)  # jpg, png, jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4268e22c-147f-4980-87cc-c7774d3ae7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/opt/ml/input/data/train/images/000001_female_Asian_45/incorrect_mask.jpg',\n",
       " '/opt/ml/input/data/train/images/000001_female_Asian_45/mask1.jpg',\n",
       " '/opt/ml/input/data/train/images/000001_female_Asian_45/mask2.jpg',\n",
       " '/opt/ml/input/data/train/images/000001_female_Asian_45/mask3.jpg',\n",
       " '/opt/ml/input/data/train/images/000001_female_Asian_45/mask4.jpg',\n",
       " '/opt/ml/input/data/train/images/000001_female_Asian_45/mask5.jpg',\n",
       " '/opt/ml/input/data/train/images/000001_female_Asian_45/normal.jpg',\n",
       " '/opt/ml/input/data/train/images/000002_female_Asian_52/incorrect_mask.jpg',\n",
       " '/opt/ml/input/data/train/images/000002_female_Asian_52/mask1.jpg',\n",
       " '/opt/ml/input/data/train/images/000002_female_Asian_52/mask2.jpg']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_path = sorted(all_path)\n",
    "all_path[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bddc3eb-3b79-4b75-bda9-6a3ae9aeda26",
   "metadata": {},
   "source": [
    "라벨링 하는 함수입니다. 조건에 따라 숫자로 라벨을 부여합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f42dfe47-e41c-4063-a516-97c18a186caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(name):\n",
    "    label = 0\n",
    "    info, mask_type = name.split('/')[-2:]\n",
    "    info = info.split('_')\n",
    "    gender, age = info[1], int(info[3])\n",
    "    if 'incorrect' in mask_type:\n",
    "        label += 6\n",
    "    elif 'normal' in mask_type:\n",
    "        label += 12\n",
    "    \n",
    "    if gender == 'female':\n",
    "        label += 3\n",
    "    \n",
    "    if 30 <= age < 60:\n",
    "        label += 1\n",
    "    elif age >= 60:\n",
    "        label += 2\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc92178-c02a-4df2-bf1b-26e79546a2d8",
   "metadata": {},
   "source": [
    "path, label을 컬럼으로 갖는 dataframe을 생성해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2a1dcdc-09ba-4f94-91c3-af227d686ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18895</th>\n",
       "      <td>/opt/ml/input/data/train/images/006959_male_As...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18896</th>\n",
       "      <td>/opt/ml/input/data/train/images/006959_male_As...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18897</th>\n",
       "      <td>/opt/ml/input/data/train/images/006959_male_As...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18898</th>\n",
       "      <td>/opt/ml/input/data/train/images/006959_male_As...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18899</th>\n",
       "      <td>/opt/ml/input/data/train/images/006959_male_As...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18900 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path  label\n",
       "0      /opt/ml/input/data/train/images/000001_female_...     10\n",
       "1      /opt/ml/input/data/train/images/000001_female_...      4\n",
       "2      /opt/ml/input/data/train/images/000001_female_...      4\n",
       "3      /opt/ml/input/data/train/images/000001_female_...      4\n",
       "4      /opt/ml/input/data/train/images/000001_female_...      4\n",
       "...                                                  ...    ...\n",
       "18895  /opt/ml/input/data/train/images/006959_male_As...      0\n",
       "18896  /opt/ml/input/data/train/images/006959_male_As...      0\n",
       "18897  /opt/ml/input/data/train/images/006959_male_As...      0\n",
       "18898  /opt/ml/input/data/train/images/006959_male_As...      0\n",
       "18899  /opt/ml/input/data/train/images/006959_male_As...     12\n",
       "\n",
       "[18900 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(all_path, columns = ['path'])\n",
    "\n",
    "train_df['label'] = train_df['path'].map(lambda x : labeling(x))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9ab386d-add5-4ed5-890d-6854a9e4223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv('./train_path_label.csv', index=False, encoding='utf-8')\n",
    "# train_df = pd.read_csv('./train_path_label.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcb76ba-db73-479e-a171-37551b0bcec1",
   "metadata": {},
   "source": [
    "dataset을 상속받아 만든 CustomDataset입니다.\n",
    "transform은 size를 [512, 284]로 변형하고, Tensor로 만들고, 정규화해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37df9b06-71ab-4436-8b38-8b524e385dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_paths_label, transform):\n",
    "        self.X = img_paths_label['path']\n",
    "        self.y = img_paths_label['label']\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.X.iloc[index])\n",
    "        label = self.y.iloc[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31a015f5-d4cd-4bdc-a021-a822158e6092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4578c0-a099-4618-8940-dac3c6a9cdb5",
   "metadata": {},
   "source": [
    "train, valid 나누는 파트입니다.\n",
    "label의 비율을 유지하면서 나눴습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8931fe1c-6cd2-4f43-98de-70af4ba3f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, valid = train_test_split(train_df, test_size=0.2,\n",
    "                               shuffle=True, stratify=train_df['label'],\n",
    "                               random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68e04143-ad8c-4b53-a2be-9fae4cd62aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15120, 2), (3780, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcf47765-b094-4d2a-b504-59b378103e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "num_workers=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5f8dcf8-0aa2-455f-a829-6eecfce0a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train, transform)\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                             batch_size = BATCH_SIZE,\n",
    "                             num_workers=num_workers,\n",
    "                             drop_last=True,\n",
    "                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67ffc07d-ba0d-4127-bdb7-ca4ed733892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = CustomDataset(valid, transform)\n",
    "valid_dataloader = DataLoader(valid_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             num_workers=num_workers,\n",
    "                             drop_last=True,\n",
    "                             shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e53b238-de65-4d1a-a016-c79218b508cb",
   "metadata": {},
   "source": [
    "dataloader는 [batchsize, channel, height, wide]를 출력해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26fb722f-f398-4bd5-9733-5992d783a539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 512, 384])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c31a7a6-0188-4d02-b8e9-4f1845b60f19",
   "metadata": {},
   "source": [
    "## 모델\n",
    "\n",
    "이 모델의 마지막 fc층만 저희 과제인 18개의 class로 변경해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "970ee4a0-8f39-411c-abd6-79e7cc629557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c4d0075-2e3c-4cb1-89ef-c3341774102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade jupyter_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0100995b-a3e3-4f4e-b97b-e51f58fcde9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "# resnet18 = models.resnet18(pretrained=True)\n",
    "# model = models.vgg16(pretrained=True)\n",
    "# densenet = models.densenet161(pretrained=True)\n",
    "# model = models.inception_v3(pretrained=True)\n",
    "# model = models.googlenet(pretrained=True)\n",
    "# model = models.mobilenet_v2(pretrained=True)\n",
    "# model = models.mobilenet_v3_large(pretrained=True)\n",
    "# model = models.resnext50_32x4d(pretrained=True)\n",
    "# wide_resnet50_2 = models.wide_resnet50_2(pretrained=True)\n",
    "# model = models.mnasnet1_0(pretrained=True)\n",
    "# model = models.efficientnet_b0(pretrained=True)\n",
    "# efficientnet_b1 = models.efficientnet_b1(pretrained=True)\n",
    "# efficientnet_b2 = models.efficientnet_b2(pretrained=True)\n",
    "# efficientnet_b3 = models.efficientnet_b3(pretrained=True)\n",
    "# model = models.efficientnet_b4(pretrained=True)\n",
    "# efficientnet_b5 = models.efficientnet_b5(pretrained=True)\n",
    "# efficientnet_b6 = models.efficientnet_b6(pretrained=True)\n",
    "model = models.efficientnet_b7(pretrained=True)\n",
    "# regnet_y_400mf = models.regnet_y_400mf(pretrained=True)\n",
    "# regnet_y_800mf = models.regnet_y_800mf(pretrained=True)\n",
    "# regnet_y_1_6gf = models.regnet_y_1_6gf(pretrained=True)\n",
    "# regnet_y_3_2gf = models.regnet_y_3_2gf(pretrained=True)\n",
    "# regnet_y_8gf = models.regnet_y_8gf(pretrained=True)\n",
    "# regnet_y_16gf = models.regnet_y_16gf(pretrained=True)\n",
    "# regnet_y_32gf = models.regnet_y_32gf(pretrained=True)\n",
    "# regnet_x_400mf = models.regnet_x_400mf(pretrained=True)\n",
    "# regnet_x_800mf = models.regnet_x_800mf(pretrained=True)\n",
    "# regnet_x_1_6gf = models.regnet_x_1_6gf(pretrained=True)\n",
    "# regnet_x_3_2gf = models.regnet_x_3_2gf(pretrained=True)\n",
    "# regnet_x_8gf = models.regnet_x_8gf(pretrained=True)\n",
    "# regnet_x_16gf = models.regnet_x_16gf(pretrained=True)\n",
    "# regnet_x_32gf = models.regnet_x_32gf(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41f9d726-dca9-41ff-9ec7-cfde9ace3b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list = list(model.children())\n",
    "layer_num = len(layer_list)\n",
    "in_features = layer_list[-1][-1].in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c26afff-1185-4a95-88e5-965b08ecb2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2560"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e923e0f7-e925-4aa6-af65-ffb4da6b2eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): ConvNormActivation(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0036363636363636364, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.007272727272727273, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.01090909090909091, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.014545454545454545, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.01818181818181818, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.02181818181818182, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025454545454545455, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.02909090909090909, mode=row)\n",
       "      )\n",
       "      (5): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.03272727272727273, mode=row)\n",
       "      )\n",
       "      (6): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.03636363636363636, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(288, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.04, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.04363636363636364, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.04727272727272727, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05090909090909091, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05454545454545454, mode=row)\n",
       "      )\n",
       "      (5): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05818181818181818, mode=row)\n",
       "      )\n",
       "      (6): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06181818181818183, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06545454545454546, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06909090909090909, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07272727272727272, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07636363636363637, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08, mode=row)\n",
       "      )\n",
       "      (5): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08363636363636365, mode=row)\n",
       "      )\n",
       "      (6): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08727272727272728, mode=row)\n",
       "      )\n",
       "      (7): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09090909090909091, mode=row)\n",
       "      )\n",
       "      (8): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09454545454545454, mode=row)\n",
       "      )\n",
       "      (9): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09818181818181819, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(960, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.10181818181818182, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.10545454545454547, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.10909090909090909, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11272727272727273, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11636363636363636, mode=row)\n",
       "      )\n",
       "      (5): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.12000000000000001, mode=row)\n",
       "      )\n",
       "      (6): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.12363636363636366, mode=row)\n",
       "      )\n",
       "      (7): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.12727272727272726, mode=row)\n",
       "      )\n",
       "      (8): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.13090909090909092, mode=row)\n",
       "      )\n",
       "      (9): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.13454545454545455, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=1344, bias=False)\n",
       "            (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.13818181818181818, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14181818181818184, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14545454545454545, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1490909090909091, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15272727272727274, mode=row)\n",
       "      )\n",
       "      (5): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15636363636363634, mode=row)\n",
       "      )\n",
       "      (6): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.16, mode=row)\n",
       "      )\n",
       "      (7): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.16363636363636364, mode=row)\n",
       "      )\n",
       "      (8): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1672727272727273, mode=row)\n",
       "      )\n",
       "      (9): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17090909090909093, mode=row)\n",
       "      )\n",
       "      (10): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17454545454545456, mode=row)\n",
       "      )\n",
       "      (11): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1781818181818182, mode=row)\n",
       "      )\n",
       "      (12): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.18181818181818182, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(640, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.18545454545454548, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(3840, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n",
       "            (1): BatchNorm2d(3840, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(3840, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(160, 3840, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(640, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1890909090909091, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(3840, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n",
       "            (1): BatchNorm2d(3840, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(3840, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(160, 3840, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(640, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.19272727272727275, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(3840, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n",
       "            (1): BatchNorm2d(3840, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(3840, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(160, 3840, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(640, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.19636363636363638, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): ConvNormActivation(\n",
       "      (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(2560, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=True)\n",
       "    (1): Linear(in_features=2560, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d6fb1d4-b217-4638-8cee-24c3e951ba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = 0\n",
    "for child in model.children():\n",
    "    ct += 1\n",
    "    if ct < layer_num:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a21f3d41-4801-454b-8389-1c663b9a55ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "OUTPUT_CLASS_NUM = 18\n",
    "model.classifier[1] = torch.nn.Linear(in_features = in_features, out_features = OUTPUT_CLASS_NUM, bias=True)  # output 18개로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "974f7005-de9a-4478-ad4e-db79a9f429d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86ac2ec-b416-4131-aca1-5eef26bdbccf",
   "metadata": {},
   "source": [
    "아래의 대부분의 코드가 부스트캠프에서 학습자료나 과제로 제공받았던 코드를 거의 그대로 사용했습니다. 설명도 주석으로 잘 달려 있어서 그대로 가져왔습니다.\n",
    "<br/><br/>\n",
    "epoch는 5, lr은 0.0001로 주었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d19a3571-807e-47db-a44c-9ea2a265ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "LEARNING_RATE = 0.0001  # 학습 때 사용하는 optimizer의 학습률 옵션 설정\n",
    "NUM_EPOCH = 20  # 학습 때 mnist train 데이터셋을 얼마나 많이 학습할 지 결정하는 옵션\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()  # 분류 학습 때 많이 사용되는 Cross entropy loss를 objective function으로 사용\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  # weight업데이트를 위한 optimizer를 Adam으로 사용\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\" : train_dataloader,\n",
    "    \"test\" : valid_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb3ab20c-dfb5-4aac-b6b6-c05d7e816c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67b6819acbc427ab41315004fffb114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-0의 train-데이터셋에서 평균 Loss : 2.518, 평균 Accuracy : 0.374\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41deb52d3884913b1c9589924943770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-0의 test-데이터셋에서 평균 Loss : 2.381, 평균 Accuracy : 0.470\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30134818bd684d6e82b56c59f28eab60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-1의 train-데이터셋에서 평균 Loss : 2.047, 평균 Accuracy : 0.609\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e337009bbb794a0991ed950c753ebe03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-1의 test-데이터셋에서 평균 Loss : 1.688, 평균 Accuracy : 0.661\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0a4b72f46648e895b7064b4581e82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-2의 train-데이터셋에서 평균 Loss : 1.732, 평균 Accuracy : 0.669\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468d02183b594fe491944a1dca861039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-2의 test-데이터셋에서 평균 Loss : 1.430, 평균 Accuracy : 0.708\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b7df5a4e9c4a6782d273cd5cf34fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-3의 train-데이터셋에서 평균 Loss : 1.510, 평균 Accuracy : 0.698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913bf9902385496e838c65a977c338e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-3의 test-데이터셋에서 평균 Loss : 1.276, 평균 Accuracy : 0.732\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc665d5464a4eeaa0d1d88209e77531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-4의 train-데이터셋에서 평균 Loss : 1.348, 평균 Accuracy : 0.724\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8846003f56aa4d74a9c7e1587ade9c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-4의 test-데이터셋에서 평균 Loss : 1.151, 평균 Accuracy : 0.746\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4de64f4a4e49a49d3d6e8e4e2571fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-5의 train-데이터셋에서 평균 Loss : 1.226, 평균 Accuracy : 0.738\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21fb26da17a42e8992288cd3eca5138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-5의 test-데이터셋에서 평균 Loss : 1.054, 평균 Accuracy : 0.759\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977776f4efed4375afa07d2ba71da21d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-6의 train-데이터셋에서 평균 Loss : 1.127, 평균 Accuracy : 0.752\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5a76c774b746a6b57a518451047594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-6의 test-데이터셋에서 평균 Loss : 0.977, 평균 Accuracy : 0.768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbca8f734c644c218a777923885cd389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-7의 train-데이터셋에서 평균 Loss : 1.049, 평균 Accuracy : 0.765\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f53729628494640857f9698281f56e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-7의 test-데이터셋에서 평균 Loss : 0.914, 평균 Accuracy : 0.779\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d933b055a4dc47dfa2a71778c61bb534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-8의 train-데이터셋에서 평균 Loss : 0.989, 평균 Accuracy : 0.773\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02cfd064c574bcdb9a4c304c747cb57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-8의 test-데이터셋에서 평균 Loss : 0.862, 평균 Accuracy : 0.785\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca6a2370bbe4834a198e66194c10a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-9의 train-데이터셋에서 평균 Loss : 0.936, 평균 Accuracy : 0.782\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c735c5518c224c5080ef0d160d7f2ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-9의 test-데이터셋에서 평균 Loss : 0.820, 평균 Accuracy : 0.790\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ddca10854d47c8bb74f7398b1f91eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-10의 train-데이터셋에서 평균 Loss : 0.890, 평균 Accuracy : 0.790\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3957ea628da4f5bac882a0b35b75256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-10의 test-데이터셋에서 평균 Loss : 0.781, 평균 Accuracy : 0.793\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5b1fc8432c46e8961b479473c7cf31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-11의 train-데이터셋에서 평균 Loss : 0.851, 평균 Accuracy : 0.798\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8452aec3d62342f490fc557537483786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-11의 test-데이터셋에서 평균 Loss : 0.752, 평균 Accuracy : 0.796\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a2c2ec37194e03a492e65c1e66b7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-12의 train-데이터셋에서 평균 Loss : 0.813, 평균 Accuracy : 0.802\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ccd4bcd0ab409399a9b9abf6627467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-12의 test-데이터셋에서 평균 Loss : 0.720, 평균 Accuracy : 0.802\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e653fa44f24d6e95b110c26eefa113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-13의 train-데이터셋에서 평균 Loss : 0.785, 평균 Accuracy : 0.804\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84003433b2e4b68b1c4958046382832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-13의 test-데이터셋에서 평균 Loss : 0.699, 평균 Accuracy : 0.806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e233a373c60470d85fd9848d2a1c0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-14의 train-데이터셋에서 평균 Loss : 0.761, 평균 Accuracy : 0.807\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80f14d3786e4e8db3877adeeedcc289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-14의 test-데이터셋에서 평균 Loss : 0.680, 평균 Accuracy : 0.808\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58d6601d8804ad6b804be0595e93c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-15의 train-데이터셋에서 평균 Loss : 0.739, 평균 Accuracy : 0.815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75f7d80f26f42c49af9ebc044020d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-15의 test-데이터셋에서 평균 Loss : 0.659, 평균 Accuracy : 0.809\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddac0310b2146a8ad75cf6eddd4b7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-16의 train-데이터셋에서 평균 Loss : 0.718, 평균 Accuracy : 0.815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd55a5cd52214c7681e8acd8bad1847e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-16의 test-데이터셋에서 평균 Loss : 0.643, 평균 Accuracy : 0.811\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9189666f6fc47e289f02e2763e1fa45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-17의 train-데이터셋에서 평균 Loss : 0.699, 평균 Accuracy : 0.815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b278e85f4e0a4f2782cf1962e68e8f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-17의 test-데이터셋에서 평균 Loss : 0.630, 평균 Accuracy : 0.812\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5432d48bbcd74825b4c36f619b1afdf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-18의 train-데이터셋에서 평균 Loss : 0.677, 평균 Accuracy : 0.820\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa489a7309a64a08ba7d18a76d9678e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-18의 test-데이터셋에서 평균 Loss : 0.614, 평균 Accuracy : 0.815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14b11a95d224b999383213c22b506f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-19의 train-데이터셋에서 평균 Loss : 0.661, 평균 Accuracy : 0.824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fa385193bb4ba594f6cc93dbbab7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "현재 epoch-19의 test-데이터셋에서 평균 Loss : 0.602, 평균 Accuracy : 0.817\n",
      "학습 종료!\n",
      "best acc : 0.8166666626930237, 최고 낮은 loss : 0.6015917742693866\n"
     ]
    }
   ],
   "source": [
    "best_test_accuracy = 0.\n",
    "best_test_loss = 9999.\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    for phase in [\"train\", \"test\"]:\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        if phase == \"train\":\n",
    "            model.train()  # 네트워크 모델을 train 모드로 두어 gradient를 계산하고, 여러 sub module(배치 정규화, 드롭아웃 등)이 train mode로 작동할 수 있도록 함\n",
    "        elif phase == \"test\":\n",
    "            model.eval()  # 네트워크 모델을 eval 모드로 두어 여러 sub module들이 eval mode로 작동할 수 있게 함\n",
    "        \n",
    "        for ind, (images, labels) in enumerate(tqdm(dataloaders[phase])):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()  # parameter gradient 업데이터 전 초기화함\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == \"train\"):  # train 모드 땐 gradient계산, 아닐 땐 gradient계산 안함으로써 연산량 줄임\n",
    "                logits = model(images)\n",
    "                _, preds = torch.max(logits, 1)  # 모델에서 linear하게 나오는 예측값 리스트에서 최대 output index를 찾아 예측 레이블로 변경함\n",
    "                loss = loss_fn(logits, labels)\n",
    "                \n",
    "                if phase == \"train\":\n",
    "                    loss.backward()  # 모델의 예측 값과 실제 값의 CrossEntropy 차이를 통해 gradient 계산\n",
    "                    optimizer.step()  # 계산된 gradient를 가지고 모델 업데이트\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0) # 한 batch에서의 loss 값 저장\n",
    "            running_acc += torch.sum(preds == labels.data) # 한 batch에서의 acc 값 저장\n",
    "            \n",
    "        # 한 epoch이 모두 종료되었을 때\n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = running_acc / len(dataloaders[phase].dataset)\n",
    "        \n",
    "        print(f\"현재 epoch-{epoch}의 {phase}-데이터셋에서 평균 Loss : {epoch_loss:.3f}, 평균 Accuracy : {epoch_acc:.3f}\")\n",
    "        if phase == \"test\" and best_test_accuracy < epoch_acc: # phase가 test일 때, best acc 계산\n",
    "            best_test_accuracy = epoch_acc\n",
    "        if phase == \"test\" and best_test_loss > epoch_loss: # phase가 test일 때 best loss 계산\n",
    "            best_test_loss = epoch_loss\n",
    "\n",
    "print(\"학습 종료!\")\n",
    "print(f\"best acc : {best_test_accuracy}, 최고 낮은 loss : {best_test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94099125-380d-429b-8249-d87351442ce8",
   "metadata": {},
   "source": [
    "loss가 계속 떨어지고 있기 때문에 epoch를 늘려서 학습해도 좋을 것 같습니다.\n",
    "<br/><br/>\n",
    "valid data 기준 99프로의 정확도를 보여주지만, 실제 test 데이터는 train이나 valid와 많이 다를 것으로 예상됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3eda34c6-1f55-4940-8515-e144b2700fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_eval(model, data_iter, device):\n",
    "    with torch.no_grad():\n",
    "        n_total, n_correct = 0, 0\n",
    "        model.eval()\n",
    "        for batch_in, batch_out in data_iter:\n",
    "            y_trgt = batch_out.to(device)\n",
    "            model_pred = model.forward(batch_in.to(device))\n",
    "            _, y_pred = torch.max(model_pred, 1)  # 행으로 비교\n",
    "            n_correct += (y_pred == y_trgt).sum().item()\n",
    "            n_total += batch_in.size(0)\n",
    "        val_acc = (n_correct/n_total)\n",
    "        #model_train()\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "edc0fa36-4986-4958-8e97-12e7ab4b88a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8302801724137931"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_eval(model, valid_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7d5efe-79e9-43f4-bcc9-c5e2928da4bc",
   "metadata": {},
   "source": [
    "실제 정답과 pred를 비교하고자 path, pred, target을 dataframe으로 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea56c8c1-548d-4bc4-9cd5-c2e350a454dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_eval(raw_data, dataloader, model, device):\n",
    "    result = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (X,y) in enumerate(dataloader):\n",
    "            model_pred = model.forward(X.to(device))\n",
    "            _, y_pred = torch.max(model_pred, 1)\n",
    "            \n",
    "            result.append([valid.iloc[i]['path'], y_pred.cpu().numpy()[0], y.cpu().numpy()[0]])\n",
    "    result = pd.DataFrame(result, columns=['path', 'pred', 'target'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7ea5d28-740d-45fc-b6cd-5416eec093fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>pred</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/opt/ml/input/data/train/images/001151_male_As...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/opt/ml/input/data/train/images/001836_female_...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/opt/ml/input/data/train/images/004079_male_As...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/opt/ml/input/data/train/images/003763_female_...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/opt/ml/input/data/train/images/006502_male_As...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3775</th>\n",
       "      <td>/opt/ml/input/data/train/images/001718_male_As...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3776</th>\n",
       "      <td>/opt/ml/input/data/train/images/003889_female_...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3777</th>\n",
       "      <td>/opt/ml/input/data/train/images/003943_male_As...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>/opt/ml/input/data/train/images/001495-1_male_...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>/opt/ml/input/data/train/images/005509_female_...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3780 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  pred  target\n",
       "0     /opt/ml/input/data/train/images/001151_male_As...     4       0\n",
       "1     /opt/ml/input/data/train/images/001836_female_...     3       3\n",
       "2     /opt/ml/input/data/train/images/004079_male_As...     4       1\n",
       "3     /opt/ml/input/data/train/images/003763_female_...     4       4\n",
       "4     /opt/ml/input/data/train/images/006502_male_As...     0       0\n",
       "...                                                 ...   ...     ...\n",
       "3775  /opt/ml/input/data/train/images/001718_male_As...     0       1\n",
       "3776  /opt/ml/input/data/train/images/003889_female_...     3       4\n",
       "3777  /opt/ml/input/data/train/images/003943_male_As...     1       1\n",
       "3778  /opt/ml/input/data/train/images/001495-1_male_...     6       6\n",
       "3779  /opt/ml/input/data/train/images/005509_female_...    16      16\n",
       "\n",
       "[3780 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_testing_dataloader = DataLoader(valid_dataset, shuffle=False)\n",
    "\n",
    "check_eval_df = check_eval(valid, valid_testing_dataloader, model, device)\n",
    "check_eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887976e0-36a6-4588-9fe3-8cee9a1c5871",
   "metadata": {},
   "source": [
    "잘못 예측한 데이터만 모아봤습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cac02f7a-e2a5-4416-80a0-67dfb336f421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>pred</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/opt/ml/input/data/train/images/001151_male_As...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/opt/ml/input/data/train/images/004079_male_As...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/opt/ml/input/data/train/images/004230_female_...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/opt/ml/input/data/train/images/001090_male_As...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/opt/ml/input/data/train/images/006728_male_As...</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>/opt/ml/input/data/train/images/003738_female_...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>/opt/ml/input/data/train/images/001635_male_As...</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>/opt/ml/input/data/train/images/004477_female_...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>/opt/ml/input/data/train/images/001718_male_As...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>/opt/ml/input/data/train/images/003889_female_...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>636 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path  pred  target\n",
       "0    /opt/ml/input/data/train/images/001151_male_As...     4       0\n",
       "1    /opt/ml/input/data/train/images/004079_male_As...     4       1\n",
       "2    /opt/ml/input/data/train/images/004230_female_...    10      11\n",
       "3    /opt/ml/input/data/train/images/001090_male_As...     0       1\n",
       "4    /opt/ml/input/data/train/images/006728_male_As...    13      12\n",
       "..                                                 ...   ...     ...\n",
       "631  /opt/ml/input/data/train/images/003738_female_...    10       4\n",
       "632  /opt/ml/input/data/train/images/001635_male_As...    12      13\n",
       "633  /opt/ml/input/data/train/images/004477_female_...    10      11\n",
       "634  /opt/ml/input/data/train/images/001718_male_As...     0       1\n",
       "635  /opt/ml/input/data/train/images/003889_female_...     3       4\n",
       "\n",
       "[636 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_df = check_eval_df[check_eval_df['pred'] != check_eval_df['target']]\n",
    "wrong_df = wrong_df.reset_index(drop=True)\n",
    "wrong_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94888574-6240-49a8-918c-a92eb66b0a9f",
   "metadata": {},
   "source": [
    "틀린 데이터들을 살펴보기 위해 이미지와 같이 출력을 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2397b809-a8c2-4c96-8d18-1cc7eaaa3598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_(df):\n",
    "#     plt.figure(figsize=(17,32))\n",
    "#     row = 7\n",
    "#     for i in range(df.shape[0]):\n",
    "#         plt.subplot(row+1, df.shape[0]//row, i+1)\n",
    "#         plt.imshow(Image.open(df['path'][i]))\n",
    "#         plt.title(f\"target:{df['target'][i]}, pred:{df['pred'][i]}\", size=20)\n",
    "#         plt.axis(\"off\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e31fd40-ebd1-4934-a4bd-6dd516362472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_(wrong_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8911f1-728b-44ad-baa2-d40f9f3d10e3",
   "metadata": {},
   "source": [
    "* 대체로 조금씩 어리게 + incorrect를 wear으로 잘못 예측\n",
    "    * 특히 노년층의 데이터가 적어서 그런지 노년층을 중장년층으로 인식하는 경우가 다수\n",
    "    * 특히 마스크 안쓴 데이터에서 중장년층 여성을 청년 여성으로 분류하는 경우도 꽤 있음\n",
    "* 남성의 머리카락이 조금만 길어도 여성으로 예측 -> 장발 남성 데이터를 데이터 어그멘테이션 해볼까?\n",
    "* 11번째 데이터 잘못 레이블링됨(5227번째 데이터. 수정 완료.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a56e89-e4b6-4537-ae5a-4de3aaca4c34",
   "metadata": {},
   "source": [
    "## f1 score 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd798dcc-519b-4138-9899-0593ca20dd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6334649701141575"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "f1_score(check_eval_df['target'], check_eval_df['pred'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3c61e27-c96a-4bf8-9890-c943ad3156b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90       554\n",
      "           1       0.78      0.79      0.79       409\n",
      "           2       0.71      0.35      0.47        83\n",
      "           3       0.90      0.92      0.91       727\n",
      "           4       0.82      0.86      0.84       818\n",
      "           5       0.76      0.38      0.50       109\n",
      "           6       0.80      0.88      0.84       111\n",
      "           7       0.71      0.66      0.68        82\n",
      "           8       0.00      0.00      0.00        16\n",
      "           9       0.87      0.84      0.86       145\n",
      "          10       0.75      0.73      0.74       164\n",
      "          11       1.00      0.05      0.09        22\n",
      "          12       0.85      0.94      0.89       111\n",
      "          13       0.77      0.80      0.79        82\n",
      "          14       1.00      0.06      0.12        16\n",
      "          15       0.93      0.89      0.91       145\n",
      "          16       0.78      0.93      0.85       164\n",
      "          17       1.00      0.14      0.24        22\n",
      "\n",
      "    accuracy                           0.83      3780\n",
      "   macro avg       0.79      0.62      0.63      3780\n",
      "weighted avg       0.83      0.83      0.82      3780\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "def report():\n",
    "    y_test, y_pred = check_eval_df['target'], check_eval_df['pred']\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    ax = plt.figure(figsize=(10, 5))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), linewidths=0.5, fmt='.1f', annot=True)\n",
    "\n",
    "report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b643c29-3b71-4452-a29e-4db9a271ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fa0de15-a49c-4b6c-ac4f-73974ff1ea2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "test_dir = '/opt/ml/input/data/eval'\n",
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submit_dir = '/opt/ml/submit'\n",
    "submission.to_csv(os.path.join(submit_dir, 'efficientnet_b7-epoch20.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87bcf204-65c0-414c-9371-4b2aaa8df1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch 10\n",
    "# f1score:0.6000 / acc:82.0000\n",
    "# f1score:0.5178 / acc:66.6667\n",
    "\n",
    "# epoch 20\n",
    "# f1score:0.6300 / acc:83.0000\n",
    "# 제출 안함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b57b99-7722-4bb6-bd49-80998cc4d9a7",
   "metadata": {},
   "source": [
    "* 가장 실제 제출 결과와 비슷!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
