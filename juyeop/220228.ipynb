{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96301699-f130-4102-83df-214ef7dea926",
   "metadata": {},
   "source": [
    "pretrained model : resnet18\n",
    "\n",
    "loss_fn : CrossEntropyLoss\n",
    "\n",
    "optimizer : adam\n",
    "\n",
    "epoch: 3\n",
    "\n",
    "batch-size : 64 -> 32\n",
    "\n",
    "data augmentation : transforms.RandomHorizontalFlip(),\n",
    "\n",
    "fc layer : relu\n",
    "\n",
    "lr : 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f7f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler\n",
    "\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e82372af-e478-4dae-a283-f792958f76f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = 'input/data/train'\n",
    "train_image_dir_path = os.path.join(train_path, 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e84dc1-18eb-4592-bd15-330007a90b01",
   "metadata": {},
   "source": [
    "Dataset 생성\n",
    "\n",
    "모든 train data의 path를 가져와 라벨링 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "040577b9-a2c5-4516-a5fd-b1f3ae11d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(dirname, result): # 하위 목록의 모든 파일을 찾는 함수\n",
    "    try:\n",
    "        filenames = os.listdir(dirname)\n",
    "        for filename in filenames:\n",
    "            if filename[0] == '.': # .으로 시작하는 애들 거름\n",
    "                continue\n",
    "            full_filename = os.path.join(dirname, filename)\n",
    "            if os.path.isdir(full_filename):\n",
    "                search(full_filename, result)\n",
    "            else:\n",
    "                ext = os.path.splitext(full_filename)[-1] # 확장자 체크\n",
    "                if ext:\n",
    "                    result.append(full_filename)\n",
    "        \n",
    "    except PermissionError:\n",
    "        print('Permission Error')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e40f2b1-7abe-49e1-abda-701cb6025934",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_path = list()\n",
    "search(train_image_dir_path, all_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3455a861-4429-4243-898c-b3f2e4186942",
   "metadata": {},
   "source": [
    "train의 데이터 디렉토리는 2700개로, 각각의 이미지 파일(incorrect, mask1~5, normal)을 곱한 갯수가 나옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba63e19e-6978-4785-921e-44a58757f838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18900"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_path) # 2700 * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff701504-72d2-44d0-8e2e-82ac0964e1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input/data/train/images/001752_male_Asian_53/mask5.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/mask4.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/mask2.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/mask3.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/normal.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/mask1.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/incorrect_mask.jpg',\n",
       " 'input/data/train/images/005127_female_Asian_51/mask5.jpg',\n",
       " 'input/data/train/images/005127_female_Asian_51/mask4.jpg',\n",
       " 'input/data/train/images/005127_female_Asian_51/mask2.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_path[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8726c41-ba96-408b-9e65-10bcab850853",
   "metadata": {},
   "source": [
    "파일의 확장자는 jpg, png, jpeg로 3종류가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b45de68-c50e-435b-853b-5e95fba44852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.jpg', '.png', '.jpeg']\n"
     ]
    }
   ],
   "source": [
    "exts = list()\n",
    "for word in all_path:\n",
    "    ext = os.path.splitext(word)[-1]\n",
    "    if ext not in exts:\n",
    "        exts.append(ext)\n",
    "print(exts) # jpg, png, jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f205b726-45fc-4d95-b3d0-fef15a7ecf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_path = sorted(all_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e47982-6d3f-4677-abfe-e9997e699876",
   "metadata": {},
   "source": [
    "라벨링을 하는 함수입니다. 조건에 따라 label에 숫자를 더해주는 식으로 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "370658c3-e841-4e0d-809b-c53d00cd9337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(name):\n",
    "    label = 0\n",
    "    info, mask_type = name.split('/')[-2:]\n",
    "    info = info.split('_')\n",
    "    gender, age = info[1], int(info[3])\n",
    "    \n",
    "    # 마스크 구별\n",
    "    if 'incorrect' in mask_type:\n",
    "        label += 6\n",
    "    elif 'normal' in mask_type:\n",
    "        label += 12\n",
    "    \n",
    "    # gender 구별\n",
    "    if gender == 'female':\n",
    "        label += 3\n",
    "    \n",
    "    # 나이 구별\n",
    "    if 30 <= age and age < 60:\n",
    "        label += 1\n",
    "    elif age >= 60:\n",
    "        label += 1\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c06615-2768-4cfd-9026-6105537d0dcb",
   "metadata": {},
   "source": [
    "path, label을 컬럼으로 갖는 dataframe을 생성해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0a01df2-a77e-4390-8a42-9465893317fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18895</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18896</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18897</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18898</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18899</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/n...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18900 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path  label\n",
       "0      input/data/train/images/000001_female_Asian_45...     10\n",
       "1      input/data/train/images/000001_female_Asian_45...      4\n",
       "2      input/data/train/images/000001_female_Asian_45...      4\n",
       "3      input/data/train/images/000001_female_Asian_45...      4\n",
       "4      input/data/train/images/000001_female_Asian_45...      4\n",
       "...                                                  ...    ...\n",
       "18895  input/data/train/images/006959_male_Asian_19/m...      0\n",
       "18896  input/data/train/images/006959_male_Asian_19/m...      0\n",
       "18897  input/data/train/images/006959_male_Asian_19/m...      0\n",
       "18898  input/data/train/images/006959_male_Asian_19/m...      0\n",
       "18899  input/data/train/images/006959_male_Asian_19/n...     12\n",
       "\n",
       "[18900 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path_label = pd.DataFrame(all_path, columns = ['path'])\n",
    "\n",
    "train_path_label['label'] = train_path_label['path'].map(lambda x: labeling(x))\n",
    "train_path_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "897da325-d4df-495c-937c-d195424edb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path_label.to_csv('./train_path_label.csv', index=False, encoding='utf-8')\n",
    "# train_path_label = pd.read_csv('./train_path_label.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee45d570-0645-4bd1-9623-797a0a287648",
   "metadata": {},
   "source": [
    "dataset을 상속받아 만든 CustomDataset입니다. transform은 size를 [512, 384]로 변형하고, Tensor로 만들고, 정규화를 해주었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa99111-9bb5-4f27-b062-956f1b61d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_paths_label, transform):\n",
    "        self.X = img_paths_label['path']\n",
    "        self.y = img_paths_label['label']\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.X.iloc[index])\n",
    "        label = self.y.iloc[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74229d34-afe4-49b3-a84c-93885000beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1da396-de7c-46e3-b4a7-9d3a47bee7d2",
   "metadata": {},
   "source": [
    "train, valid를 나누는 부분입니다.\n",
    "\n",
    "label의 비율을 유지하면서 나눴습니다.\n",
    "\n",
    "+ 기존 방법 대신StratifiedKFold 사용을 시도했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f983476-59fd-485c-b5bd-a3755af6cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# train, valid = train_test_split(train_path_label, test_size=0.2,\n",
    "#                                shuffle=True, stratify=train_path_label['label'],\n",
    "#                                random_state=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53192a6-95ba-431b-80c7-85b820aab853",
   "metadata": {},
   "source": [
    "DataLoader\n",
    "- index를 사용한 Dataloader 정의\n",
    "- getDataloader 함수 설명\n",
    "    1. Pytorch Dataset, train 인덱스, valid 인덱스, batch size를 전달받아 Train, Valid DataLoader 객체를 반환합니다.\n",
    "    2. torch.utils.data.Subset 객체는 데이터셋과 해당 데이터셋의 인덱스를 전달받아 Subset 객체를 생성합니다. 생성한 Subset 객체를 사용해 DataLoader 객체를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d5e3ee2-3afe-469d-b248-27b77e87d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataloader(dataset, train_idx, valid_idx, batch_size, num_workers):\n",
    "    # 인자로 전달받은 dataset에서 train_idx에 해당하는 Subset 추출\n",
    "    train_set = torch.utils.data.Subset(dataset,\n",
    "                                        indices=train_idx)\n",
    "    # 인자로 전달받은 dataset에서 valid_idx에 해당하는 Subset 추출\n",
    "    val_set   = torch.utils.data.Subset(dataset,\n",
    "                                        indices=valid_idx)\n",
    "    \n",
    "    # 추출된 Train Subset으로 DataLoader 생성\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "    # 추출된 Valid Subset으로 DataLoader 생성\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # 생성한 DataLoader 반환\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44331d5-b6ae-403d-b3b1-c76a7758d53e",
   "metadata": {},
   "source": [
    "dataloader를 정의했습니다. batchsize는 64로 했고 shuffle을 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec86e71c-2975-47b0-bd06-28df82c791e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01bfaea4-9ff5-42c4-af4f-1f584af88e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(train_path_label, transform)\n",
    "\n",
    "custom_dataloader = DataLoader(dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=True\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e466688b-3615-422b-ad07-821a8d6c491d",
   "metadata": {},
   "source": [
    "모델\n",
    "모델은 pretrain된 resnet18을 가져왔습니다. 이 모델의 마지막 fc층만 저희의 과제인 18개의 class로 변경해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e76528b7-b699-491c-8507-a1d6f4a0d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "998b8581-1351-4a2c-aba4-08a74c4a17b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "OUTPUT_CLASS_NUM = 18\n",
    "resnet18.fc = torch.nn.Linear(in_features=512, out_features=OUTPUT_CLASS_NUM, bias=True) # output 18개로\n",
    "\n",
    "# resnet18.fc = nn.Sequential(\n",
    "#                        nn.Linear(512, 512),\n",
    "#                        nn.ReLU(inplace=True),\n",
    "#                        nn.Dropout(0.7),\n",
    "#                        nn.Linear(512, 512),\n",
    "#                        nn.ReLU(inplace=True),\n",
    "#                        nn.Dropout(0.7),\n",
    "#                        nn.Linear(512, 18)\n",
    "#                         ).to(device)\n",
    "\n",
    "# xavier uniform\n",
    "torch.nn.init.xavier_uniform_(resnet18.fc.weight)\n",
    "stdv = 1. / math.sqrt(resnet18.fc.weight.size(1))\n",
    "resnet18.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "resnet18.fc.weight.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89442b2-35cf-4384-9d18-18481d60f01a",
   "metadata": {},
   "source": [
    "아래 대부분의 코드가 부스트캠프에서 학습 자료나 과제로 제공받았던 코드를 거의 그대로 사용했습니다.\n",
    "\n",
    "설명도 주석도 잘 달려 있어서 그대로 가져왔습니다.\n",
    "\n",
    "epoch는 5, lr은 0.0001로 주었습니다.\n",
    "\n",
    "추후에 lr scheduler로 lr을 변경해보는 방법도 좋을 것 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "034530d8-23ca-4a6e-a65b-43834df02325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe33dbb7-a718-4d57-b51c-79961d4ab129",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-557086e9111c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresnet18\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m \u001b[0;31m# 학습 때 사용하는 optimizer의 학습률 옵션 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mNUM_EPOCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;31m# 학습 때 mnist train data set을 얼마나 많이 학습할 지 결정하는 옵션\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "resnet18.to(device)\n",
    "\n",
    "LEARNING_RATE = 0.0001 # 학습 때 사용하는 optimizer의 학습률 옵션 설정\n",
    "NUM_EPOCH = 3 # 학습 때 mnist train data set을 얼마나 많이 학습할 지 결정하는 옵션\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss() # 분류 학습 때 많이 사용되는 Cross Entropy Loss를 objective function으로 사용\n",
    "optimizer = torch.optim.Adam(resnet18.parameters(), lr=LEARNING_RATE) # weight 업데이트를 위한 optimizer를 Adam으로 사용함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d55cbe-9d85-4c5d-9ac0-12b8f9b09ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold Stratified KFold 5개의 fold를 형성하고 5번 Cross Validation을 진행합니다.\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "best_test_accuracy = 0.\n",
    "best_test_loss = 9999.\n",
    "start = time.time()  # 시작 시간 저장\n",
    "\n",
    "# skf 설정\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "# kfold = KFold(n_splits=4, shuffle=False)\n",
    "\n",
    "# skf에서 사용할 labels 설정\n",
    "labels = [i for i in train_path_label['label']]\n",
    "\n",
    "# BATCH_SIZE = 32\n",
    "num_workers = 4\n",
    "\n",
    "print(train_path_label)\n",
    "temp_idx = 0\n",
    "for train_index, validate_index in skf.split(train_path_label, labels):\n",
    "#     print(train_index, validate_index)\n",
    "    temp_idx += 1\n",
    "    train = train_path_label.iloc[train_index]\n",
    "    valid = train_path_label.iloc[validate_index]\n",
    "\n",
    "    train_dataset = CustomDataset(train, transform)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset,\n",
    "                                 batch_size=BATCH_SIZE,\n",
    "                                 shuffle=False\n",
    "                                 )\n",
    "\n",
    "    valid_dataset = CustomDataset(valid, transform)\n",
    "\n",
    "    valid_dataloader = DataLoader(valid_dataset,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=False)\n",
    "\n",
    "    dataloaders = {\n",
    "        \"train\": train_dataloader,\n",
    "        \"test\": valid_dataloader,\n",
    "    }\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "\n",
    "        for phase in [\"train\", \"test\"]:\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "#             # 네트워크 모델을 train 모드로 두어 gradient를 계산하고, \n",
    "#             # 여러 sub module (배치 정규화, 드롭아웃 등)이 train_mode로 작동할 수 있게 함.\n",
    "            if phase == \"train\":\n",
    "                resnet18.train()\n",
    "            # 네트워크 모델을 eval 모드로 두어 여러 sub module들이 eval mode로 작동할 수 있게 함.\n",
    "            elif phase == \"test\":\n",
    "                resnet18.eval()\n",
    "            \n",
    "            for ind, (images, labels) in enumerate(dataloaders[phase]):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad() # parameter gradient를 업데이트 전 초기화함.\n",
    "\n",
    "                # train 모드일 시에는 gradient를 계산하고, 아닐 때는 gradient를 계산하지 않아 연산량 최소화\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    logits = resnet18(images)\n",
    "                    # 모델에서 linear 값으로 나오는 예측 값([0.9, 1.2, 3.2, 0.1, -0.1, ...])에서 최대 output index를 찾아 예측 레이블([2])로 변경함\n",
    "                    _, preds = torch.max(logits, 1)\n",
    "                    loss = loss_fn(logits, labels)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward() # 모델의 예측 값과 실제 값의 CrossEntropy 차이를 통해 gradient를 계산\n",
    "                        optimizer.step() # 계산된 gradient를 가지고 모델 업데이트\n",
    "\n",
    "                running_loss += loss.item() * images.size(0) # 한 Batch에서의 loss 값 저장\n",
    "                running_acc += torch.sum(preds == labels.data) # 한 Batch에서의 Accuracy 값 저장\n",
    "\n",
    "            # 한 epoch이 모두 종료되었을 때,\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_acc / len(dataloaders[phase].dataset)\n",
    "\n",
    "            seconds = int(time.time() - start)\n",
    "            print(f\"현재 epoch-{temp_idx}-{epoch}의 {phase}-데이터 셋에서 평균 Loss: {epoch_loss:.3f}, 평균 Accuracy: {epoch_acc:.3f}\")\n",
    "            print(f\"소요 시간: {seconds // 60}분 {seconds % 60}초\")  # 현재시각 - 시작시간 = 실행 시간\n",
    "#             print(f\"현재 epoch-{epoch}의 {phase}-데이터 셋에서 평균 Loss: {epoch_loss:.3f}, 평균 Accuracy: {epoch_acc:.3f}\")\n",
    "#             print(f\"소요 시간: {seconds // 60}분 {seconds % 60}초\")  # 현재시각 - 시작시간 = 실행 시간\n",
    "\n",
    "            # phase가 test일 때\n",
    "            if phase == \"test\":\n",
    "                # best accuracy 계산\n",
    "                if best_test_accuracy < epoch_acc:\n",
    "                    best_test_accuracy = epoch_acc\n",
    "                # best loss 계산\n",
    "                if best_test_loss > epoch_loss:\n",
    "                    best_test_loss = epoch_loss\n",
    "\n",
    "                \n",
    "seconds = int(time.time() - start)\n",
    "print(\"학습 종료!\")\n",
    "print(f\"최고 accuracy: {best_test_accuracy}, 최고 낮은 loss: {best_test_loss}\")\n",
    "print(f\"소요 시간: {seconds // 60}분 {seconds % 60}초\")  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b8b5f-b9cc-489d-a8dc-6177bd582940",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0].shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394de42a-a2b6-467f-a8fe-5657afcedd28",
   "metadata": {},
   "source": [
    "dataloader를 정의했습니다. batchsize는 64로 했고 shuffle을 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac036e-abaa-4b02-93ec-98f7f93106c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/input'\n",
    "\n",
    "torch.save(resnet18, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5867fb-4ace-4c4f-a078-be1d6b5ff4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3beba0d-98de-43af-9e9b-59f32bc88304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5baa8534-841f-4ad2-91a9-c3aa65330f63",
   "metadata": {},
   "source": [
    "검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0299e3-3b3e-45b9-935f-33ff69f97011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_eval(model, data_iter, device):\n",
    "    with torch.no_grad():\n",
    "        n_total, n_correct = 0, 0\n",
    "        model.eval()\n",
    "        for batch_in, batch_out in data_iter:\n",
    "            y_trgt = batch_out.to(device)\n",
    "            model_pred = model.forward(batch_in.to(device))\n",
    "            _, y_pred = torch.max(model_pred, 1)  # 행으로 비교\n",
    "            n_correct += (y_pred == y_trgt).sum().item()\n",
    "            n_total += batch_in.size(0)\n",
    "        val_acc = (n_correct/n_total)\n",
    "        #model_train()\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500c3ff1-45cc-4e72-b9b9-31e1e5ac207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_eval(resnet18, valid_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f018c8-9e3e-4ace-8ef0-f22293b82c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_eval(raw_data, dataloader, model, device):\n",
    "    result = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (X,y) in enumerate(dataloader):\n",
    "            model_pred = model.forward(X.to(device))\n",
    "            _, y_pred = torch.max(model_pred, 1)\n",
    "            \n",
    "            result.append([valid.iloc[i]['path'], y_pred.cpu().numpy()[0], y.cpu().numpy()[0]])\n",
    "    result = pd.DataFrame(result, columns=['path', 'pred', 'target'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d2802f-43d8-4516-b4ce-ae2d69a75edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_testing_dataloader = DataLoader(valid_dataset, shuffle=False)\n",
    "\n",
    "check_eval_df = check_eval(valid, valid_testing_dataloader, resnet18, device)\n",
    "check_eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f95332-f0e4-42e1-ab83-1cebbc46f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "잘못 예측한 데이터 리스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf64055-0028-4ab5-b34f-9bf6e7e399f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_df = check_eval_df[check_eval_df['pred'] != check_eval_df['target']]\n",
    "wrong_df = wrong_df.reset_index(drop=True)\n",
    "wrong_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4d31dd-d56c-4785-9fcb-09f6a37fe991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8298cf4c-f313-45cd-8549-7ecae3f11cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 score 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f74389-3912-4679-85c2-ce268e266dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c7477-c27f-4857-9b8b-c87c1f02647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d9764-2532-4f97-9e00-0a4f430c0902",
   "metadata": {},
   "source": [
    "함수 정의\n",
    "\n",
    "- precision, recall, f1-score, confusion matrix 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45717d2d-5fdc-48b4-b553-549ce1572da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report():\n",
    "    y_test, y_pred = check_eval_df['target'], check_eval_df['pred']\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('resnet18 Accuracy:', np.mean(y_pred == y_test))\n",
    "    ax = plt.figure(figsize=(10, 5))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), linewidths=0.5, fmt='.1f', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ae7f1-9938-43c4-a775-47366e60f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc17027-5f8e-423f-9d39-315ce880c97a",
   "metadata": {},
   "source": [
    "제출할 파일 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a26268e-43f5-4579-a079-590c7bae74ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf83901-c617-4da3-94e8-012e208ace06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "# model = MyModel(num_classes=18).to(device)\n",
    "PATH = '/input'\n",
    "model = torch.load(PATH)\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d3cafa-1f87-4c7e-89f0-6a3bd2e9c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "클래스 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5796e2ea-516e-4cf6-b957-af77da9989b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('input/data/eval/submission.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee1cf62-30f4-46da-b0e2-bb5917581d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = dict()\n",
    "\n",
    "for cla in test_data['ans']:\n",
    "    if cla in classes:\n",
    "        classes[cla] += 1\n",
    "    else:\n",
    "        classes[cla] = 1\n",
    "        \n",
    "classes = sorted(classes.items())\n",
    "print(classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
