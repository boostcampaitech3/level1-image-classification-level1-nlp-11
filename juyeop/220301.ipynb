{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31b9b979-b5a6-4d6c-82b6-1658ef6d60ff",
   "metadata": {},
   "source": [
    "pretrained model : resnet18\n",
    "\n",
    "loss_fn : CrossEntropyLoss\n",
    "\n",
    "optimizer : adam\n",
    "\n",
    "epoch: 5\n",
    "\n",
    "batch-size : 64 -> 32\n",
    "\n",
    "data augmentation : transforms.RandomHorizontalFlip(),\n",
    "\n",
    "fc layer : relu\n",
    "\n",
    "lr : 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d2f7f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler\n",
    "\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "e82372af-e478-4dae-a283-f792958f76f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = 'input/data/train'\n",
    "train_image_dir_path = os.path.join(train_path, 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e84dc1-18eb-4592-bd15-330007a90b01",
   "metadata": {},
   "source": [
    "Dataset 생성\n",
    "\n",
    "모든 train data의 path를 가져와 라벨링 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "040577b9-a2c5-4516-a5fd-b1f3ae11d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(dirname, result): # 하위 목록의 모든 파일을 찾는 함수\n",
    "    try:\n",
    "        filenames = os.listdir(dirname)\n",
    "        for filename in filenames:\n",
    "            if filename[0] == '.': # .으로 시작하는 애들 거름\n",
    "                continue\n",
    "            full_filename = os.path.join(dirname, filename)\n",
    "            if os.path.isdir(full_filename):\n",
    "                search(full_filename, result)\n",
    "            else:\n",
    "                ext = os.path.splitext(full_filename)[-1] # 확장자 체크\n",
    "                if ext:\n",
    "                    result.append(full_filename)\n",
    "        \n",
    "    except PermissionError:\n",
    "        print('Permission Error')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2e40f2b1-7abe-49e1-abda-701cb6025934",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_path = list()\n",
    "search(train_image_dir_path, all_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3455a861-4429-4243-898c-b3f2e4186942",
   "metadata": {},
   "source": [
    "train의 데이터 디렉토리는 2700개로, 각각의 이미지 파일(incorrect, mask1~5, normal)을 곱한 갯수가 나옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ba63e19e-6978-4785-921e-44a58757f838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18900"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_path) # 2700 * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ff701504-72d2-44d0-8e2e-82ac0964e1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input/data/train/images/001752_male_Asian_53/mask5.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/mask4.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/mask2.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/mask3.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/normal.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/mask1.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/incorrect_mask.jpg',\n",
       " 'input/data/train/images/005127_female_Asian_51/mask5.jpg',\n",
       " 'input/data/train/images/005127_female_Asian_51/mask4.jpg',\n",
       " 'input/data/train/images/005127_female_Asian_51/mask2.jpg']"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_path[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8726c41-ba96-408b-9e65-10bcab850853",
   "metadata": {},
   "source": [
    "파일의 확장자는 jpg, png, jpeg로 3종류가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "1b45de68-c50e-435b-853b-5e95fba44852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.jpg', '.png', '.jpeg']\n"
     ]
    }
   ],
   "source": [
    "exts = list()\n",
    "for word in all_path:\n",
    "    ext = os.path.splitext(word)[-1]\n",
    "    if ext not in exts:\n",
    "        exts.append(ext)\n",
    "print(exts) # jpg, png, jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "f205b726-45fc-4d95-b3d0-fef15a7ecf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_path = sorted(all_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e47982-6d3f-4677-abfe-e9997e699876",
   "metadata": {},
   "source": [
    "라벨링을 하는 함수입니다. 조건에 따라 label에 숫자를 더해주는 식으로 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "370658c3-e841-4e0d-809b-c53d00cd9337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(name):\n",
    "    label = 0\n",
    "    info, mask_type = name.split('/')[-2:]\n",
    "    info = info.split('_')\n",
    "    gender, age = info[1], int(info[3])\n",
    "    \n",
    "    # 마스크 구별\n",
    "    if 'incorrect' in mask_type:\n",
    "        label += 6\n",
    "    elif 'normal' in mask_type:\n",
    "        label += 12\n",
    "    \n",
    "    # gender 구별\n",
    "    if gender == 'female':\n",
    "        label += 3\n",
    "    \n",
    "    # 나이 구별\n",
    "    if 30 <= age and age < 60:\n",
    "        label += 1\n",
    "    elif age >= 60:\n",
    "        label += 2\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c06615-2768-4cfd-9026-6105537d0dcb",
   "metadata": {},
   "source": [
    "path, label을 컬럼으로 갖는 dataframe을 생성해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f0a01df2-a77e-4390-8a42-9465893317fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18895</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18896</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18897</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18898</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18899</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/n...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18900 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path  label\n",
       "0      input/data/train/images/000001_female_Asian_45...     10\n",
       "1      input/data/train/images/000001_female_Asian_45...      4\n",
       "2      input/data/train/images/000001_female_Asian_45...      4\n",
       "3      input/data/train/images/000001_female_Asian_45...      4\n",
       "4      input/data/train/images/000001_female_Asian_45...      4\n",
       "...                                                  ...    ...\n",
       "18895  input/data/train/images/006959_male_Asian_19/m...      0\n",
       "18896  input/data/train/images/006959_male_Asian_19/m...      0\n",
       "18897  input/data/train/images/006959_male_Asian_19/m...      0\n",
       "18898  input/data/train/images/006959_male_Asian_19/m...      0\n",
       "18899  input/data/train/images/006959_male_Asian_19/n...     12\n",
       "\n",
       "[18900 rows x 2 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path_label = pd.DataFrame(all_path, columns = ['path'])\n",
    "\n",
    "train_path_label['label'] = train_path_label['path'].map(lambda x: labeling(x))\n",
    "train_path_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "897da325-d4df-495c-937c-d195424edb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path_label.to_csv('./train_path_label.csv', index=False, encoding='utf-8')\n",
    "# train_path_label = pd.read_csv('./train_path_label.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee45d570-0645-4bd1-9623-797a0a287648",
   "metadata": {},
   "source": [
    "dataset을 상속받아 만든 CustomDataset입니다. transform은 size를 [512, 384]로 변형하고, Tensor로 만들고, 정규화를 해주었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "cfa99111-9bb5-4f27-b062-956f1b61d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_paths_label, transform):\n",
    "        self.X = img_paths_label['path']\n",
    "        self.y = img_paths_label['label']\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.X.iloc[index])\n",
    "        label = self.y.iloc[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "74229d34-afe4-49b3-a84c-93885000beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1da396-de7c-46e3-b4a7-9d3a47bee7d2",
   "metadata": {},
   "source": [
    "train, valid를 나누는 부분입니다.\n",
    "\n",
    "label의 비율을 유지하면서 나눴습니다.\n",
    "\n",
    "+ 기존 방법 대신StratifiedKFold 사용을 시도했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "2f983476-59fd-485c-b5bd-a3755af6cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# train, valid = train_test_split(train_path_label, test_size=0.2,\n",
    "#                                shuffle=True, stratify=train_path_label['label'],\n",
    "#                                random_state=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53192a6-95ba-431b-80c7-85b820aab853",
   "metadata": {},
   "source": [
    "DataLoader\n",
    "- index를 사용한 Dataloader 정의\n",
    "- getDataloader 함수 설명\n",
    "    1. Pytorch Dataset, train 인덱스, valid 인덱스, batch size를 전달받아 Train, Valid DataLoader 객체를 반환합니다.\n",
    "    2. torch.utils.data.Subset 객체는 데이터셋과 해당 데이터셋의 인덱스를 전달받아 Subset 객체를 생성합니다. 생성한 Subset 객체를 사용해 DataLoader 객체를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "3d5e3ee2-3afe-469d-b248-27b77e87d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataloader(dataset, train_idx, valid_idx, batch_size, num_workers):\n",
    "    # 인자로 전달받은 dataset에서 train_idx에 해당하는 Subset 추출\n",
    "    train_set = torch.utils.data.Subset(dataset,\n",
    "                                        indices=train_idx)\n",
    "    # 인자로 전달받은 dataset에서 valid_idx에 해당하는 Subset 추출\n",
    "    val_set   = torch.utils.data.Subset(dataset,\n",
    "                                        indices=valid_idx)\n",
    "    \n",
    "    # 추출된 Train Subset으로 DataLoader 생성\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "    # 추출된 Valid Subset으로 DataLoader 생성\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # 생성한 DataLoader 반환\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44331d5-b6ae-403d-b3b1-c76a7758d53e",
   "metadata": {},
   "source": [
    "dataloader를 정의했습니다. batchsize는 64로 했고 shuffle을 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "ec86e71c-2975-47b0-bd06-28df82c791e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "01bfaea4-9ff5-42c4-af4f-1f584af88e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(train_path_label, transform)\n",
    "\n",
    "custom_dataloader = DataLoader(dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=True\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e466688b-3615-422b-ad07-821a8d6c491d",
   "metadata": {},
   "source": [
    "모델\n",
    "모델은 pretrain된 resnet18을 가져왔습니다. 이 모델의 마지막 fc층만 저희의 과제인 18개의 class로 변경해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "e76528b7-b699-491c-8507-a1d6f4a0d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "998b8581-1351-4a2c-aba4-08a74c4a17b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "OUTPUT_CLASS_NUM = 18\n",
    "resnet18.fc = torch.nn.Linear(in_features=512, out_features=OUTPUT_CLASS_NUM, bias=True) # output 18개로\n",
    "\n",
    "# xavier uniform\n",
    "torch.nn.init.xavier_uniform_(resnet18.fc.weight)\n",
    "stdv = 1. / math.sqrt(resnet18.fc.weight.size(1))\n",
    "resnet18.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "resnet18.fc.weight.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "58a6c46b-00fd-434d-97f8-17f87cbc9ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89442b2-35cf-4384-9d18-18481d60f01a",
   "metadata": {},
   "source": [
    "아래 대부분의 코드가 부스트캠프에서 학습 자료나 과제로 제공받았던 코드를 거의 그대로 사용했습니다.\n",
    "\n",
    "설명도 주석도 잘 달려 있어서 그대로 가져왔습니다.\n",
    "\n",
    "epoch는 5, lr은 0.0001로 주었습니다.\n",
    "\n",
    "추후에 lr scheduler로 lr을 변경해보는 방법도 좋을 것 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "fe33dbb7-a718-4d57-b51c-79961d4ab129",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18.to(device)\n",
    "\n",
    "LEARNING_RATE = 0.0001 # 학습 때 사용하는 optimizer의 학습률 옵션 설정\n",
    "NUM_EPOCH = 5 # 학습 때 mnist train data set을 얼마나 많이 학습할 지 결정하는 옵션\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss() # 분류 학습 때 많이 사용되는 Cross Entropy Loss를 objective function으로 사용\n",
    "optimizer = torch.optim.Adam(resnet18.parameters(), lr=LEARNING_RATE) # weight 업데이트를 위한 optimizer를 Adam으로 사용함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "57d55cbe-9d85-4c5d-9ac0-12b8f9b09ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    path  label\n",
      "0      input/data/train/images/000001_female_Asian_45...     10\n",
      "1      input/data/train/images/000001_female_Asian_45...      4\n",
      "2      input/data/train/images/000001_female_Asian_45...      4\n",
      "3      input/data/train/images/000001_female_Asian_45...      4\n",
      "4      input/data/train/images/000001_female_Asian_45...      4\n",
      "...                                                  ...    ...\n",
      "18895  input/data/train/images/006959_male_Asian_19/m...      0\n",
      "18896  input/data/train/images/006959_male_Asian_19/m...      0\n",
      "18897  input/data/train/images/006959_male_Asian_19/m...      0\n",
      "18898  input/data/train/images/006959_male_Asian_19/m...      0\n",
      "18899  input/data/train/images/006959_male_Asian_19/n...     12\n",
      "\n",
      "[18900 rows x 2 columns]\n",
      "현재 epoch-1-0의 train-데이터 셋에서 평균 Loss: 1.122, 평균 Accuracy: 0.653\n",
      "소요 시간: 2분 19초\n",
      "현재 epoch-1-0의 test-데이터 셋에서 평균 Loss: 2.442, 평균 Accuracy: 0.330\n",
      "소요 시간: 2분 43초\n",
      "현재 epoch-1-1의 train-데이터 셋에서 평균 Loss: 0.713, 평균 Accuracy: 0.767\n",
      "소요 시간: 5분 2초\n",
      "현재 epoch-1-1의 test-데이터 셋에서 평균 Loss: 1.392, 평균 Accuracy: 0.533\n",
      "소요 시간: 5분 27초\n",
      "현재 epoch-1-2의 train-데이터 셋에서 평균 Loss: 0.385, 평균 Accuracy: 0.874\n",
      "소요 시간: 7분 46초\n",
      "현재 epoch-1-2의 test-데이터 셋에서 평균 Loss: 0.981, 평균 Accuracy: 0.665\n",
      "소요 시간: 8분 10초\n",
      "현재 epoch-1-3의 train-데이터 셋에서 평균 Loss: 0.217, 평균 Accuracy: 0.933\n",
      "소요 시간: 10분 29초\n",
      "현재 epoch-1-3의 test-데이터 셋에서 평균 Loss: 1.027, 평균 Accuracy: 0.647\n",
      "소요 시간: 10분 53초\n",
      "현재 epoch-1-4의 train-데이터 셋에서 평균 Loss: 0.125, 평균 Accuracy: 0.966\n",
      "소요 시간: 13분 13초\n",
      "현재 epoch-1-4의 test-데이터 셋에서 평균 Loss: 0.926, 평균 Accuracy: 0.685\n",
      "소요 시간: 13분 38초\n",
      "현재 epoch-2-0의 train-데이터 셋에서 평균 Loss: 0.472, 평균 Accuracy: 0.856\n",
      "소요 시간: 15분 59초\n",
      "현재 epoch-2-0의 test-데이터 셋에서 평균 Loss: 0.848, 평균 Accuracy: 0.713\n",
      "소요 시간: 16분 23초\n",
      "현재 epoch-2-1의 train-데이터 셋에서 평균 Loss: 0.231, 평균 Accuracy: 0.925\n",
      "소요 시간: 18분 44초\n",
      "현재 epoch-2-1의 test-데이터 셋에서 평균 Loss: 0.816, 평균 Accuracy: 0.772\n",
      "소요 시간: 19분 8초\n",
      "현재 epoch-2-2의 train-데이터 셋에서 평균 Loss: 0.117, 평균 Accuracy: 0.968\n",
      "소요 시간: 21분 27초\n",
      "현재 epoch-2-2의 test-데이터 셋에서 평균 Loss: 0.934, 평균 Accuracy: 0.751\n",
      "소요 시간: 21분 52초\n",
      "현재 epoch-2-3의 train-데이터 셋에서 평균 Loss: 0.071, 평균 Accuracy: 0.984\n",
      "소요 시간: 24분 11초\n",
      "현재 epoch-2-3의 test-데이터 셋에서 평균 Loss: 0.845, 평균 Accuracy: 0.798\n",
      "소요 시간: 24분 36초\n",
      "현재 epoch-2-4의 train-데이터 셋에서 평균 Loss: 0.048, 평균 Accuracy: 0.988\n",
      "소요 시간: 26분 57초\n",
      "현재 epoch-2-4의 test-데이터 셋에서 평균 Loss: 0.853, 평균 Accuracy: 0.770\n",
      "소요 시간: 27분 21초\n",
      "현재 epoch-3-0의 train-데이터 셋에서 평균 Loss: 0.192, 평균 Accuracy: 0.938\n",
      "소요 시간: 29분 40초\n",
      "현재 epoch-3-0의 test-데이터 셋에서 평균 Loss: 0.506, 평균 Accuracy: 0.815\n",
      "소요 시간: 30분 4초\n",
      "현재 epoch-3-1의 train-데이터 셋에서 평균 Loss: 0.078, 평균 Accuracy: 0.975\n",
      "소요 시간: 32분 21초\n",
      "현재 epoch-3-1의 test-데이터 셋에서 평균 Loss: 0.594, 평균 Accuracy: 0.801\n",
      "소요 시간: 32분 45초\n",
      "현재 epoch-3-2의 train-데이터 셋에서 평균 Loss: 0.047, 평균 Accuracy: 0.986\n",
      "소요 시간: 35분 2초\n",
      "현재 epoch-3-2의 test-데이터 셋에서 평균 Loss: 0.617, 평균 Accuracy: 0.790\n",
      "소요 시간: 35분 26초\n",
      "현재 epoch-3-3의 train-데이터 셋에서 평균 Loss: 0.034, 평균 Accuracy: 0.992\n",
      "소요 시간: 37분 45초\n",
      "현재 epoch-3-3의 test-데이터 셋에서 평균 Loss: 0.865, 평균 Accuracy: 0.749\n",
      "소요 시간: 38분 10초\n",
      "현재 epoch-3-4의 train-데이터 셋에서 평균 Loss: 0.021, 평균 Accuracy: 0.995\n",
      "소요 시간: 40분 30초\n",
      "현재 epoch-3-4의 test-데이터 셋에서 평균 Loss: 0.637, 평균 Accuracy: 0.815\n",
      "소요 시간: 40분 54초\n",
      "현재 epoch-4-0의 train-데이터 셋에서 평균 Loss: 0.174, 평균 Accuracy: 0.945\n",
      "소요 시간: 43분 9초\n",
      "현재 epoch-4-0의 test-데이터 셋에서 평균 Loss: 0.427, 평균 Accuracy: 0.836\n",
      "소요 시간: 43분 35초\n",
      "현재 epoch-4-1의 train-데이터 셋에서 평균 Loss: 0.073, 평균 Accuracy: 0.976\n",
      "소요 시간: 45분 50초\n",
      "현재 epoch-4-1의 test-데이터 셋에서 평균 Loss: 0.231, 평균 Accuracy: 0.911\n",
      "소요 시간: 46분 17초\n",
      "현재 epoch-4-2의 train-데이터 셋에서 평균 Loss: 0.041, 평균 Accuracy: 0.990\n",
      "소요 시간: 48분 33초\n",
      "현재 epoch-4-2의 test-데이터 셋에서 평균 Loss: 0.610, 평균 Accuracy: 0.817\n",
      "소요 시간: 48분 59초\n",
      "현재 epoch-4-3의 train-데이터 셋에서 평균 Loss: 0.030, 평균 Accuracy: 0.992\n",
      "소요 시간: 51분 16초\n",
      "현재 epoch-4-3의 test-데이터 셋에서 평균 Loss: 0.515, 평균 Accuracy: 0.833\n",
      "소요 시간: 51분 42초\n",
      "현재 epoch-4-4의 train-데이터 셋에서 평균 Loss: 0.015, 평균 Accuracy: 0.997\n",
      "소요 시간: 53분 58초\n",
      "현재 epoch-4-4의 test-데이터 셋에서 평균 Loss: 0.568, 평균 Accuracy: 0.844\n",
      "소요 시간: 54분 25초\n",
      "현재 epoch-5-0의 train-데이터 셋에서 평균 Loss: 0.043, 평균 Accuracy: 0.987\n",
      "소요 시간: 56분 44초\n",
      "현재 epoch-5-0의 test-데이터 셋에서 평균 Loss: 2.142, 평균 Accuracy: 0.443\n",
      "소요 시간: 57분 9초\n",
      "현재 epoch-5-1의 train-데이터 셋에서 평균 Loss: 0.051, 평균 Accuracy: 0.984\n",
      "소요 시간: 59분 28초\n",
      "현재 epoch-5-1의 test-데이터 셋에서 평균 Loss: 2.631, 평균 Accuracy: 0.510\n",
      "소요 시간: 59분 52초\n",
      "현재 epoch-5-2의 train-데이터 셋에서 평균 Loss: 0.031, 평균 Accuracy: 0.991\n",
      "소요 시간: 62분 12초\n",
      "현재 epoch-5-2의 test-데이터 셋에서 평균 Loss: 2.691, 평균 Accuracy: 0.502\n",
      "소요 시간: 62분 37초\n",
      "현재 epoch-5-3의 train-데이터 셋에서 평균 Loss: 0.020, 평균 Accuracy: 0.994\n",
      "소요 시간: 64분 54초\n",
      "현재 epoch-5-3의 test-데이터 셋에서 평균 Loss: 0.967, 평균 Accuracy: 0.701\n",
      "소요 시간: 65분 18초\n",
      "현재 epoch-5-4의 train-데이터 셋에서 평균 Loss: 0.009, 평균 Accuracy: 0.998\n",
      "소요 시간: 67분 38초\n",
      "현재 epoch-5-4의 test-데이터 셋에서 평균 Loss: 1.072, 평균 Accuracy: 0.700\n",
      "소요 시간: 68분 2초\n",
      "학습 종료!\n",
      "최고 accuracy: 0.9108465909957886, 최고 낮은 loss: 0.231270661373101\n",
      "소요 시간: 68분 2초\n"
     ]
    }
   ],
   "source": [
    "# 5-fold Stratified KFold 5개의 fold를 형성하고 5번 Cross Validation을 진행합니다.\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "best_test_accuracy = 0.\n",
    "best_test_loss = 9999.\n",
    "start = time.time()  # 시작 시간 저장\n",
    "\n",
    "# skf 설정\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "# kfold = KFold(n_splits=4, shuffle=False)\n",
    "\n",
    "# skf에서 사용할 labels 설정\n",
    "labels = [i for i in train_path_label['label']]\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 4\n",
    "\n",
    "print(train_path_label)\n",
    "temp_idx = 0\n",
    "for train_index, validate_index in skf.split(train_path_label, labels):\n",
    "#     print(train_index, validate_index)\n",
    "    temp_idx += 1\n",
    "    train = train_path_label.iloc[train_index]\n",
    "    valid = train_path_label.iloc[validate_index]\n",
    "\n",
    "    train_dataset = CustomDataset(train, transform)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset,\n",
    "                                 batch_size=BATCH_SIZE,\n",
    "                                 shuffle=False\n",
    "                                 )\n",
    "\n",
    "    valid_dataset = CustomDataset(valid, transform)\n",
    "\n",
    "    valid_dataloader = DataLoader(valid_dataset,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=False)\n",
    "\n",
    "    dataloaders = {\n",
    "        \"train\": train_dataloader,\n",
    "        \"test\": valid_dataloader,\n",
    "    }\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "\n",
    "        for phase in [\"train\", \"test\"]:\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "#             # 네트워크 모델을 train 모드로 두어 gradient를 계산하고, \n",
    "#             # 여러 sub module (배치 정규화, 드롭아웃 등)이 train_mode로 작동할 수 있게 함.\n",
    "            if phase == \"train\":\n",
    "                resnet18.train()\n",
    "            # 네트워크 모델을 eval 모드로 두어 여러 sub module들이 eval mode로 작동할 수 있게 함.\n",
    "            elif phase == \"test\":\n",
    "                resnet18.eval()\n",
    "            \n",
    "            for ind, (images, labels) in enumerate(dataloaders[phase]):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad() # parameter gradient를 업데이트 전 초기화함.\n",
    "\n",
    "                # train 모드일 시에는 gradient를 계산하고, 아닐 때는 gradient를 계산하지 않아 연산량 최소화\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    logits = resnet18(images)\n",
    "                    # 모델에서 linear 값으로 나오는 예측 값([0.9, 1.2, 3.2, 0.1, -0.1, ...])에서 최대 output index를 찾아 예측 레이블([2])로 변경함\n",
    "                    _, preds = torch.max(logits, 1)\n",
    "                    loss = loss_fn(logits, labels)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward() # 모델의 예측 값과 실제 값의 CrossEntropy 차이를 통해 gradient를 계산\n",
    "                        optimizer.step() # 계산된 gradient를 가지고 모델 업데이트\n",
    "\n",
    "                running_loss += loss.item() * images.size(0) # 한 Batch에서의 loss 값 저장\n",
    "                running_acc += torch.sum(preds == labels.data) # 한 Batch에서의 Accuracy 값 저장\n",
    "\n",
    "            # 한 epoch이 모두 종료되었을 때,\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_acc / len(dataloaders[phase].dataset)\n",
    "\n",
    "            seconds = int(time.time() - start)\n",
    "            print(f\"현재 epoch-{temp_idx}-{epoch}의 {phase}-데이터 셋에서 평균 Loss: {epoch_loss:.3f}, 평균 Accuracy: {epoch_acc:.3f}\")\n",
    "            print(f\"소요 시간: {seconds // 60}분 {seconds % 60}초\")  # 현재시각 - 시작시간 = 실행 시간\n",
    "#             print(f\"현재 epoch-{epoch}의 {phase}-데이터 셋에서 평균 Loss: {epoch_loss:.3f}, 평균 Accuracy: {epoch_acc:.3f}\")\n",
    "#             print(f\"소요 시간: {seconds // 60}분 {seconds % 60}초\")  # 현재시각 - 시작시간 = 실행 시간\n",
    "\n",
    "            # phase가 test일 때\n",
    "            if phase == \"test\":\n",
    "                # best accuracy 계산\n",
    "                if best_test_accuracy < epoch_acc:\n",
    "                    best_test_accuracy = epoch_acc\n",
    "                # best loss 계산\n",
    "                if best_test_loss > epoch_loss:\n",
    "                    best_test_loss = epoch_loss\n",
    "\n",
    "                \n",
    "seconds = int(time.time() - start)\n",
    "print(\"학습 종료!\")\n",
    "print(f\"최고 accuracy: {best_test_accuracy}, 최고 낮은 loss: {best_test_loss}\")\n",
    "print(f\"소요 시간: {seconds // 60}분 {seconds % 60}초\")  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "62f155eb-8160-4d02-85c5-57a8ca990be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    path  label\n",
      "0      input/data/train/images/000001_female_Asian_45...     10\n",
      "1      input/data/train/images/000001_female_Asian_45...      4\n",
      "2      input/data/train/images/000001_female_Asian_45...      4\n",
      "3      input/data/train/images/000001_female_Asian_45...      4\n",
      "4      input/data/train/images/000001_female_Asian_45...      4\n",
      "...                                                  ...    ...\n",
      "18042  input/data/train/images/006615_male_Asian_19/m...      0\n",
      "18043  input/data/train/images/006615_male_Asian_19/m...      0\n",
      "18044  input/data/train/images/006615_male_Asian_19/m...      0\n",
      "18045  input/data/train/images/006615_male_Asian_19/n...     12\n",
      "18047  input/data/train/images/006616_male_Asian_20/m...      0\n",
      "\n",
      "[15120 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "fe8b8b5f-b9cc-489d-a8dc-6177bd582940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[0].shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394de42a-a2b6-467f-a8fe-5657afcedd28",
   "metadata": {},
   "source": [
    "dataloader를 정의했습니다. batchsize는 64로 했고 shuffle을 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "23ac036e-abaa-4b02-93ec-98f7f93106c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/input'\n",
    "\n",
    "torch.save(resnet18, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "4b5867fb-4ace-4c4f-a078-be1d6b5ff4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=18, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3beba0d-98de-43af-9e9b-59f32bc88304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "670fead6-c072-4272-be02-d2e2861c5afc",
   "metadata": {},
   "source": [
    "검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "53b2efc1-8481-47e0-b7a2-8c7588254d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_eval(model, data_iter, device):\n",
    "    with torch.no_grad():\n",
    "        n_total, n_correct = 0, 0\n",
    "        model.eval()\n",
    "        for batch_in, batch_out in data_iter:\n",
    "            y_trgt = batch_out.to(device)\n",
    "            model_pred = model.forward(batch_in.to(device))\n",
    "            _, y_pred = torch.max(model_pred, 1)  # 행으로 비교\n",
    "            n_correct += (y_pred == y_trgt).sum().item()\n",
    "            n_total += batch_in.size(0)\n",
    "        val_acc = (n_correct/n_total)\n",
    "        #model_train()\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "18617b1f-e3fb-4f1d-b93a-e92068129850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6968253968253968"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_eval(resnet18, valid_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "262d7e91-3b25-43f5-bfdd-dbd0e73e4350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_eval(raw_data, dataloader, model, device):\n",
    "    result = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (X,y) in enumerate(dataloader):\n",
    "            model_pred = model.forward(X.to(device))\n",
    "            _, y_pred = torch.max(model_pred, 1)\n",
    "            \n",
    "            result.append([valid.iloc[i]['path'], y_pred.cpu().numpy()[0], y.cpu().numpy()[0]])\n",
    "    result = pd.DataFrame(result, columns=['path', 'pred', 'target'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "ed5019f3-d4d7-4a24-ba87-c976a5cfbb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>pred</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input/data/train/images/003997_male_Asian_59/i...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input/data/train/images/003997_male_Asian_59/m...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input/data/train/images/003997_male_Asian_59/m...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>input/data/train/images/003997_male_Asian_59/m...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>input/data/train/images/003997_male_Asian_59/m...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3775</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3776</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3777</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/n...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3780 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  pred  target\n",
       "0     input/data/train/images/003997_male_Asian_59/i...     7       7\n",
       "1     input/data/train/images/003997_male_Asian_59/m...     1       1\n",
       "2     input/data/train/images/003997_male_Asian_59/m...     1       1\n",
       "3     input/data/train/images/003997_male_Asian_59/m...     1       1\n",
       "4     input/data/train/images/003997_male_Asian_59/m...     1       1\n",
       "...                                                 ...   ...     ...\n",
       "3775  input/data/train/images/006959_male_Asian_19/m...     0       0\n",
       "3776  input/data/train/images/006959_male_Asian_19/m...     0       0\n",
       "3777  input/data/train/images/006959_male_Asian_19/m...     0       0\n",
       "3778  input/data/train/images/006959_male_Asian_19/m...     0       0\n",
       "3779  input/data/train/images/006959_male_Asian_19/n...    12      12\n",
       "\n",
       "[3780 rows x 3 columns]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_testing_dataloader = DataLoader(valid_dataset, shuffle=False)\n",
    "\n",
    "check_eval_df = check_eval(valid, valid_testing_dataloader, resnet18, device)\n",
    "check_eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a211b3d1-1a55-4bc5-94d1-e82662e81ee0",
   "metadata": {},
   "source": [
    "잘못 예측한 데이터 리스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "d12ce11e-66d9-43d1-be5c-cc4a36d7bbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>pred</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input/data/train/images/004006_male_Asian_54/m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input/data/train/images/004006_male_Asian_54/m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input/data/train/images/004006_male_Asian_54/m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>input/data/train/images/004006_male_Asian_54/m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>input/data/train/images/004006_male_Asian_54/m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>input/data/train/images/006424_female_Asian_18...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>input/data/train/images/006424_female_Asian_18...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>input/data/train/images/006424_female_Asian_18...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>input/data/train/images/006424_female_Asian_18...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>input/data/train/images/006424_female_Asian_18...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1142 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  pred  target\n",
       "0     input/data/train/images/004006_male_Asian_54/m...     0       1\n",
       "1     input/data/train/images/004006_male_Asian_54/m...     0       1\n",
       "2     input/data/train/images/004006_male_Asian_54/m...     0       1\n",
       "3     input/data/train/images/004006_male_Asian_54/m...     0       1\n",
       "4     input/data/train/images/004006_male_Asian_54/m...     0       1\n",
       "...                                                 ...   ...     ...\n",
       "1137  input/data/train/images/006424_female_Asian_18...     0       3\n",
       "1138  input/data/train/images/006424_female_Asian_18...     0       3\n",
       "1139  input/data/train/images/006424_female_Asian_18...     0       3\n",
       "1140  input/data/train/images/006424_female_Asian_18...     0       3\n",
       "1141  input/data/train/images/006424_female_Asian_18...     0       3\n",
       "\n",
       "[1142 rows x 3 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_df = check_eval_df[check_eval_df['pred'] != check_eval_df['target']]\n",
    "wrong_df = wrong_df.reset_index(drop=True)\n",
    "wrong_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067c8ef6-4b24-4e21-8b53-d64f651cbf11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "813bb94d-347c-4fbe-86ee-d07e8def980a",
   "metadata": {},
   "source": [
    "f1 score 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "6c0299e3-3b3e-45b9-935f-33ff69f97011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "500c3ff1-45cc-4e72-b9b9-31e1e5ac207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c7ebad-b00a-46d4-8537-d04ad6c321a5",
   "metadata": {},
   "source": [
    "함수 정의\n",
    "- precision, recall, f1-score, confusion matrix 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "89d2802f-43d8-4516-b4ce-ae2d69a75edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report():\n",
    "    y_test, y_pred = check_eval_df['target'], check_eval_df['pred']\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('resnet18 Accuracy:', np.mean(y_pred == y_test))\n",
    "    ax = plt.figure(figsize=(10, 5))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), linewidths=0.5, fmt='.1f', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "65f95332-f0e4-42e1-ab83-1cebbc46f381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73       554\n",
      "           1       0.92      0.49      0.64       409\n",
      "           2       1.00      0.66      0.80        83\n",
      "           3       0.55      0.99      0.71       727\n",
      "           4       0.99      0.16      0.28       818\n",
      "           5       0.94      0.57      0.71       109\n",
      "           6       0.87      1.00      0.93       111\n",
      "           7       1.00      0.73      0.85        82\n",
      "           8       0.93      0.81      0.87        16\n",
      "           9       0.77      0.99      0.86       146\n",
      "          10       0.97      0.70      0.81       163\n",
      "          11       1.00      0.36      0.53        22\n",
      "          12       0.91      1.00      0.95       111\n",
      "          13       0.93      0.79      0.85        81\n",
      "          14       0.81      0.76      0.79        17\n",
      "          15       0.80      1.00      0.89       145\n",
      "          16       0.93      0.76      0.83       164\n",
      "          17       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.70      3780\n",
      "   macro avg       0.88      0.73      0.76      3780\n",
      "weighted avg       0.81      0.70      0.65      3780\n",
      "\n",
      "resnet18 Accuracy: 0.6978835978835979\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf64055-0028-4ab5-b34f-9bf6e7e399f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4abe317e-6b21-49e6-b0f7-22cd4a7fc9e2",
   "metadata": {},
   "source": [
    "데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "8298cf4c-f313-45cd-8549-7ecae3f11cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "9f83d0ba-da1a-4058-bbf0-c4b0b0ad828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "test_dir = 'input/data/eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "b6f74389-3912-4679-85c2-ce268e266dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "# model = MyModel(num_classes=18).to(device)\n",
    "PATH = '/input'\n",
    "model = torch.load(PATH)\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "a30c7477-c27f-4857-9b8b-c87c1f02647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('input/data/eval/submission.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "69ec98e2-26fc-4d3c-add1-a8cb7f92a5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4538), (1, 1003), (2, 529), (3, 2264), (4, 483), (5, 498), (6, 493), (7, 323), (8, 201), (9, 323), (10, 223), (11, 44), (12, 486), (13, 240), (14, 338), (15, 320), (16, 254), (17, 40)]\n"
     ]
    }
   ],
   "source": [
    "classes = dict()\n",
    "\n",
    "for cla in test_data['ans']:\n",
    "    if cla in classes:\n",
    "        classes[cla] += 1\n",
    "    else:\n",
    "        classes[cla] = 1\n",
    "        \n",
    "classes = sorted(classes.items())\n",
    "print(classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
