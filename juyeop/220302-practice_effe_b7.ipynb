{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31b9b979-b5a6-4d6c-82b6-1658ef6d60ff",
   "metadata": {},
   "source": [
    "pretrained model : resnet18\n",
    "\n",
    "loss_fn : CrossEntropyLoss\n",
    "\n",
    "optimizer : adam\n",
    "\n",
    "epoch: 5\n",
    "\n",
    "batch-size : 32\n",
    "\n",
    "data augmentation : transforms.RandomHorizontalFlip(),\n",
    "\n",
    "fc layer : relu\n",
    "\n",
    "lr : 0.0001\n",
    "\n",
    "Normalized : (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a7524-0967-4449-8505-52dd527c72e2",
   "metadata": {},
   "source": [
    " + alpha(더 시도해볼 것들)\n",
    "\n",
    "seresnet50\n",
    "\n",
    "epoch 증가 (거의 더 좋을 듯)\n",
    "\n",
    "Normalized mean, std값 조정 -> 완료\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2f7f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler\n",
    "\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e82372af-e478-4dae-a283-f792958f76f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = 'input/data/train'\n",
    "train_image_dir_path = os.path.join(train_path, 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c19bf-2d75-400f-9bb7-7b1ee5540ebc",
   "metadata": {},
   "source": [
    "이하 CUDA out of memory. Tried to allocate 1.50 GiB (GPU 0; 31.75 GiB total capacity; 5.97 GiB already allocated; 1.23 GiB free; 6.98 GiB reserved in total by PyTorch)\n",
    "\n",
    "떴을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59a4f72e-5177-427c-8365-b571fde9b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e84dc1-18eb-4592-bd15-330007a90b01",
   "metadata": {},
   "source": [
    "Dataset 생성\n",
    "\n",
    "모든 train data의 path를 가져와 라벨링 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "040577b9-a2c5-4516-a5fd-b1f3ae11d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(dirname, result): # 하위 목록의 모든 파일을 찾는 함수\n",
    "    try:\n",
    "        filenames = os.listdir(dirname)\n",
    "        for filename in filenames:\n",
    "            if filename[0] == '.': # .으로 시작하는 애들 거름\n",
    "                continue\n",
    "            full_filename = os.path.join(dirname, filename)\n",
    "            if os.path.isdir(full_filename):\n",
    "                search(full_filename, result)\n",
    "            else:\n",
    "                ext = os.path.splitext(full_filename)[-1] # 확장자 체크\n",
    "                if ext:\n",
    "                    result.append(full_filename)\n",
    "        \n",
    "    except PermissionError:\n",
    "        print('Permission Error')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e40f2b1-7abe-49e1-abda-701cb6025934",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_path = list()\n",
    "search(train_image_dir_path, all_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3455a861-4429-4243-898c-b3f2e4186942",
   "metadata": {},
   "source": [
    "train의 데이터 디렉토리는 2700개로, 각각의 이미지 파일(incorrect, mask1~5, normal)을 곱한 갯수가 나옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba63e19e-6978-4785-921e-44a58757f838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18900"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_path) # 2700 * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff701504-72d2-44d0-8e2e-82ac0964e1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input/data/train/images/001752_male_Asian_53/mask5.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/mask4.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/mask2.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/mask3.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/normal.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/mask1.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/incorrect_mask.jpg',\n",
       " 'input/data/train/images/005127_female_Asian_51/mask5.jpg',\n",
       " 'input/data/train/images/005127_female_Asian_51/mask4.jpg',\n",
       " 'input/data/train/images/005127_female_Asian_51/mask2.jpg']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_path[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8726c41-ba96-408b-9e65-10bcab850853",
   "metadata": {},
   "source": [
    "파일의 확장자는 jpg, png, jpeg로 3종류가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b45de68-c50e-435b-853b-5e95fba44852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.jpg', '.png', '.jpeg']\n"
     ]
    }
   ],
   "source": [
    "exts = list()\n",
    "for word in all_path:\n",
    "    ext = os.path.splitext(word)[-1]\n",
    "    if ext not in exts:\n",
    "        exts.append(ext)\n",
    "print(exts) # jpg, png, jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f205b726-45fc-4d95-b3d0-fef15a7ecf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_path = sorted(all_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e47982-6d3f-4677-abfe-e9997e699876",
   "metadata": {},
   "source": [
    "라벨링을 하는 함수입니다. 조건에 따라 label에 숫자를 더해주는 식으로 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "370658c3-e841-4e0d-809b-c53d00cd9337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(name):\n",
    "    label = 0\n",
    "    info, mask_type = name.split('/')[-2:]\n",
    "    info = info.split('_')\n",
    "    gender, age = info[1], int(info[3])\n",
    "    \n",
    "    # 마스크 구별\n",
    "    if 'incorrect' in mask_type:\n",
    "        label += 6\n",
    "    elif 'normal' in mask_type:\n",
    "        label += 12\n",
    "    \n",
    "    # gender 구별\n",
    "    if gender == 'female':\n",
    "        label += 3\n",
    "    \n",
    "    # 나이 구별\n",
    "    if 30 <= age and age < 60:\n",
    "        label += 1\n",
    "    elif age >= 60:\n",
    "        label += 2\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c06615-2768-4cfd-9026-6105537d0dcb",
   "metadata": {},
   "source": [
    "path, label을 컬럼으로 갖는 dataframe을 생성해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0a01df2-a77e-4390-8a42-9465893317fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18895</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18896</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18897</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18898</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18899</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/n...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18900 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path  label\n",
       "0      input/data/train/images/000001_female_Asian_45...     10\n",
       "1      input/data/train/images/000001_female_Asian_45...      4\n",
       "2      input/data/train/images/000001_female_Asian_45...      4\n",
       "3      input/data/train/images/000001_female_Asian_45...      4\n",
       "4      input/data/train/images/000001_female_Asian_45...      4\n",
       "...                                                  ...    ...\n",
       "18895  input/data/train/images/006959_male_Asian_19/m...      0\n",
       "18896  input/data/train/images/006959_male_Asian_19/m...      0\n",
       "18897  input/data/train/images/006959_male_Asian_19/m...      0\n",
       "18898  input/data/train/images/006959_male_Asian_19/m...      0\n",
       "18899  input/data/train/images/006959_male_Asian_19/n...     12\n",
       "\n",
       "[18900 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path_label = pd.DataFrame(all_path, columns = ['path'])\n",
    "\n",
    "train_path_label['label'] = train_path_label['path'].map(lambda x: labeling(x))\n",
    "train_path_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "897da325-d4df-495c-937c-d195424edb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path_label.to_csv('./train_path_label.csv', index=False, encoding='utf-8')\n",
    "# train_path_label = pd.read_csv('./train_path_label.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee45d570-0645-4bd1-9623-797a0a287648",
   "metadata": {},
   "source": [
    "dataset을 상속받아 만든 CustomDataset입니다. transform은 size를 [512, 384]로 변형하고, Tensor로 만들고, 정규화를 해주었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfa99111-9bb5-4f27-b062-956f1b61d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_paths_label, transform):\n",
    "        self.X = img_paths_label['path']\n",
    "        self.y = img_paths_label['label']\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.X.iloc[index])\n",
    "        label = self.y.iloc[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74229d34-afe4-49b3-a84c-93885000beef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    ToTensor(),\n",
    "#     Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1da396-de7c-46e3-b4a7-9d3a47bee7d2",
   "metadata": {},
   "source": [
    "train, valid를 나누는 부분입니다.\n",
    "\n",
    "label의 비율을 유지하면서 나눴습니다.\n",
    "\n",
    "+ 기존 방법 대신StratifiedKFold 사용을 시도했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f983476-59fd-485c-b5bd-a3755af6cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# train, valid = train_test_split(train_path_label, test_size=0.2,\n",
    "#                                shuffle=True, stratify=train_path_label['label'],\n",
    "#                                random_state=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53192a6-95ba-431b-80c7-85b820aab853",
   "metadata": {},
   "source": [
    "DataLoader\n",
    "- index를 사용한 Dataloader 정의\n",
    "- getDataloader 함수 설명\n",
    "    1. Pytorch Dataset, train 인덱스, valid 인덱스, batch size를 전달받아 Train, Valid DataLoader 객체를 반환합니다.\n",
    "    2. torch.utils.data.Subset 객체는 데이터셋과 해당 데이터셋의 인덱스를 전달받아 Subset 객체를 생성합니다. 생성한 Subset 객체를 사용해 DataLoader 객체를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d5e3ee2-3afe-469d-b248-27b77e87d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataloader(dataset, train_idx, valid_idx, batch_size, num_workers):\n",
    "    # 인자로 전달받은 dataset에서 train_idx에 해당하는 Subset 추출\n",
    "    train_set = torch.utils.data.Subset(dataset,\n",
    "                                        indices=train_idx)\n",
    "    # 인자로 전달받은 dataset에서 valid_idx에 해당하는 Subset 추출\n",
    "    val_set   = torch.utils.data.Subset(dataset,\n",
    "                                        indices=valid_idx)\n",
    "    \n",
    "    # 추출된 Train Subset으로 DataLoader 생성\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "    # 추출된 Valid Subset으로 DataLoader 생성\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # 생성한 DataLoader 반환\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44331d5-b6ae-403d-b3b1-c76a7758d53e",
   "metadata": {},
   "source": [
    "dataloader를 정의했습니다. batchsize는 64로 했고 shuffle을 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ec86e71c-2975-47b0-bd06-28df82c791e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01bfaea4-9ff5-42c4-af4f-1f584af88e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(train_path_label, transform)\n",
    "\n",
    "custom_dataloader = DataLoader(dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=True\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e466688b-3615-422b-ad07-821a8d6c491d",
   "metadata": {},
   "source": [
    "모델\n",
    "\n",
    "모델은 pretrain된 resnet18을 가져왔습니다. 이 모델의 마지막 fc층만 저희의 과제인 18개의 class로 변경해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea56b314-d7c6-4a37-adab-4f45504a51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f49a2e49-e24d-4e1c-8ce7-9be3193a40ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = torchvision.models.efficientnet_b7(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c96c451d-9390-4809-a6c4-d4ab199d120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output 18개로\n",
    "IN_FEATURES = my_model.classifier[1].in_features\n",
    "\n",
    "OUTPUT_CLASS_NUM = 18\n",
    "my_model.classifier[1] = torch.nn.Linear(in_features = IN_FEATURES, out_features = OUTPUT_CLASS_NUM, bias=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f299509a-d3f8-47b7-9657-e6397a767c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "OUTPUT_CLASS_NUM = 18\n",
    "my_model.fc = torch.nn.Linear(in_features=512, out_features=OUTPUT_CLASS_NUM, bias=True) # output 18개로\n",
    "\n",
    "# xavier uniform\n",
    "torch.nn.init.xavier_uniform_(my_model.fc.weight)\n",
    "stdv = 1. / math.sqrt(my_model.fc.weight.size(1))\n",
    "my_model.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "my_model.fc.weight.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1cbcaf2d-53ec-4b36-bb78-c7df4c74a3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "911b6054-9b4b-4a0e-bfc6-b56575293620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73604167-7ab2-49be-9daa-e7a3a4ba1953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # my_model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# import timm\n",
    "# my_model = timm.create_model('resnet50', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "998b8581-1351-4a2c-aba4-08a74c4a17b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "\n",
    "# OUTPUT_CLASS_NUM = 18\n",
    "# print(my_model.fc)\n",
    "# num_ftrs = my_model.fc.in_features\n",
    "# print(num_ftrs)\n",
    "# # my_model.fc = torch.nn.Linear(in_features=num_ftrs, out_features=OUTPUT_CLASS_NUM, bias=True) # output 18개로\n",
    "\n",
    "# my_model.fc = nn.Sequential(\n",
    "#                    nn.Linear(num_ftrs, 512),\n",
    "#                    nn.ReLU(inplace=True),\n",
    "#                    nn.Dropout(0.2),\n",
    "#                    nn.Linear(512, 512),\n",
    "#                    nn.ReLU(inplace=True),\n",
    "#                    nn.Dropout(0.2),\n",
    "#                    nn.Linear(512, OUTPUT_CLASS_NUM)\n",
    "#                 ).to(device)\n",
    "\n",
    "# # Linear, ReLU, Dropout 넣기\n",
    "\n",
    "# # num_ftrs = my_model.fc.in_features\n",
    "# # my_model.classifier = nn.Sequential(\n",
    "# #     nn.Linear(512 * 7 * 7, 4096),\n",
    "# #     nn.ReLU(True),\n",
    "# #     nn.Dropout(p=0.2),\n",
    "# #     nn.Linear(4096, 4096),\n",
    "# #     nn.ReLU(True),\n",
    "# #     nn.Dropout(p=0.2),\n",
    "# #     nn.Linear(4096, OUTPUT_CLASS_NUM),\n",
    "# # )\n",
    "\n",
    "\n",
    "\n",
    "# # xavier uniform\n",
    "# for i in range(0, len(my_model.fc), 3):\n",
    "#     torch.nn.init.xavier_uniform_(my_model.fc[i].weight)\n",
    "#     stdv = 1. / math.sqrt(my_model.fc[i].weight.size(1))\n",
    "#     my_model.fc[i].bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "# my_model.fc[-1].weight.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072cbb59-b947-422e-b685-0ae3b43a4f91",
   "metadata": {},
   "source": [
    "다음 코드를 참고하세요.\n",
    "- pre-trained model에 원하는 함수 추가\n",
    "- 입력값 모를 때 자동으로 계산해서 넣는 법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd2aaf69-6d40-4186-bd68-9f0f6f7ef295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-trained model에 원하는 함수 추가\n",
    "\n",
    "# num_classes = 18\n",
    "# model = vgg19_bn(pretrained=True)\n",
    "# model.classifier = nn.Sequential(\n",
    "#     nn.Linear(512 * 7 * 7, 4096),\n",
    "#     nn.ReLU(True),\n",
    "#     nn.Dropout(),\n",
    "#     nn.Linear(4096, 4096),\n",
    "#     nn.ReLU(True),\n",
    "#     nn.Dropout(),\n",
    "#     nn.Linear(4096, num_classes),\n",
    "# )\n",
    "\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a941f7f-4688-4a62-936b-16bee0cacfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력값 모를 때 넣는 법\n",
    "\n",
    "# model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "# num_ftrs = model_conv.fc.in_features\n",
    "# model_conv.fc = nn.Linear(num_ftrs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4d8956a1-6f32-414d-9461-c8186523317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의로 둘을 합쳐봄\n",
    "\n",
    "# from torchvision.models import vgg19_bn\n",
    "\n",
    "# OUTPUT_CLASS_NUM = 18\n",
    "# model = vgg19_bn(pretrained=True)\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.classifier = nn.Sequential(\n",
    "#     nn.Linear(num_ftrs, 512),\n",
    "#     nn.ReLU(True),\n",
    "#     nn.Dropout(p=0.2),\n",
    "#     nn.Linear(512, 512),\n",
    "#     nn.ReLU(True),\n",
    "#     nn.Dropout(p=0.2),\n",
    "#     nn.Linear(512, OUTPUT_CLASS_NUM),\n",
    "# )\n",
    "\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89442b2-35cf-4384-9d18-18481d60f01a",
   "metadata": {},
   "source": [
    "아래 대부분의 코드가 부스트캠프에서 학습 자료나 과제로 제공받았던 코드를 거의 그대로 사용했습니다.\n",
    "\n",
    "설명도 주석도 잘 달려 있어서 그대로 가져왔습니다.\n",
    "\n",
    "epoch는 5, lr은 0.0001로 주었습니다.\n",
    "\n",
    "추후에 lr scheduler로 lr을 변경해보는 방법도 좋을 것 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe33dbb7-a718-4d57-b51c-79961d4ab129",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.to(device)\n",
    "\n",
    "LEARNING_RATE = 0.0001 # 학습 때 사용하는 optimizer의 학습률 옵션 설정\n",
    "NUM_EPOCH = 5 # 학습 때 mnist train data set을 얼마나 많이 학습할 지 결정하는 옵션\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss() # 분류 학습 때 많이 사용되는 Cross Entropy Loss를 objective function으로 사용\n",
    "# loss_fn = torch.nn.NLLLoss() # VGG\n",
    "optimizer = torch.optim.Adam(my_model.parameters(), lr=LEARNING_RATE) # weight 업데이트를 위한 optimizer를 Adam으로 사용함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57d55cbe-9d85-4c5d-9ac0-12b8f9b09ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    path  label\n",
      "0      input/data/train/images/000001_female_Asian_45...     10\n",
      "1      input/data/train/images/000001_female_Asian_45...      4\n",
      "2      input/data/train/images/000001_female_Asian_45...      4\n",
      "3      input/data/train/images/000001_female_Asian_45...      4\n",
      "4      input/data/train/images/000001_female_Asian_45...      4\n",
      "...                                                  ...    ...\n",
      "18895  input/data/train/images/006959_male_Asian_19/m...      0\n",
      "18896  input/data/train/images/006959_male_Asian_19/m...      0\n",
      "18897  input/data/train/images/006959_male_Asian_19/m...      0\n",
      "18898  input/data/train/images/006959_male_Asian_19/m...      0\n",
      "18899  input/data/train/images/006959_male_Asian_19/n...     12\n",
      "\n",
      "[18900 rows x 2 columns]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 31.75 GiB total capacity; 1.06 GiB already allocated; 32.50 MiB free; 1.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-05de6f5b4644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;31m# train 모드일 시에는 gradient를 계산하고, 아닐 때는 gradient를 계산하지 않아 연산량 최소화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                     \u001b[0;31m# 모델에서 linear 값으로 나오는 예측 값([0.9, 1.2, 3.2, 0.1, -0.1, ...])에서 최대 output index를 찾아 예측 레이블([2])로 변경함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msilu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1896\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 31.75 GiB total capacity; 1.06 GiB already allocated; 32.50 MiB free; 1.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# 5-fold Stratified KFold 5개의 fold를 형성하고 5번 Cross Validation을 진행합니다.\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "best_test_accuracy = 0.\n",
    "best_test_loss = 9999.\n",
    "start = time.time()  # 시작 시간 저장\n",
    "\n",
    "# skf 설정\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "# kfold = KFold(n_splits=4, shuffle=False)\n",
    "\n",
    "# skf에서 사용할 labels 설정\n",
    "labels = [i for i in train_path_label['label']]\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 4\n",
    "\n",
    "print(train_path_label)\n",
    "temp_idx = 0\n",
    "for train_index, validate_index in skf.split(train_path_label, labels):\n",
    "#     print(train_index, validate_index)\n",
    "    temp_idx += 1\n",
    "    train = train_path_label.iloc[train_index]\n",
    "    valid = train_path_label.iloc[validate_index]\n",
    "\n",
    "    train_dataset = CustomDataset(train, transform)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset,\n",
    "                                 batch_size=BATCH_SIZE,\n",
    "                                 shuffle=False\n",
    "                                 )\n",
    "\n",
    "    valid_dataset = CustomDataset(valid, transform)\n",
    "\n",
    "    valid_dataloader = DataLoader(valid_dataset,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=False)\n",
    "\n",
    "    dataloaders = {\n",
    "        \"train\": train_dataloader,\n",
    "        \"test\": valid_dataloader,\n",
    "    }\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "\n",
    "        for phase in [\"train\", \"test\"]:\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "#             # 네트워크 모델을 train 모드로 두어 gradient를 계산하고, \n",
    "#             # 여러 sub module (배치 정규화, 드롭아웃 등)이 train_mode로 작동할 수 있게 함.\n",
    "            if phase == \"train\":\n",
    "                my_model.train()\n",
    "            # 네트워크 모델을 eval 모드로 두어 여러 sub module들이 eval mode로 작동할 수 있게 함.\n",
    "            elif phase == \"test\":\n",
    "                my_model.eval()\n",
    "            \n",
    "            for ind, (images, labels) in enumerate(dataloaders[phase]):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad() # parameter gradient를 업데이트 전 초기화함.\n",
    "\n",
    "                # train 모드일 시에는 gradient를 계산하고, 아닐 때는 gradient를 계산하지 않아 연산량 최소화\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    logits = my_model(images)\n",
    "                    # 모델에서 linear 값으로 나오는 예측 값([0.9, 1.2, 3.2, 0.1, -0.1, ...])에서 최대 output index를 찾아 예측 레이블([2])로 변경함\n",
    "                    _, preds = torch.max(logits, 1)\n",
    "                    loss = loss_fn(logits, labels)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward() # 모델의 예측 값과 실제 값의 CrossEntropy 차이를 통해 gradient를 계산\n",
    "                        optimizer.step() # 계산된 gradient를 가지고 모델 업데이트\n",
    "\n",
    "                running_loss += loss.item() * images.size(0) # 한 Batch에서의 loss 값 저장\n",
    "                running_acc += torch.sum(preds == labels.data) # 한 Batch에서의 Accuracy 값 저장\n",
    "\n",
    "            # 한 epoch이 모두 종료되었을 때,\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_acc / len(dataloaders[phase].dataset)\n",
    "\n",
    "            seconds = int(time.time() - start)\n",
    "            print(f\"현재 epoch-{temp_idx}-{epoch}의 {phase}-데이터 셋에서 평균 Loss: {epoch_loss:.3f}, 평균 Accuracy: {epoch_acc:.3f}\")\n",
    "            print(f\"소요 시간: {seconds // 60}분 {seconds % 60}초\")  # 현재시각 - 시작시간 = 실행 시간\n",
    "#             print(f\"현재 epoch-{epoch}의 {phase}-데이터 셋에서 평균 Loss: {epoch_loss:.3f}, 평균 Accuracy: {epoch_acc:.3f}\")\n",
    "#             print(f\"소요 시간: {seconds // 60}분 {seconds % 60}초\")  # 현재시각 - 시작시간 = 실행 시간\n",
    "\n",
    "            # phase가 test일 때\n",
    "            if phase == \"test\":\n",
    "                # best accuracy 계산\n",
    "                if best_test_accuracy < epoch_acc:\n",
    "                    best_test_accuracy = epoch_acc\n",
    "                # best loss 계산\n",
    "                if best_test_loss > epoch_loss:\n",
    "                    best_test_loss = epoch_loss\n",
    "\n",
    "                \n",
    "seconds = int(time.time() - start)\n",
    "print(\"학습 종료!\")\n",
    "print(f\"최고 accuracy: {best_test_accuracy}, 최고 낮은 loss: {best_test_loss}\")\n",
    "print(f\"소요 시간: {seconds // 60}분 {seconds % 60}초\")  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f155eb-8160-4d02-85c5-57a8ca990be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b8b5f-b9cc-489d-a8dc-6177bd582940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[0].shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394de42a-a2b6-467f-a8fe-5657afcedd28",
   "metadata": {},
   "source": [
    "dataloader를 정의했습니다. batchsize는 64로 했고 shuffle을 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac036e-abaa-4b02-93ec-98f7f93106c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/input'\n",
    "\n",
    "torch.save(my_model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5867fb-4ace-4c4f-a078-be1d6b5ff4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3beba0d-98de-43af-9e9b-59f32bc88304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "670fead6-c072-4272-be02-d2e2861c5afc",
   "metadata": {},
   "source": [
    "검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b2efc1-8481-47e0-b7a2-8c7588254d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_eval(model, data_iter, device):\n",
    "    with torch.no_grad():\n",
    "        n_total, n_correct = 0, 0\n",
    "        model.eval()\n",
    "        for batch_in, batch_out in data_iter:\n",
    "            y_trgt = batch_out.to(device)\n",
    "            model_pred = model.forward(batch_in.to(device))\n",
    "            _, y_pred = torch.max(model_pred, 1)  # 행으로 비교\n",
    "            n_correct += (y_pred == y_trgt).sum().item()\n",
    "            n_total += batch_in.size(0)\n",
    "        val_acc = (n_correct/n_total)\n",
    "        #model_train()\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18617b1f-e3fb-4f1d-b93a-e92068129850",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_eval(my_model, valid_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262d7e91-3b25-43f5-bfdd-dbd0e73e4350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_eval(raw_data, dataloader, model, device):\n",
    "    result = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (X,y) in enumerate(dataloader):\n",
    "            model_pred = model.forward(X.to(device))\n",
    "            _, y_pred = torch.max(model_pred, 1)\n",
    "            \n",
    "            result.append([valid.iloc[i]['path'], y_pred.cpu().numpy()[0], y.cpu().numpy()[0]])\n",
    "    result = pd.DataFrame(result, columns=['path', 'pred', 'target'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5019f3-d4d7-4a24-ba87-c976a5cfbb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_testing_dataloader = DataLoader(valid_dataset, shuffle=False)\n",
    "\n",
    "check_eval_df = check_eval(valid, valid_testing_dataloader, my_model, device)\n",
    "check_eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a211b3d1-1a55-4bc5-94d1-e82662e81ee0",
   "metadata": {},
   "source": [
    "잘못 예측한 데이터 리스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12ce11e-66d9-43d1-be5c-cc4a36d7bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_df = check_eval_df[check_eval_df['pred'] != check_eval_df['target']]\n",
    "wrong_df = wrong_df.reset_index(drop=True)\n",
    "wrong_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502faa33-ea25-4485-a905-b2cc01dafbef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ca21b8-d14c-48fd-8fd7-8e859710dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = [[['wear'], ['male'], ['un30']], [['wear'], ['male'], ['3060']], [['wear'], ['male'], ['ov60']],\n",
    "              [['wear'], ['fema'], ['un30']], [['wear'], ['fema'], ['3060']], [['wear'], ['fema'], ['ov60']],\n",
    "              [['Inco'], ['male'], ['un30']], [['Inco'], ['male'], ['3060']], [['Inco'], ['male'], ['ov60']],\n",
    "              [['Inco'], ['fema'], ['un30']], [['Inco'], ['fema'], ['3060']], [['Inco'], ['fema'], ['ov60']],\n",
    "              [['NoWe'], ['male'], ['un30']], [['NoWe'], ['male'], ['3060']], [['NoWe'], ['male'], ['ov60']],\n",
    "              [['NoWe'], ['fema'], ['un30']], [['NoWe'], ['fema'], ['3060']], [['NoWe'], ['fema'], ['ov60']]\n",
    "             ]\n",
    "\n",
    "def draw_(df):\n",
    "    plt.figure(figsize = (15, 30))\n",
    "    row = len(wrong_df) // 3\n",
    "    # 틀린 번호 찾기\n",
    "    wrong_number = list()\n",
    "    for df_path in list(df['path']):\n",
    "        wrong_number.append(df_path.split('/')[4].split('_')[0])\n",
    "        \n",
    "    for i in range(df.shape[0]):\n",
    "        plt.subplot(row + 1, df.shape[0] // row, i + 1)\n",
    "        plt.imshow(Image.open(df['path'][i]))\n",
    "        plt.title(f\"target:{class_list[df['target'][i]]}, \\n pred: {class_list[df['pred'][i]]} \\n id: {wrong_number[i]}\", color='r', size=20)\n",
    "        plt.axis('off')\n",
    "    print(df)\n",
    "    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a326e-3fc6-4f28-aeb2-92964bc142db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wrong_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067c8ef6-4b24-4e21-8b53-d64f651cbf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_(wrong_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813bb94d-347c-4fbe-86ee-d07e8def980a",
   "metadata": {},
   "source": [
    "f1 score 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0299e3-3b3e-45b9-935f-33ff69f97011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500c3ff1-45cc-4e72-b9b9-31e1e5ac207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c7ebad-b00a-46d4-8537-d04ad6c321a5",
   "metadata": {},
   "source": [
    "함수 정의\n",
    "- precision, recall, f1-score, confusion matrix 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d2802f-43d8-4516-b4ce-ae2d69a75edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report():\n",
    "    y_test, y_pred = check_eval_df['target'], check_eval_df['pred']\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('my_model Accuracy:', np.mean(y_pred == y_test))\n",
    "    ax = plt.figure(figsize=(10, 5))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), linewidths=0.5, fmt='.1f', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f95332-f0e4-42e1-ab83-1cebbc46f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf64055-0028-4ab5-b34f-9bf6e7e399f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4abe317e-6b21-49e6-b0f7-22cd4a7fc9e2",
   "metadata": {},
   "source": [
    "데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8298cf4c-f313-45cd-8549-7ecae3f11cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f83d0ba-da1a-4058-bbf0-c4b0b0ad828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "test_dir = 'input/data/eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f74389-3912-4679-85c2-ce268e266dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    ToTensor(),\n",
    "#     Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "\n",
    "])\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "# model = MyModel(num_classes=18).to(device)\n",
    "PATH = '/input'\n",
    "model = torch.load(PATH)\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c7477-c27f-4857-9b8b-c87c1f02647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('input/data/eval/submission.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ec98e2-26fc-4d3c-add1-a8cb7f92a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = dict()\n",
    "\n",
    "for cla in test_data['ans']:\n",
    "    if cla in classes:\n",
    "        classes[cla] += 1\n",
    "    else:\n",
    "        classes[cla] = 1\n",
    "        \n",
    "classes = sorted(classes.items())\n",
    "print(classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
