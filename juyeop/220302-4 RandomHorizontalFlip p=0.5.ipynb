{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31b9b979-b5a6-4d6c-82b6-1658ef6d60ff",
   "metadata": {},
   "source": [
    "pretrained model : resnet18\n",
    "\n",
    "loss_fn : CrossEntropyLoss\n",
    "\n",
    "optimizer : adam\n",
    "\n",
    "epoch: 5\n",
    "\n",
    "batch-size : 32\n",
    "\n",
    "data augmentation : transforms.RandomHorizontalFlip(),\n",
    "\n",
    "fc layer : relu\n",
    "\n",
    "lr : 0.0001\n",
    "\n",
    "Normalized : (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a7524-0967-4449-8505-52dd527c72e2",
   "metadata": {},
   "source": [
    " + alpha(더 시도해볼 것들)\n",
    "\n",
    "seresnet50\n",
    "\n",
    "epoch 증가 (거의 더 좋을 듯)\n",
    "\n",
    "Normalized mean, std값 조정 -> 완료\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f7f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler\n",
    "\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e82372af-e478-4dae-a283-f792958f76f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = 'input/data/train'\n",
    "train_image_dir_path = os.path.join(train_path, 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c19bf-2d75-400f-9bb7-7b1ee5540ebc",
   "metadata": {},
   "source": [
    "이하 CUDA out of memory. Tried to allocate 1.50 GiB (GPU 0; 31.75 GiB total capacity; 5.97 GiB already allocated; 1.23 GiB free; 6.98 GiB reserved in total by PyTorch)\n",
    "\n",
    "떴을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a4f72e-5177-427c-8365-b571fde9b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e84dc1-18eb-4592-bd15-330007a90b01",
   "metadata": {},
   "source": [
    "Dataset 생성\n",
    "\n",
    "모든 train data의 path를 가져와 라벨링 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "040577b9-a2c5-4516-a5fd-b1f3ae11d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(dirname, result): # 하위 목록의 모든 파일을 찾는 함수\n",
    "    try:\n",
    "        filenames = os.listdir(dirname)\n",
    "        for filename in filenames:\n",
    "            if filename[0] == '.': # .으로 시작하는 애들 거름\n",
    "                continue\n",
    "            full_filename = os.path.join(dirname, filename)\n",
    "            if os.path.isdir(full_filename):\n",
    "                search(full_filename, result)\n",
    "            else:\n",
    "                ext = os.path.splitext(full_filename)[-1] # 확장자 체크\n",
    "                if ext:\n",
    "                    result.append(full_filename)\n",
    "        \n",
    "    except PermissionError:\n",
    "        print('Permission Error')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e40f2b1-7abe-49e1-abda-701cb6025934",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_path = list()\n",
    "search(train_image_dir_path, all_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3455a861-4429-4243-898c-b3f2e4186942",
   "metadata": {},
   "source": [
    "train의 데이터 디렉토리는 2700개로, 각각의 이미지 파일(incorrect, mask1~5, normal)을 곱한 갯수가 나옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba63e19e-6978-4785-921e-44a58757f838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18900"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_path) # 2700 * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff701504-72d2-44d0-8e2e-82ac0964e1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input/data/train/images/001752_male_Asian_53/mask5.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/mask4.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/mask2.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/mask3.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/normal.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/mask1.jpg',\n",
       " 'input/data/train/images/001752_male_Asian_53/incorrect_mask.jpg',\n",
       " 'input/data/train/images/005127_female_Asian_51/mask5.jpg',\n",
       " 'input/data/train/images/005127_female_Asian_51/mask4.jpg',\n",
       " 'input/data/train/images/005127_female_Asian_51/mask2.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_path[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8726c41-ba96-408b-9e65-10bcab850853",
   "metadata": {},
   "source": [
    "파일의 확장자는 jpg, png, jpeg로 3종류가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b45de68-c50e-435b-853b-5e95fba44852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.jpg', '.png', '.jpeg']\n"
     ]
    }
   ],
   "source": [
    "exts = list()\n",
    "for word in all_path:\n",
    "    ext = os.path.splitext(word)[-1]\n",
    "    if ext not in exts:\n",
    "        exts.append(ext)\n",
    "print(exts) # jpg, png, jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f205b726-45fc-4d95-b3d0-fef15a7ecf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_path = sorted(all_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e47982-6d3f-4677-abfe-e9997e699876",
   "metadata": {},
   "source": [
    "라벨링을 하는 함수입니다. 조건에 따라 label에 숫자를 더해주는 식으로 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "370658c3-e841-4e0d-809b-c53d00cd9337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(name):\n",
    "    label = 0\n",
    "    info, mask_type = name.split('/')[-2:]\n",
    "    info = info.split('_')\n",
    "    gender, age = info[1], int(info[3])\n",
    "    \n",
    "    # 마스크 구별\n",
    "    if 'incorrect' in mask_type:\n",
    "        label += 6\n",
    "    elif 'normal' in mask_type:\n",
    "        label += 12\n",
    "    \n",
    "    # gender 구별\n",
    "    if gender == 'female':\n",
    "        label += 3\n",
    "    \n",
    "    # 나이 구별\n",
    "    if 30 <= age and age < 60:\n",
    "        label += 1\n",
    "    elif age >= 60:\n",
    "        label += 2\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c06615-2768-4cfd-9026-6105537d0dcb",
   "metadata": {},
   "source": [
    "path, label을 컬럼으로 갖는 dataframe을 생성해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0a01df2-a77e-4390-8a42-9465893317fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>input/data/train/images/000001_female_Asian_45...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18895</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18896</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18897</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18898</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18899</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/n...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18900 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path  label\n",
       "0      input/data/train/images/000001_female_Asian_45...     10\n",
       "1      input/data/train/images/000001_female_Asian_45...      4\n",
       "2      input/data/train/images/000001_female_Asian_45...      4\n",
       "3      input/data/train/images/000001_female_Asian_45...      4\n",
       "4      input/data/train/images/000001_female_Asian_45...      4\n",
       "...                                                  ...    ...\n",
       "18895  input/data/train/images/006959_male_Asian_19/m...      0\n",
       "18896  input/data/train/images/006959_male_Asian_19/m...      0\n",
       "18897  input/data/train/images/006959_male_Asian_19/m...      0\n",
       "18898  input/data/train/images/006959_male_Asian_19/m...      0\n",
       "18899  input/data/train/images/006959_male_Asian_19/n...     12\n",
       "\n",
       "[18900 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path_label = pd.DataFrame(all_path, columns = ['path'])\n",
    "\n",
    "train_path_label['label'] = train_path_label['path'].map(lambda x: labeling(x))\n",
    "train_path_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "897da325-d4df-495c-937c-d195424edb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path_label.to_csv('./train_path_label.csv', index=False, encoding='utf-8')\n",
    "# train_path_label = pd.read_csv('./train_path_label.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee45d570-0645-4bd1-9623-797a0a287648",
   "metadata": {},
   "source": [
    "dataset을 상속받아 만든 CustomDataset입니다. transform은 size를 [512, 384]로 변형하고, Tensor로 만들고, 정규화를 해주었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfa99111-9bb5-4f27-b062-956f1b61d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_paths_label, transform):\n",
    "        self.X = img_paths_label['path']\n",
    "        self.y = img_paths_label['label']\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.X.iloc[index])\n",
    "        label = self.y.iloc[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74229d34-afe4-49b3-a84c-93885000beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    ToTensor(),\n",
    "#     Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1da396-de7c-46e3-b4a7-9d3a47bee7d2",
   "metadata": {},
   "source": [
    "train, valid를 나누는 부분입니다.\n",
    "\n",
    "label의 비율을 유지하면서 나눴습니다.\n",
    "\n",
    "+ 기존 방법 대신StratifiedKFold 사용을 시도했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f983476-59fd-485c-b5bd-a3755af6cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# train, valid = train_test_split(train_path_label, test_size=0.2,\n",
    "#                                shuffle=True, stratify=train_path_label['label'],\n",
    "#                                random_state=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53192a6-95ba-431b-80c7-85b820aab853",
   "metadata": {},
   "source": [
    "DataLoader\n",
    "- index를 사용한 Dataloader 정의\n",
    "- getDataloader 함수 설명\n",
    "    1. Pytorch Dataset, train 인덱스, valid 인덱스, batch size를 전달받아 Train, Valid DataLoader 객체를 반환합니다.\n",
    "    2. torch.utils.data.Subset 객체는 데이터셋과 해당 데이터셋의 인덱스를 전달받아 Subset 객체를 생성합니다. 생성한 Subset 객체를 사용해 DataLoader 객체를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d5e3ee2-3afe-469d-b248-27b77e87d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataloader(dataset, train_idx, valid_idx, batch_size, num_workers):\n",
    "    # 인자로 전달받은 dataset에서 train_idx에 해당하는 Subset 추출\n",
    "    train_set = torch.utils.data.Subset(dataset,\n",
    "                                        indices=train_idx)\n",
    "    # 인자로 전달받은 dataset에서 valid_idx에 해당하는 Subset 추출\n",
    "    val_set   = torch.utils.data.Subset(dataset,\n",
    "                                        indices=valid_idx)\n",
    "    \n",
    "    # 추출된 Train Subset으로 DataLoader 생성\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "    # 추출된 Valid Subset으로 DataLoader 생성\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # 생성한 DataLoader 반환\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44331d5-b6ae-403d-b3b1-c76a7758d53e",
   "metadata": {},
   "source": [
    "dataloader를 정의했습니다. batchsize는 64로 했고 shuffle을 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec86e71c-2975-47b0-bd06-28df82c791e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01bfaea4-9ff5-42c4-af4f-1f584af88e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(train_path_label, transform)\n",
    "\n",
    "custom_dataloader = DataLoader(dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=True\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e466688b-3615-422b-ad07-821a8d6c491d",
   "metadata": {},
   "source": [
    "모델\n",
    "\n",
    "모델은 pretrain된 resnet18을 가져왔습니다. 이 모델의 마지막 fc층만 저희의 과제인 18개의 class로 변경해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f49a2e49-e24d-4e1c-8ce7-9be3193a40ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f299509a-d3f8-47b7-9657-e6397a767c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "OUTPUT_CLASS_NUM = 18\n",
    "my_model.fc = torch.nn.Linear(in_features=512, out_features=OUTPUT_CLASS_NUM, bias=True) # output 18개로\n",
    "\n",
    "# xavier uniform\n",
    "torch.nn.init.xavier_uniform_(my_model.fc.weight)\n",
    "stdv = 1. / math.sqrt(my_model.fc.weight.size(1))\n",
    "my_model.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "my_model.fc.weight.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cbcaf2d-53ec-4b36-bb78-c7df4c74a3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "911b6054-9b4b-4a0e-bfc6-b56575293620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73604167-7ab2-49be-9daa-e7a3a4ba1953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # my_model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# import timm\n",
    "# my_model = timm.create_model('resnet50', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "998b8581-1351-4a2c-aba4-08a74c4a17b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "\n",
    "# OUTPUT_CLASS_NUM = 18\n",
    "# print(my_model.fc)\n",
    "# num_ftrs = my_model.fc.in_features\n",
    "# print(num_ftrs)\n",
    "# # my_model.fc = torch.nn.Linear(in_features=num_ftrs, out_features=OUTPUT_CLASS_NUM, bias=True) # output 18개로\n",
    "\n",
    "# my_model.fc = nn.Sequential(\n",
    "#                    nn.Linear(num_ftrs, 512),\n",
    "#                    nn.ReLU(inplace=True),\n",
    "#                    nn.Dropout(0.2),\n",
    "#                    nn.Linear(512, 512),\n",
    "#                    nn.ReLU(inplace=True),\n",
    "#                    nn.Dropout(0.2),\n",
    "#                    nn.Linear(512, OUTPUT_CLASS_NUM)\n",
    "#                 ).to(device)\n",
    "\n",
    "# # Linear, ReLU, Dropout 넣기\n",
    "\n",
    "# # num_ftrs = my_model.fc.in_features\n",
    "# # my_model.classifier = nn.Sequential(\n",
    "# #     nn.Linear(512 * 7 * 7, 4096),\n",
    "# #     nn.ReLU(True),\n",
    "# #     nn.Dropout(p=0.2),\n",
    "# #     nn.Linear(4096, 4096),\n",
    "# #     nn.ReLU(True),\n",
    "# #     nn.Dropout(p=0.2),\n",
    "# #     nn.Linear(4096, OUTPUT_CLASS_NUM),\n",
    "# # )\n",
    "\n",
    "\n",
    "\n",
    "# # xavier uniform\n",
    "# for i in range(0, len(my_model.fc), 3):\n",
    "#     torch.nn.init.xavier_uniform_(my_model.fc[i].weight)\n",
    "#     stdv = 1. / math.sqrt(my_model.fc[i].weight.size(1))\n",
    "#     my_model.fc[i].bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "# my_model.fc[-1].weight.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072cbb59-b947-422e-b685-0ae3b43a4f91",
   "metadata": {},
   "source": [
    "다음 코드를 참고하세요.\n",
    "- pre-trained model에 원하는 함수 추가\n",
    "- 입력값 모를 때 자동으로 계산해서 넣는 법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd2aaf69-6d40-4186-bd68-9f0f6f7ef295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-trained model에 원하는 함수 추가\n",
    "\n",
    "# num_classes = 18\n",
    "# model = vgg19_bn(pretrained=True)\n",
    "# model.classifier = nn.Sequential(\n",
    "#     nn.Linear(512 * 7 * 7, 4096),\n",
    "#     nn.ReLU(True),\n",
    "#     nn.Dropout(),\n",
    "#     nn.Linear(4096, 4096),\n",
    "#     nn.ReLU(True),\n",
    "#     nn.Dropout(),\n",
    "#     nn.Linear(4096, num_classes),\n",
    "# )\n",
    "\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a941f7f-4688-4a62-936b-16bee0cacfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력값 모를 때 넣는 법\n",
    "\n",
    "# model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "# num_ftrs = model_conv.fc.in_features\n",
    "# model_conv.fc = nn.Linear(num_ftrs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d8956a1-6f32-414d-9461-c8186523317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의로 둘을 합쳐봄\n",
    "\n",
    "# from torchvision.models import vgg19_bn\n",
    "\n",
    "# OUTPUT_CLASS_NUM = 18\n",
    "# model = vgg19_bn(pretrained=True)\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.classifier = nn.Sequential(\n",
    "#     nn.Linear(num_ftrs, 512),\n",
    "#     nn.ReLU(True),\n",
    "#     nn.Dropout(p=0.2),\n",
    "#     nn.Linear(512, 512),\n",
    "#     nn.ReLU(True),\n",
    "#     nn.Dropout(p=0.2),\n",
    "#     nn.Linear(512, OUTPUT_CLASS_NUM),\n",
    "# )\n",
    "\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89442b2-35cf-4384-9d18-18481d60f01a",
   "metadata": {},
   "source": [
    "아래 대부분의 코드가 부스트캠프에서 학습 자료나 과제로 제공받았던 코드를 거의 그대로 사용했습니다.\n",
    "\n",
    "설명도 주석도 잘 달려 있어서 그대로 가져왔습니다.\n",
    "\n",
    "epoch는 5, lr은 0.0001로 주었습니다.\n",
    "\n",
    "추후에 lr scheduler로 lr을 변경해보는 방법도 좋을 것 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe33dbb7-a718-4d57-b51c-79961d4ab129",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.to(device)\n",
    "\n",
    "LEARNING_RATE = 0.0001 # 학습 때 사용하는 optimizer의 학습률 옵션 설정\n",
    "NUM_EPOCH = 5 # 학습 때 mnist train data set을 얼마나 많이 학습할 지 결정하는 옵션\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss() # 분류 학습 때 많이 사용되는 Cross Entropy Loss를 objective function으로 사용\n",
    "# loss_fn = torch.nn.NLLLoss() # VGG\n",
    "optimizer = torch.optim.Adam(my_model.parameters(), lr=LEARNING_RATE) # weight 업데이트를 위한 optimizer를 Adam으로 사용함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57d55cbe-9d85-4c5d-9ac0-12b8f9b09ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    path  label\n",
      "0      input/data/train/images/000001_female_Asian_45...     10\n",
      "1      input/data/train/images/000001_female_Asian_45...      4\n",
      "2      input/data/train/images/000001_female_Asian_45...      4\n",
      "3      input/data/train/images/000001_female_Asian_45...      4\n",
      "4      input/data/train/images/000001_female_Asian_45...      4\n",
      "...                                                  ...    ...\n",
      "18895  input/data/train/images/006959_male_Asian_19/m...      0\n",
      "18896  input/data/train/images/006959_male_Asian_19/m...      0\n",
      "18897  input/data/train/images/006959_male_Asian_19/m...      0\n",
      "18898  input/data/train/images/006959_male_Asian_19/m...      0\n",
      "18899  input/data/train/images/006959_male_Asian_19/n...     12\n",
      "\n",
      "[18900 rows x 2 columns]\n",
      "현재 epoch-1-0의 train-데이터 셋에서 평균 Loss: 1.134, 평균 Accuracy: 0.645\n",
      "소요 시간: 2분 36초\n",
      "현재 epoch-1-0의 test-데이터 셋에서 평균 Loss: 2.528, 평균 Accuracy: 0.298\n",
      "소요 시간: 3분 5초\n",
      "현재 epoch-1-1의 train-데이터 셋에서 평균 Loss: 0.710, 평균 Accuracy: 0.773\n",
      "소요 시간: 5분 42초\n",
      "현재 epoch-1-1의 test-데이터 셋에서 평균 Loss: 1.656, 평균 Accuracy: 0.453\n",
      "소요 시간: 6분 11초\n",
      "현재 epoch-1-2의 train-데이터 셋에서 평균 Loss: 0.358, 평균 Accuracy: 0.883\n",
      "소요 시간: 8분 50초\n",
      "현재 epoch-1-2의 test-데이터 셋에서 평균 Loss: 1.160, 평균 Accuracy: 0.575\n",
      "소요 시간: 9분 20초\n",
      "현재 epoch-1-3의 train-데이터 셋에서 평균 Loss: 0.195, 평균 Accuracy: 0.941\n",
      "소요 시간: 11분 57초\n",
      "현재 epoch-1-3의 test-데이터 셋에서 평균 Loss: 1.104, 평균 Accuracy: 0.586\n",
      "소요 시간: 12분 26초\n",
      "현재 epoch-1-4의 train-데이터 셋에서 평균 Loss: 0.118, 평균 Accuracy: 0.966\n",
      "소요 시간: 15분 4초\n",
      "현재 epoch-1-4의 test-데이터 셋에서 평균 Loss: 1.322, 평균 Accuracy: 0.549\n",
      "소요 시간: 15분 33초\n",
      "현재 epoch-2-0의 train-데이터 셋에서 평균 Loss: 0.468, 평균 Accuracy: 0.856\n",
      "소요 시간: 18분 21초\n",
      "현재 epoch-2-0의 test-데이터 셋에서 평균 Loss: 0.903, 평균 Accuracy: 0.731\n",
      "소요 시간: 18분 50초\n",
      "현재 epoch-2-1의 train-데이터 셋에서 평균 Loss: 0.227, 평균 Accuracy: 0.928\n",
      "소요 시간: 21분 26초\n",
      "현재 epoch-2-1의 test-데이터 셋에서 평균 Loss: 0.970, 평균 Accuracy: 0.715\n",
      "소요 시간: 21분 55초\n",
      "현재 epoch-2-2의 train-데이터 셋에서 평균 Loss: 0.128, 평균 Accuracy: 0.962\n",
      "소요 시간: 24분 41초\n",
      "현재 epoch-2-2의 test-데이터 셋에서 평균 Loss: 0.879, 평균 Accuracy: 0.734\n",
      "소요 시간: 25분 10초\n",
      "현재 epoch-2-3의 train-데이터 셋에서 평균 Loss: 0.079, 평균 Accuracy: 0.979\n",
      "소요 시간: 27분 48초\n",
      "현재 epoch-2-3의 test-데이터 셋에서 평균 Loss: 0.986, 평균 Accuracy: 0.703\n",
      "소요 시간: 28분 17초\n",
      "현재 epoch-2-4의 train-데이터 셋에서 평균 Loss: 0.049, 평균 Accuracy: 0.989\n",
      "소요 시간: 30분 55초\n",
      "현재 epoch-2-4의 test-데이터 셋에서 평균 Loss: 0.925, 평균 Accuracy: 0.731\n",
      "소요 시간: 31분 23초\n",
      "현재 epoch-3-0의 train-데이터 셋에서 평균 Loss: 0.193, 평균 Accuracy: 0.938\n",
      "소요 시간: 33분 58초\n",
      "현재 epoch-3-0의 test-데이터 셋에서 평균 Loss: 0.548, 평균 Accuracy: 0.807\n",
      "소요 시간: 34분 28초\n",
      "현재 epoch-3-1의 train-데이터 셋에서 평균 Loss: 0.095, 평균 Accuracy: 0.969\n",
      "소요 시간: 37분 3초\n",
      "현재 epoch-3-1의 test-데이터 셋에서 평균 Loss: 0.747, 평균 Accuracy: 0.748\n",
      "소요 시간: 37분 32초\n",
      "현재 epoch-3-2의 train-데이터 셋에서 평균 Loss: 0.048, 평균 Accuracy: 0.987\n",
      "소요 시간: 40분 9초\n",
      "현재 epoch-3-2의 test-데이터 셋에서 평균 Loss: 0.588, 평균 Accuracy: 0.824\n",
      "소요 시간: 40분 38초\n",
      "현재 epoch-3-3의 train-데이터 셋에서 평균 Loss: 0.029, 평균 Accuracy: 0.994\n",
      "소요 시간: 43분 14초\n",
      "현재 epoch-3-3의 test-데이터 셋에서 평균 Loss: 0.986, 평균 Accuracy: 0.763\n",
      "소요 시간: 43분 43초\n",
      "현재 epoch-3-4의 train-데이터 셋에서 평균 Loss: 0.026, 평균 Accuracy: 0.994\n",
      "소요 시간: 46분 19초\n",
      "현재 epoch-3-4의 test-데이터 셋에서 평균 Loss: 0.706, 평균 Accuracy: 0.786\n",
      "소요 시간: 46분 52초\n",
      "현재 epoch-4-0의 train-데이터 셋에서 평균 Loss: 0.169, 평균 Accuracy: 0.945\n",
      "소요 시간: 49분 39초\n",
      "현재 epoch-4-0의 test-데이터 셋에서 평균 Loss: 0.474, 평균 Accuracy: 0.802\n",
      "소요 시간: 50분 14초\n",
      "현재 epoch-4-1의 train-데이터 셋에서 평균 Loss: 0.078, 평균 Accuracy: 0.974\n",
      "소요 시간: 52분 54초\n",
      "현재 epoch-4-1의 test-데이터 셋에서 평균 Loss: 0.469, 평균 Accuracy: 0.835\n",
      "소요 시간: 53분 25초\n",
      "현재 epoch-4-2의 train-데이터 셋에서 평균 Loss: 0.034, 평균 Accuracy: 0.991\n",
      "소요 시간: 56분 0초\n",
      "현재 epoch-4-2의 test-데이터 셋에서 평균 Loss: 0.410, 평균 Accuracy: 0.867\n",
      "소요 시간: 56분 31초\n",
      "현재 epoch-4-3의 train-데이터 셋에서 평균 Loss: 0.021, 평균 Accuracy: 0.996\n",
      "소요 시간: 59분 7초\n",
      "현재 epoch-4-3의 test-데이터 셋에서 평균 Loss: 0.632, 평균 Accuracy: 0.795\n",
      "소요 시간: 59분 39초\n",
      "현재 epoch-4-4의 train-데이터 셋에서 평균 Loss: 0.015, 평균 Accuracy: 0.997\n",
      "소요 시간: 62분 14초\n",
      "현재 epoch-4-4의 test-데이터 셋에서 평균 Loss: 0.656, 평균 Accuracy: 0.823\n",
      "소요 시간: 62분 45초\n",
      "현재 epoch-5-0의 train-데이터 셋에서 평균 Loss: 0.030, 평균 Accuracy: 0.991\n",
      "소요 시간: 65분 22초\n",
      "현재 epoch-5-0의 test-데이터 셋에서 평균 Loss: 2.479, 평균 Accuracy: 0.321\n",
      "소요 시간: 65분 52초\n",
      "현재 epoch-5-1의 train-데이터 셋에서 평균 Loss: 0.037, 평균 Accuracy: 0.989\n",
      "소요 시간: 68분 29초\n",
      "현재 epoch-5-1의 test-데이터 셋에서 평균 Loss: 3.269, 평균 Accuracy: 0.498\n",
      "소요 시간: 68분 58초\n",
      "현재 epoch-5-2의 train-데이터 셋에서 평균 Loss: 0.043, 평균 Accuracy: 0.987\n",
      "소요 시간: 71분 35초\n",
      "현재 epoch-5-2의 test-데이터 셋에서 평균 Loss: 2.372, 평균 Accuracy: 0.485\n",
      "소요 시간: 72분 4초\n",
      "현재 epoch-5-3의 train-데이터 셋에서 평균 Loss: 0.023, 평균 Accuracy: 0.993\n",
      "소요 시간: 74분 42초\n",
      "현재 epoch-5-3의 test-데이터 셋에서 평균 Loss: 1.387, 평균 Accuracy: 0.602\n",
      "소요 시간: 75분 11초\n",
      "현재 epoch-5-4의 train-데이터 셋에서 평균 Loss: 0.007, 평균 Accuracy: 0.999\n",
      "소요 시간: 77분 47초\n",
      "현재 epoch-5-4의 test-데이터 셋에서 평균 Loss: 0.546, 평균 Accuracy: 0.818\n",
      "소요 시간: 78분 15초\n",
      "학습 종료!\n",
      "최고 accuracy: 0.8671957850456238, 최고 낮은 loss: 0.4101978215827513\n",
      "소요 시간: 78분 15초\n"
     ]
    }
   ],
   "source": [
    "# 5-fold Stratified KFold 5개의 fold를 형성하고 5번 Cross Validation을 진행합니다.\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "best_test_accuracy = 0.\n",
    "best_test_loss = 9999.\n",
    "start = time.time()  # 시작 시간 저장\n",
    "\n",
    "# skf 설정\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "# kfold = KFold(n_splits=4, shuffle=False)\n",
    "\n",
    "# skf에서 사용할 labels 설정\n",
    "labels = [i for i in train_path_label['label']]\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 4\n",
    "\n",
    "print(train_path_label)\n",
    "temp_idx = 0\n",
    "for train_index, validate_index in skf.split(train_path_label, labels):\n",
    "#     print(train_index, validate_index)\n",
    "    temp_idx += 1\n",
    "    train = train_path_label.iloc[train_index]\n",
    "    valid = train_path_label.iloc[validate_index]\n",
    "\n",
    "    train_dataset = CustomDataset(train, transform)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset,\n",
    "                                 batch_size=BATCH_SIZE,\n",
    "                                 shuffle=False\n",
    "                                 )\n",
    "\n",
    "    valid_dataset = CustomDataset(valid, transform)\n",
    "\n",
    "    valid_dataloader = DataLoader(valid_dataset,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=False)\n",
    "\n",
    "    dataloaders = {\n",
    "        \"train\": train_dataloader,\n",
    "        \"test\": valid_dataloader,\n",
    "    }\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "\n",
    "        for phase in [\"train\", \"test\"]:\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "#             # 네트워크 모델을 train 모드로 두어 gradient를 계산하고, \n",
    "#             # 여러 sub module (배치 정규화, 드롭아웃 등)이 train_mode로 작동할 수 있게 함.\n",
    "            if phase == \"train\":\n",
    "                my_model.train()\n",
    "            # 네트워크 모델을 eval 모드로 두어 여러 sub module들이 eval mode로 작동할 수 있게 함.\n",
    "            elif phase == \"test\":\n",
    "                my_model.eval()\n",
    "            \n",
    "            for ind, (images, labels) in enumerate(dataloaders[phase]):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad() # parameter gradient를 업데이트 전 초기화함.\n",
    "\n",
    "                # train 모드일 시에는 gradient를 계산하고, 아닐 때는 gradient를 계산하지 않아 연산량 최소화\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    logits = my_model(images)\n",
    "                    # 모델에서 linear 값으로 나오는 예측 값([0.9, 1.2, 3.2, 0.1, -0.1, ...])에서 최대 output index를 찾아 예측 레이블([2])로 변경함\n",
    "                    _, preds = torch.max(logits, 1)\n",
    "                    loss = loss_fn(logits, labels)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward() # 모델의 예측 값과 실제 값의 CrossEntropy 차이를 통해 gradient를 계산\n",
    "                        optimizer.step() # 계산된 gradient를 가지고 모델 업데이트\n",
    "\n",
    "                running_loss += loss.item() * images.size(0) # 한 Batch에서의 loss 값 저장\n",
    "                running_acc += torch.sum(preds == labels.data) # 한 Batch에서의 Accuracy 값 저장\n",
    "\n",
    "            # 한 epoch이 모두 종료되었을 때,\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_acc / len(dataloaders[phase].dataset)\n",
    "\n",
    "            seconds = int(time.time() - start)\n",
    "            print(f\"현재 epoch-{temp_idx}-{epoch}의 {phase}-데이터 셋에서 평균 Loss: {epoch_loss:.3f}, 평균 Accuracy: {epoch_acc:.3f}\")\n",
    "            print(f\"소요 시간: {seconds // 60}분 {seconds % 60}초\")  # 현재시각 - 시작시간 = 실행 시간\n",
    "#             print(f\"현재 epoch-{epoch}의 {phase}-데이터 셋에서 평균 Loss: {epoch_loss:.3f}, 평균 Accuracy: {epoch_acc:.3f}\")\n",
    "#             print(f\"소요 시간: {seconds // 60}분 {seconds % 60}초\")  # 현재시각 - 시작시간 = 실행 시간\n",
    "\n",
    "            # phase가 test일 때\n",
    "            if phase == \"test\":\n",
    "                # best accuracy 계산\n",
    "                if best_test_accuracy < epoch_acc:\n",
    "                    best_test_accuracy = epoch_acc\n",
    "                # best loss 계산\n",
    "                if best_test_loss > epoch_loss:\n",
    "                    best_test_loss = epoch_loss\n",
    "\n",
    "                \n",
    "seconds = int(time.time() - start)\n",
    "print(\"학습 종료!\")\n",
    "print(f\"최고 accuracy: {best_test_accuracy}, 최고 낮은 loss: {best_test_loss}\")\n",
    "print(f\"소요 시간: {seconds // 60}분 {seconds % 60}초\")  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62f155eb-8160-4d02-85c5-57a8ca990be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    path  label\n",
      "0      input/data/train/images/000001_female_Asian_45...     10\n",
      "1      input/data/train/images/000001_female_Asian_45...      4\n",
      "2      input/data/train/images/000001_female_Asian_45...      4\n",
      "3      input/data/train/images/000001_female_Asian_45...      4\n",
      "4      input/data/train/images/000001_female_Asian_45...      4\n",
      "...                                                  ...    ...\n",
      "18042  input/data/train/images/006615_male_Asian_19/m...      0\n",
      "18043  input/data/train/images/006615_male_Asian_19/m...      0\n",
      "18044  input/data/train/images/006615_male_Asian_19/m...      0\n",
      "18045  input/data/train/images/006615_male_Asian_19/n...     12\n",
      "18047  input/data/train/images/006616_male_Asian_20/m...      0\n",
      "\n",
      "[15120 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe8b8b5f-b9cc-489d-a8dc-6177bd582940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[0].shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394de42a-a2b6-467f-a8fe-5657afcedd28",
   "metadata": {},
   "source": [
    "dataloader를 정의했습니다. batchsize는 64로 했고 shuffle을 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23ac036e-abaa-4b02-93ec-98f7f93106c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/input'\n",
    "\n",
    "torch.save(my_model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b5867fb-4ace-4c4f-a078-be1d6b5ff4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=18, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3beba0d-98de-43af-9e9b-59f32bc88304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "670fead6-c072-4272-be02-d2e2861c5afc",
   "metadata": {},
   "source": [
    "검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53b2efc1-8481-47e0-b7a2-8c7588254d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_eval(model, data_iter, device):\n",
    "    with torch.no_grad():\n",
    "        n_total, n_correct = 0, 0\n",
    "        model.eval()\n",
    "        for batch_in, batch_out in data_iter:\n",
    "            y_trgt = batch_out.to(device)\n",
    "            model_pred = model.forward(batch_in.to(device))\n",
    "            _, y_pred = torch.max(model_pred, 1)  # 행으로 비교\n",
    "            n_correct += (y_pred == y_trgt).sum().item()\n",
    "            n_total += batch_in.size(0)\n",
    "        val_acc = (n_correct/n_total)\n",
    "        #model_train()\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18617b1f-e3fb-4f1d-b93a-e92068129850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8153439153439154"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_eval(my_model, valid_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "262d7e91-3b25-43f5-bfdd-dbd0e73e4350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_eval(raw_data, dataloader, model, device):\n",
    "    result = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (X,y) in enumerate(dataloader):\n",
    "            model_pred = model.forward(X.to(device))\n",
    "            _, y_pred = torch.max(model_pred, 1)\n",
    "            \n",
    "            result.append([valid.iloc[i]['path'], y_pred.cpu().numpy()[0], y.cpu().numpy()[0]])\n",
    "    result = pd.DataFrame(result, columns=['path', 'pred', 'target'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed5019f3-d4d7-4a24-ba87-c976a5cfbb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>pred</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input/data/train/images/003997_male_Asian_59/i...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input/data/train/images/003997_male_Asian_59/m...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input/data/train/images/003997_male_Asian_59/m...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>input/data/train/images/003997_male_Asian_59/m...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>input/data/train/images/003997_male_Asian_59/m...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3775</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3776</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3777</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>input/data/train/images/006959_male_Asian_19/n...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3780 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  pred  target\n",
       "0     input/data/train/images/003997_male_Asian_59/i...     7       7\n",
       "1     input/data/train/images/003997_male_Asian_59/m...     1       1\n",
       "2     input/data/train/images/003997_male_Asian_59/m...     1       1\n",
       "3     input/data/train/images/003997_male_Asian_59/m...     1       1\n",
       "4     input/data/train/images/003997_male_Asian_59/m...     1       1\n",
       "...                                                 ...   ...     ...\n",
       "3775  input/data/train/images/006959_male_Asian_19/m...     0       0\n",
       "3776  input/data/train/images/006959_male_Asian_19/m...     0       0\n",
       "3777  input/data/train/images/006959_male_Asian_19/m...     0       0\n",
       "3778  input/data/train/images/006959_male_Asian_19/m...     0       0\n",
       "3779  input/data/train/images/006959_male_Asian_19/n...    12      12\n",
       "\n",
       "[3780 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_testing_dataloader = DataLoader(valid_dataset, shuffle=False)\n",
    "\n",
    "check_eval_df = check_eval(valid, valid_testing_dataloader, my_model, device)\n",
    "check_eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a211b3d1-1a55-4bc5-94d1-e82662e81ee0",
   "metadata": {},
   "source": [
    "잘못 예측한 데이터 리스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d12ce11e-66d9-43d1-be5c-cc4a36d7bbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>pred</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input/data/train/images/004026_male_Asian_59/n...</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input/data/train/images/004072_male_Asian_55/i...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input/data/train/images/004074_male_Asian_59/i...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>input/data/train/images/004074_male_Asian_59/m...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>input/data/train/images/004075_male_Asian_54/i...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>input/data/train/images/005555_male_Asian_48/i...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>input/data/train/images/005555_male_Asian_48/m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>input/data/train/images/005557_male_Asian_46/i...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>input/data/train/images/006424_female_Asian_18...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>input/data/train/images/006672_male_Asian_19/m...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>678 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path  pred  target\n",
       "0    input/data/train/images/004026_male_Asian_59/n...    14      13\n",
       "1    input/data/train/images/004072_male_Asian_55/i...     8       7\n",
       "2    input/data/train/images/004074_male_Asian_59/i...     8       7\n",
       "3    input/data/train/images/004074_male_Asian_59/m...     2       1\n",
       "4    input/data/train/images/004075_male_Asian_54/i...     6       7\n",
       "..                                                 ...   ...     ...\n",
       "673  input/data/train/images/005555_male_Asian_48/i...     6       7\n",
       "674  input/data/train/images/005555_male_Asian_48/m...     0       1\n",
       "675  input/data/train/images/005557_male_Asian_46/i...     6       7\n",
       "676  input/data/train/images/006424_female_Asian_18...     0       3\n",
       "677  input/data/train/images/006672_male_Asian_19/m...     3       0\n",
       "\n",
       "[678 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_df = check_eval_df[check_eval_df['pred'] != check_eval_df['target']]\n",
    "wrong_df = wrong_df.reset_index(drop=True)\n",
    "wrong_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502faa33-ea25-4485-a905-b2cc01dafbef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0ca21b8-d14c-48fd-8fd7-8e859710dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = [[['wear'], ['male'], ['un30']], [['wear'], ['male'], ['3060']], [['wear'], ['male'], ['ov60']],\n",
    "              [['wear'], ['fema'], ['un30']], [['wear'], ['fema'], ['3060']], [['wear'], ['fema'], ['ov60']],\n",
    "              [['Inco'], ['male'], ['un30']], [['Inco'], ['male'], ['3060']], [['Inco'], ['male'], ['ov60']],\n",
    "              [['Inco'], ['fema'], ['un30']], [['Inco'], ['fema'], ['3060']], [['Inco'], ['fema'], ['ov60']],\n",
    "              [['NoWe'], ['male'], ['un30']], [['NoWe'], ['male'], ['3060']], [['NoWe'], ['male'], ['ov60']],\n",
    "              [['NoWe'], ['fema'], ['un30']], [['NoWe'], ['fema'], ['3060']], [['NoWe'], ['fema'], ['ov60']]\n",
    "             ]\n",
    "\n",
    "def draw_(df):\n",
    "    plt.figure(figsize = (15, 30))\n",
    "    row = len(wrong_df) // 3\n",
    "    # 틀린 번호 찾기\n",
    "    wrong_number = list()\n",
    "    for df_path in list(df['path']):\n",
    "        wrong_number.append(df_path.split('/')[4].split('_')[0])\n",
    "        \n",
    "    for i in range(df.shape[0]):\n",
    "        plt.subplot(row + 1, df.shape[0] // row, i + 1)\n",
    "        plt.imshow(Image.open(df['path'][i]))\n",
    "        plt.title(f\"target:{class_list[df['target'][i]]}, \\n pred: {class_list[df['pred'][i]]} \\n id: {wrong_number[i]}\", color='r', size=20)\n",
    "        plt.axis('off')\n",
    "    print(df)\n",
    "    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "760a326e-3fc6-4f28-aeb2-92964bc142db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  path  pred  target\n",
      "0    input/data/train/images/004026_male_Asian_59/n...    14      13\n",
      "1    input/data/train/images/004072_male_Asian_55/i...     8       7\n",
      "2    input/data/train/images/004074_male_Asian_59/i...     8       7\n",
      "3    input/data/train/images/004074_male_Asian_59/m...     2       1\n",
      "4    input/data/train/images/004075_male_Asian_54/i...     6       7\n",
      "..                                                 ...   ...     ...\n",
      "673  input/data/train/images/005555_male_Asian_48/i...     6       7\n",
      "674  input/data/train/images/005555_male_Asian_48/m...     0       1\n",
      "675  input/data/train/images/005557_male_Asian_46/i...     6       7\n",
      "676  input/data/train/images/006424_female_Asian_18...     0       3\n",
      "677  input/data/train/images/006672_male_Asian_19/m...     3       0\n",
      "\n",
      "[678 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(wrong_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "067c8ef6-4b24-4e21-8b53-d64f651cbf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_(wrong_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813bb94d-347c-4fbe-86ee-d07e8def980a",
   "metadata": {},
   "source": [
    "f1 score 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c0299e3-3b3e-45b9-935f-33ff69f97011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "500c3ff1-45cc-4e72-b9b9-31e1e5ac207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c7ebad-b00a-46d4-8537-d04ad6c321a5",
   "metadata": {},
   "source": [
    "함수 정의\n",
    "- precision, recall, f1-score, confusion matrix 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89d2802f-43d8-4516-b4ce-ae2d69a75edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report():\n",
    "    y_test, y_pred = check_eval_df['target'], check_eval_df['pred']\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('my_model Accuracy:', np.mean(y_pred == y_test))\n",
    "    ax = plt.figure(figsize=(10, 5))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), linewidths=0.5, fmt='.1f', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65f95332-f0e4-42e1-ab83-1cebbc46f381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94       554\n",
      "           1       0.99      0.83      0.90       409\n",
      "           2       0.90      0.92      0.91        83\n",
      "           3       0.65      1.00      0.79       727\n",
      "           4       0.97      0.52      0.68       818\n",
      "           5       0.74      0.74      0.74       109\n",
      "           6       0.72      1.00      0.83       111\n",
      "           7       1.00      0.43      0.60        82\n",
      "           8       0.74      0.88      0.80        16\n",
      "           9       0.74      1.00      0.85       146\n",
      "          10       0.98      0.62      0.76       163\n",
      "          11       0.70      0.64      0.67        22\n",
      "          12       0.90      1.00      0.94       111\n",
      "          13       0.98      0.74      0.85        81\n",
      "          14       0.83      0.88      0.86        17\n",
      "          15       0.86      1.00      0.92       145\n",
      "          16       0.96      0.80      0.87       164\n",
      "          17       0.62      0.68      0.65        22\n",
      "\n",
      "    accuracy                           0.82      3780\n",
      "   macro avg       0.84      0.82      0.81      3780\n",
      "weighted avg       0.86      0.82      0.81      3780\n",
      "\n",
      "my_model Accuracy: 0.8206349206349206\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAEvCAYAAACT9RFqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd3hURduH70khoSWhpyEEQRER6TW00EIJRQULVYH4YpcPxQ6iYqWIPahIUaoKEogCoQaFEDqEFnoqLSR0Uub7YzchYTe72cDZbE7mvq65cnZmzvxmzrNlMmfO8wgpJQqFQqFQKBT2xqm4O6BQKBQKhaJ0oiYhCoVCoVAoigU1CVEoFAqFQlEsqEmIQqFQKBSKYkFNQhQKhUKhUBQLahKiUCgUCoWiWHCxg4Z6BlihUCgUpQ1hT7GMc8ds/q11rVrHrn00hz0mIVz9YpRmbZcb9yMALmX8NNPIvJlgFw0t27eHhr2uk140lL1Ll4ayd+nTUFjHLpMQhUKhUCgUGpKdVdw9KBJ22RPiPnwi7sPew23IOwC4tu2L+7Of4z7sPdyHvYdTwEOGzngH5Oa5D5uAc90mZtsTnlVxG/wW7iMnW9Tt0b0T+/dt5GBsFK+/9rxJeZkyZfjt1+84GBvFv1HLqVXL3+axaa0xM2wKifG72bUzssA606ZO4mBsFDu2r6ZJ44Y2jwG0H4cebKE0HKd9peFYGnoYg700NENm254cALtMQq4v+oLrcyZxY96HuXmZ21dzfc4krs+ZRPbxvQBkn0vg+twPDfm/T6dM96EgTLvo2uFRMmNWc/2ntwrUdHJyYsaXH9EnZAgPPdyZxx/vzwMP1MtX55mnnyQ1NY36DQKZPmMmH09+26Zx2UNjzpxF9O4zuMDynsFB1KsbQP0GgYwZM55vvv7YpvbtMQ692EJpOEb7SsOxNPQwBntpaEp2tu3JAXCsp2Myb+bOzoSLa4FbWp1r1ifr8HaLTbVs0YSjR09w/PgpMjIyWLRoGX1DeuSr0zekO3PnLgbg999XENQ50Kbu2kNjU9RWLqReLLA8JKQHc39dAsDW6B14enni7V3docahF1soDcdoX2k4loYexmAvDS2RMtvm5AhYnYQIIeoLIcYLIWYY03ghxAO2iLg/9iruQ97FuVGH3DyXJkG4D59ImR4jwK3crQ55B+A+4n3ch0/k5uq5pktGZSsgb1yzupTk6+fN6fjE3NfxCUn4+noXWCcrK4u0tHSqVKlU6HHZQ8Mafr7exJ++1YeE+CT8buuDNbQeh15soTSUvZWGPsdgLw1N0WAlRAhxvxBiV56ULoR4RQhRWQixWghxxPi3krG+MM4T4oQQe4QQTa1pWJyECCHGAwswPGoUbUwCmC+EeKMQlwWA63M/4Pof03Ft3Bkn/3pk7FrP9R/f5Prs95FX0ijTaVBu3ezk41z/ZQLX532ES6te4Kz2zioUCoVCYREN9oRIKQ9JKRtLKRsDzYCrwJ/AG0CklLIeEGl8DdATqGdMocB31jSsrYSMBFpIKT+RUs4zpk+AlsYyswghQoUQMUKImLCwMEPm1Utkxe3EyTsArqaDlIAkc89GnHwCTAd/IQkyruNU9bbHqK5dRriVNbtXJC+JCcnU9PfNfe3v50NiYnKBdZydnfH09OD8+VSL7dpbwxoJicn417zVBz9/HxJu64M1tB6HXmyhNJS9lYY+x2AvDU3JzrI92UYX4KiU8iTQD5htzJ8N9Dce9wPmSANbAC8hhI+lRq1NQrIBXzP5PsYys0gpw6SUzaWUHUNDQw2ZrmVwqtWA7HMJUN4zt65zvaaGPAxPveRMLoRHZURlH7LTz5u0n3X6EM73NbPY8W0xu6hbN4DatWvi6urKoEH9WB6+Kl+d5eGrGDp0IACPPtqbdes3W2yzODSsER6+iqGDHwOgVcumpKelk5x8xqY2tB6HXmyhNByjfaXhWBp6GIO9NDRF+6djngDmG49rSCmTjMfJQA3jsR9wOs858cY8C/2WssAEBANxQAQQZkx/G/OCLZ1rTHWklDIr5ZTMOhsvb2z8Q175fKTM2PevzDpzWmadOS0zjuyUV74dK698PlJeXzFTZp2Nl1kpJ2VW8gl5/c+v5JXPR8orn4+UmUf3yKvGelfDxsvMxGMy60KKzMHZ1dck9QkZIg8dPirj4o7Ld979RDq7+soPPpwq+w0YLp1dfWW5CgFy8ZLl8siRYzI6eoese19rs+3YS8Nc/vwFf8rExGR58+ZNefp0ohw1eqwc89x4Oea58bl1vvl2loyLOy737I2VLVsFm23HksbdGoeebFFc9i5JGnqyhbK3srcGGtZ+H+9qunF0q7Q1YbhlEpMnhZprGygDnDNOPgAu3laeavwbDgTmyY8EmlvqtzBWLBAhhBOG2y85s5kEYJuUsrBrOVJ5TC2chvKoWLo0lL1Ll4ayd6nTsKtL9BtHt9jstt3t3taF6qMQoh/wvJSyu/H1IaCTlDLJeLtlvZTyfiHED8bj+bfXK6htq7s+peE5ni2F6ahCoVAoFIpiQFu/H09y61YMwF/AcOAT499lefJfEEIsAFoBaZYmIKDctisUCoVCUfLRyO+HEKI80A14Nk/2J8AiIcRI4CSQ84jrSqAXhi0bV4GnrbZv7XbMXUBF0VUoFApFacO+t2MObrD9dkz9jqUjiq5CoVAoFAoNcRAPqLZil0lIQJWHNWv7+PndAKytMchKzaITlLIIgDJu2gUrunkjXm1cK2Uayt6lS0PZu/Rp2BUHiQVjK2olRKFQKBSKkk4JXQmxawC7ih4V+XbWF6zZspTV//1Jk+aNeHPiq6zZspSIjYv5fs40KnpUNHtuh6C2RG5dxrpty/nfy8+YlLdY+xktN0wh4DWDI5n60/5nyFv3OQ1/HItzOTcA3P2r0njJu7Rc9zlN/piAm09l831tFEDL9V/QessMi2N66aVR7NoZyc4da5g752vc3NzylZcpU4Zf531LbGwUUZscN7y0CvWtNO6mhh7GoDQcp309aSjyY9dJyISPX2dD5Ga6tu5Prw4DiTt8nKj1W+jR7lF6dhjI8aMnee5VU2/wTk5OTPrsLUYMeo7ubQfQ95Fg6t5fJ1+dbUGvs63L61QOaoxHs3oceXc224JeJ7rza1xPOIf/yGAA6k4YSvKijUR3fo0TU5dw79tPme3r/Z+N5uD//cCW1i8VOB5fX2+ef/4ZWrfpTZOmXXF2dmbQoL756jz99BOkXkyjQYNAZsyYyeSP3rLpmukhhLUexqA0lL2Vhn7HYC8NTdEggJ09sNskpGLFCrRs04yF8/4EICMjk0vpl9i0/j+ysgx+z3bG7MHbxzQM/cNNG3Ly+GlOn0wgIyOT5X/+TbeenUzqCVdnnFycQUqyLl/LzXdyL0POQ0Dl7vMnNWofAKlR+6ka3NyknTLVvXCuUJb07UesjsvF2YWyZd1xdnambLmyJCWl5CsPyRv6+Y8VdHbA8NIq1LfSUPZWGsre2mtoiZRZNidHwG6TEP9aflw4n8rnX08ifN1CPpk+gbLlyuarM+ip/myINPXF7+1TnaSEW4GEkhPP4O1TI1+dFpGfEbj/Ry5s2Ev6jjgAHpg+hsB9YZSv50v8TxEAXI49SbXeLQGo1qslLhXL4VKpQr623HwqcyPJNGbN7SQmJjNt+g8cjdvKqZM7SE+7xJo1G/PV8fP1Jj7e4KslKyuLtHTHCy+tQn0rDWVvpaHsrb2GpmgfO0YTijwJEUJYdUKSFxcXZx5sVJ9fZy2mT+fHuXr1GmPy7O14fuwoMrOyWLp4RZH6s63L6/zb+H94NL2X8vVrAnDgle+IavQsVw4nUKNfWwDiJs7Fq00DWqz5FK+2DbieeB6yimYMLy9PQvp0577721CrdjPKly/LU08+UqS2FAqFQqEoMqXwdsz7BRUIIUKFEDFCiJiwsDAAkhJTSE5MYdf2vQBE/LWaBxvVB+DRJ/sS1L0Drzz7ptn2kpPO4ON3a0bq7Vud5NtuewBkpl8lNWo/lTs3vpWZLTmz9F+q9WkFwM2UVPY9M4VtXcdzbPL83PPyciPpAm4+VaxegC5BgZw4cZpz5y6QmZnJ0qURtG6TP7pvQmIy/v6GSMbOzs54ejheeGkV6ltpKHsrDWVv7TU0RY8rIUKIPQWkvdwK3WuClDJMStlcStk8NDQUgHNnzpOUkEKdurUAaNuhFXGHjtEhqC3PvjiC0YNf5vq162bb27NzP7Xr3IP/PX64uroQMiCYNREbTAfj7krljo24ejSRsrVvda9qj+ZcPWJYQnOtXBGEwUlcrZcHkDR/nUk7N89cJOvyNTya1TMpy8up04m0atWEsmXdAejcOZCDB+Py1QkPX30r9PMjvVnvgOGlVahvpaHsrTSUvbXX0JTsLNuTI2ApxC6QAjQGat2WagOJhQwxLGtXbiRrV24ke3YYKHfv3CcP7Dsk/1kRKRsFtJPHj56UCfFJcv+eA3L/ngNy3s+LZO3KjWTLBl3k2lUbc88dMeg5eezICXni2Cn5+YczcvNzuLT/hLx04KQ8+skCGVljkEzdekBeij0pLx04KZOWbJTr6wyTkdUHyj3PfCGvHE2UV+ISZMK8NXKt/5MysvpAGVl9oEzfezz3OLrbeHnpwEl59XhSroZrGT+T9MEHU+XBg0fkvn0H5Lx5S2T5CgHyww+nyQGPjJCuZfxkhYp15JIly+WRuOMyOnqnvO/+NmbbUaG+HS4Md4m2hbK342koezuOLeykUZjfx7uWrm1dJG1N9u6juWQxdowQ4idglpQyykzZb1JK88+33jbPUR5TraM8ppY+DWXv0qWh7F3qNOwal+X6loU2x45xb/24Y8eOkVKaOu24VVaYCYhCoVAoFAqtcZA9Hrai3LYrFAqFQlHScZCnXWzF4u2Yu4TmAgqFQqFQOBj2vR2zaa7tt2PaD3Xs2zEKhUKhUCgcH0fxgGordpmE6GSTEfWrt9BM4+CZbbrZuOaqoUaGjjau6cXeSqNwGsrepU/DrpTQ2zFqJUShUCgUipJOCd2YatcounmZGTaFxPjd7NoZWWCdaVMncTA2ih3bV9OkcUOH0Ai4txZ/rv01N8UcXcew0CcBGDJyECs3L2b5xoWMe+9Fs+cHdm5DxL9L+GfrH4x+cXihxqGHENZHDm9h5441xGxbxZb/VpqtM23qJA7cgb31cJ30oqGHMSgNx2lfTxqaUQrdtt8Rc+YsonefwQWW9wwOol7dAOo3CGTMmPF88/XHDqFx/OhJBgQNZkDQYB7tOpRr126wZuU6WrVrRlDPjvTr/BQhHR7n52/nmZzr5OTEe5++zugnX6ZP4CB6P9Kde+8LsKinpxDWXbsNpHmL7rRu08ukLDg4iLp1A3jAaIuvbbS3Xq6THjT0MAaloeyt1fegZujRbbuWbIrayoXUiwWWh4T0YO6vSwDYGr0DTy9PvL2rO5RGmw4tOH0insT4ZJ4Y8SgzZ8wm42YGABfOmcYTaNT0QU4dP038yQQyMjJZ+edqugR3tKhRWkJY9w3pwbw7sIVerpMeNPQwBqWh7F0c34OlEauTECFEfSFEFyFEhdvyg7XrFvj5ehN/+lZY5YT4JPxuC6tc3Bq9+ndnxR//AFD73lo0b92YhRGzmLv0Bxo2bmBSv4Z3NZISbgXeS05KoYZPNYsaeglhLaUkYuV8tm6JYNRI09Up3zu0hV6ukx409DAGpaHsrYWGpujxdowQ4iVgGfAisE8I0S9P8WQtO+bouLq6ENSjA38vN+w3cXZ2xtPLg8d7Ps1n73/J9Jml+vKY0KnzAFq2CqZPyBDGjBlBYGCr4u6SQqFQ6Aed3o4ZDTSTUvYHOgHvCiFeNpYV6ORECBEqhIgRQsSEhYUVqWMJicn417wVVtnP34eE28Iq3yl3otG+S1ti9x7k/NkLAKQknWH1CkNE3r07Y8mWkkpVvPKdk5J8Fh+/W9F9vX1qkJJ01qKOXkJY57R39ux5li6LoEWLxibld2Jv3VwnHWjoYQxKQ9lbCw1N0eNKCOAkpbwMIKU8gWEi0lMIMRULkxApZZiUsrmUsnloaGiROhYevoqhgx8DoFXLpqSnpZOcfKZIbWmh0XtAD1b8cSvM85qI9bQMbA5A7Tr34OrqSur5/PtR9u6MpVade/C7xxdXVxd6DejG2n82WtTRQwjrcuXKUqFC+dzjbl07sn//IZP2h9yBvfVwnfSioYcxKA1lby00NKWETkKs+QlJEUI0llLuApBSXhZC9AF+Bh66E+F5c7+hY4c2VK1amRPHYnh/0he4uroCEDZzLisjIgkODuLQgc1cvXaNUaPGOoxG2XLutOvYkgnjbt1y+eO3v/joy/f4a8MCMjIyeOPFiQBUr1GVD6a9w7NPvUJWVhYfvPEZPy2cgZOzM7//9hdxh45Z1MrKyuLlV95h5YrfcHZy4pfZC4mNPczECeOI2b6b8PDV/DxrAbN/mcHB2ChSUy/y1JDnbLpOWmvUqFGNJYt/AsDZxZkFC5ayatV6QkcPBQy2iIiIpGdwEAcPbOZaEeyth+ukFw09jEFpKHtroaEpDnJ7xVYsxo4RQvgDmVJKk3VxIUQ7KWVhpoFSL97vlMdU6+2D8phaWA292FtpFE5D2bvUadg1Lsu1v76wOXZM2b7jHDt2jJQy3kKZA61DKRQKhUJRiimhKyHF5idEoVAoFArFXUKjPSFCCC8hxBIhxEEhxAEhRBshRGUhxGohxBHj30rGukIIMUMIESeE2COEaGqtfTUJUSgUCoWipKPdI7pfAn9LKesDDwMHgDeASCllPSDS+BqgJ1DPmEKB76w1bnFPyF1CcwGFQqFQKBwM++4JWfKh7XtCHnvHYh+FEJ7ALqCOzDNZEEIcAjpJKZOEED7Aeinl/UKIH4zH82+vV5CGXaLo6mSTkeYaGecsPylzp7hWraOL66QXDbVRsXRpKHuXPg27os0jtwHAWWCWEOJhYDvwMlAjz8QiGchxgOUHnM5zfrwxr8BJiLodo1AoFApFSUdKm1Nex6LGdLtjLxegKfCdlLIJcIVbt16MslJyB3c8im0SMjNsConxu9m1M7LAOtOmTuJgKQntfuzYMR4d/nxuatXtEeYu/JMvvv6RkCdHM2DYGF56cxLply7nnnMo7jiDQ1+l3+BnGTB0DDdu3DRpNy39EqNefotej4/k6aefxqkAi6tQ30rjbmroYQxKw3Ha15OGZhRhY2pex6LGdLuL83ggXkq51fh6CYZJSYrxNgzGvzmeJROAmnnO9zfmFUixTULmzFlE7z6mgcxy6BkcRL26AdQ3hnb/Rueh3evUqcPvs7/h99nfsOjnGbi7u9OlY1vatGjCn3O/588531G7ph8/zl0IQGZmFm9M+ox3X3uRZb/+wKyvP8XFxdmk3R/nLqJ188asXPgTbdq0wcuzjN2vVUmzhdJQ9lYayt5aaGiKBk/HGH2EnRZC3G/M6gLEAn8Bw415wzHEmMOYP8z4lExrIM3SfhAoxknIpqitXEi9WGB5SEgP5pbS0O5bYnZR088HX+8atGvVLHdy0ejB+qScOQfAv9Hbue/eAOrXqwOAl6cHzs6mk5B1m/6jX8+uAPTv35/y5Uy3AalQ30pD2VtpKHtrr6Ep2j0d8yLwqxBiD9AYQ/DaT4BuQogjQFfja4CVwDEgDpgJWHUpa3USIoRoKYRoYTxuIIQYK4ToVdjeFxW/UhzaPSJyA726djTJ/3PFKgLbGLy2njydgBCC0FffZuDTL/Dzr4vNtnU+9SLVqlYGoFq1ajg7m26GVqG+lYayt9JQ9tZeQ1M08hMipdxlvFXTSErZX0qZKqU8L6XsIqWsJ6XsKqW8YKwrpZTPSynvlVI+JKWMsda+xadjhBATMDz36yKEWA20AtYBbwghmkgpPyrUKBSFJiMjg/VRW3nlf0/ny/9h9nycnZ3p070zAJlZWezcs58FP36Ju7sbo156kwb316V18yYFti1EsXvoVSgUCoUiF2srIY8B7YAOwPNAfynlB0AP4PGCTsq74zYs7PZ9LoUjoZSGdt+0JYYH7ruXqpVvza6XrljNxs3RfDrh9dyJRI3qVWn2cEMqeXlS1t2d9m1aEHvoqEl7VSp5cfbcBQDOnDlDVpbpJmYV6ltpKHsrDWVv7TU0pQhPxzgC1iYhmVLKLCnlVeColDIdQEp5DShwLSfvjtvQ0Nuf+Ckc4eGrGFoKQ7uvXL2eXt065b6O2hLDz78t5qtPJ1DW3T03v13LZhw5doJr16+TmZlFzK693Btwj0l7nQJbsyxiDQBLly7lytVMu4zDnu0rDcfS0MMYlIaytxYamqLR7Ritseas7KYQopxxEtIsJ9PoRe2ORjBv7jd07NCGqlUrc+JYDO9P+gJXV1fAENp9ZUQkwcFBHDqwmaulJLT71WvX+W/bTia8/lJu3kdTv+VmRgajXzHswm70YH0mvP4inh4VGfbEIzwx8mWEELRv04KObVsC8N7H0xnUvxcNH7iPUUMH8X/vTuaP8H/wq1mLi2mmj/GqUN9KQ9lbaSh7a6+hKQ4yqbAVi27bhRBuUsobZvKrAj5Syr2F0JB68X6nPKZaRk+2sIeG8qBZujSUvUudhn3dtv841na37aOmFvtGQYsrIeYmIMb8c8A5TXqkUCgUCoXCJmS2Y+zxsBW7xI5RKBQKhUKhISX0doyahCgUCoVCUdIpvPMxh8LinpC7RMlcI1IoFAqFoujYdb/F1W9esPm3ttzzXzv2npC7hZt7TeuVisiN64aowXrYyBTj31+z9gGaxy8lKbCzZu37RK0DoGzZWpppXLt2EtCHvdVGxdKloexd+jTsirodo1AoFAqFolgooZOQYgtg98Lzz7Bj+xp27ljDiy+MNFtn6pT3id2/iZhtq2jcuKHNGiUl9LObmxsADVZN48HIGfj+3xO5ZX6vD6bhxm94cN1XVH+mNwAV2zSkceyvNPhnGg3+mYbPK4PM9q1MzerUX/4ZDaO+o8634wyZTk5U/TmMSp9OBsDrvbep9ttsqs75Gc83XwdjEDxRsQKVJk+i6i8/UiXsW1wCapvVcPbxpkrYt1RbMM+k7PvvP+fkye3ExNxy+PP2269w9OhWtmxZyZYtK+nRw/zKTLduHdm9ey379m1g3LgxZuvcTkmxd2nQ0MMYlIbjtK8nDc3QqcdUTWjQ4H6eeeYp2gX2oXmLHvTq1YV769TOVye4R2fq1g2gwYPtee758Xw1Y7JNGiUp9PONG4YnoWO7v0psj1fx6NSU8k3vo8qgIFx9q7Kv4wvs7/wiF5ZF5Z5zOTqW2B6G+knTF5ntn/9bw0mZ+Rf7AseQmXYZgPIDHyXz5KncOtdWreHsU8M5N+wZhFsZyoUYJjoVhg4m40gc50aM4uKHH+Px8otmNSqOeZYrCxdz9okhJmVz5y6mX7/hJvlfffUTrVv3onXrXvzzzzqTcicnJ6ZP/4B+/YbTpElXBg7sS/369Uzq3X5OSbG33jX0MAaloeythYamlFCPqcUyCalfvy7R23Zy7dp1srKy2LhpK/37B+erExLSnXm//g5AdPROvLw88PauXmiNkhr6Wbg4I1ycQUqqDwsmafrC3Blr5vk0m/pXsd1DpK74F4Dziw0/9m5tWnN1+YrcOje2bM09zog9iHP1agC41K7Nje07Acg6dRpnnxo4VTKNFunWtAnX128wq795czQXLly0qc8ALVo05ujRE5w4cZqMjAwWL15Onz7dLJ5TUu2tRw09jEFpKHtroaEp2dL25ADYPAkRQsy5U9HY/YcIbNeSypW9KFvWneAenfHPEzgIwNfXm/g8YZUTzIRVtkRJDP3c4J9pPLx7NumbdnNl5xHcanlTOSSQB1Z8Qb257+IW4JNbt0Kz+2mwahr15r6L+32mG39dKlUkK/0KZBlmuzeTzgOQ/t0P5h/lcnambI9uXN8SDUBm3FHcO7YHwPWB+jjX8MbJOEHJQXh6kH35cq5GYfnf/4YRHf0333//OV5eHiblBtsn5b5OSEjCz8+y7UuivfWqoYcxKA1lby00NEVm254cAIuTECHEX7el5cAjOa+LKnrwUBxfTPmWFeG/snz5PPbsiSUrK6uozemG2B6vsqfFKMo3rof7/fcgyriSfSODA73Hcfa31dT+wnBL5Mreo+xpFUps91c5M2sldX9602rbFQMbAZB56LDZcs//e4Wbu/eQscfgif/yvN9wqlCBqrNmUu7RAWQcOQJ3wUYzZ86jQYMOtGrVk+TkM3zyybt33KZCoVCUenS6EuIPpANTgSnGdCnPsVmEEKFCiBghRExYWJjZOr/8spA2bXvTtetjpF5M48iR4/nKExOT862O+JkJq2yJkhr6OSv9Cpf+3YtnpybcTDpPasR/AFyM2ELZBwyPvmZfvkb21esApK3djnBxwaVSxXztZKZewtmjPDgbTOzR7iEAqi2ej9fE93Br1gSvd98CoMLTw3Dy8iL9q29zz5dXr5L28Wece3o0aR9+jJOXF1mJSfk0ZFo6ThUq5GoUhjNnzpGdnY2Ukp9/nk/z5g+b1DHY/taqj5+fDwkJlm1fUu2tRw09jEFpKHtroaElMjvb5uQIWPv1aA5sB94G0qSU64FrUsoNUkrzGwEAKWWYlLK5lLJ5aGio2TrVqlUBoGZNX/r3C2bBwqX5ysPDVzNk8KMAtGzZhLS0SyQnnyncqChZoZ+rVq2ceyzcy+DRvjHX4xK4+M9WKrY1TB4qtmnIjWOGZUCXal659cs3rgdOgszUSybtXvp3L5V6twUg+5ph8+vZgU9yceIkbmzfycUPJlO2Ty/cWrYgdeIH+XZLiwrlwcXwBHfZkN7c3L0HefWqicaNnTtx79SxEFfLQN59Pf369SA29pBJnZiY3dStG0CtWobrOnBgCCtWrLbYbkmyt9419DAGpaHsrYWGwhRrAeyygWlCiMXGvynWziksCxaEUaWyFxkZmbz8yjukpaUzepThCYuZP84j4u+1BAcHcSA2iqtXrzE69P9sar8khX728akBQIPV0xFCcCF8M2mRMVzedoCAr16lxui+ZF+5xonXvgGgUu+2VB8ajMzKIvv6TY4990VuW/XmvMuJ174mIyWV+MlzuPfb/xiYq+QAACAASURBVMPv9cFc3Wc+Qq/nuLFkpSRT9QdD29c3bOLyL3NwqVULr3feACnJPH6Ci598nntOpc8/Ju2TL8g+f55L34XhNfFdKo42fcx69uwZtG/fhqpVKxEXt4UPPphGhw6tadSoAVJKTp6M58UX3zJeg+p8++1nDBgwgqysLF599T2WL5+Ds7Mzs2cv4sCBI3axhdJQod2VhrK3Vhqa4iC3V2zFJrftQojeQDsp5Vs2aEjlMbVwGspjqnWUx1TH0dCbd0tlb+vtgz5sYScNu7pEv/LhEJtnIeXfmVey3LZLKVcAK6xWVCgUCoVCYT9K6EqIctuuUCgUCkVJx0E2mtqKmoQoFAqFQlHSKaErITbtCSkiJfPKKBQKhUJRdOy7J+TdQbbvCflgUcnaE1JkEX1sMtJcQ8sNnWDY1Onufo9m7V+/bohJ82CNVppp7E8xuJnXg73VRsXSpaHsXfo07EoJXQlRt2MUCoVCoSjhOIrzMVsplgB2oJ+wzFpofP/955w8uZ2YmPyOcsaMGcGuXZFs376ajz4y76q9W7eO7N69ln37NjBu3JgCNX744XNOndrB9u23nIBNnvwWu3evZdu2f1i4MAxPT9O4Ljkae/asY//+jYwbV/Bz8sOefYJlG+azdMNvfP79B5RxK8NTzzxGxJYl7E/ZildlzwLP7TeoFyv/W8LK/5bQb1CvAuvlpaTaW48aehiD0nCc9vWkoRk6dduujahOwjJrpTF37mL69RueL69Dhzb06dONli170qxZN6ZPN3WH7+TkxPTpH9Cv33CaNOnKwIF9qV+/nkm9HI2+fYfly1u7dhNNm3ajRYseHDlynNfMfAidnJz48ssP6ddvOI0bd2HQIPMa1b2rMXjU4wzqMYL+HZ/CycmJXv27sSN6DyMHvkjCqUSTc3Lw9PJgzLhRPNnzGZ4Ifpox40bh4VmxwPo5/Sqp9tabhh7GoDSUvbXQ0BQ1CSk8egnLrJXG5s3RXLhwMV9eaOgQvvjiW27evAnA2bPnTc5r0aIxR4+e4MSJ02RkZLB48XL69OlmViMqKprU1Pwaa9Zsyg0kGB29A39/08i1ORo5Y168eDkhId3Najg7O+Pu7mb4W86dM8nnOLjvMImnk8zWz6Fd59b8tyGatIvppKdd4r8N0QQGtbF4Tkm2t9409DAGpaHsrYWGpugxiu7tCCEChRBjhRDmf3UKiV7CMtsz9HPdugG0a9eSjRuXsmrVQpo1a2TaH19v4uNv/cAnJCTh52c6kSgMw4c/zj//rC9A49aYExKS8PWtYVLvTPJZfvnuV9bsWMb6PSu4nH6ZfzdsLZR2de9qJCem5L5OSTxDde9qFs/Ri731oKGHMSgNZW8tv881QaOVECHECSHEXiHELiFEjDGvshBitRDiiPFvJWO+EELMEELECSH2CCGaWmvf4iRECBGd53g08DVQEZgghHijUCNQ3BVcXFyoXNmLDh3689Zbk5k371vrJxWR8eNfIDMzk/nz/yxyGx6eFQkK7kD3FgPo/HBvypYrS59Hg+9iLxUKhUKRg8yWNicb6CylbCylbG58/QYQKaWsB0QaXwP0BOoZUyjwnbWGra2EuOY5DgW6SSnfB7oDgws6SQgRKoSIEULEhIWZ7l3QS1hme4Z+TkhIYunSvwFDlNns7Ox80XcBEhOT8ff3yX3t5+dDQkL+/lhj6NDH6NmzCyNGvGS23KBxa8x+fj4k5lm1yKF1hxbEn0ok9fxFMjOzWLNiHU1aPFSoPpxJPot3ntWVGr7VOZN81uI5erG3HjT0MAaloeyt5fe5Jth3T0g/YLbxeDbQP0/+HGlgC+AlhPAx10AO1iYhTkKISkKIKhgcm50FkFJeATILOklKGSalbC6lbB4aGmpSrpewzPYM/bx8+So6djTsi6hbN4AyZVw5d+5CvjoxMbupWzeAWrUM/Rk4MIQVK1aba84s3bp1ZOzYMTz22EiuXbtutk6ORs6YBw4MITzcVCMpIYWHmzbEvawbAK3bt+DokROF6sfmdVto26kVHp4V8fCsSNtOrdi8bovFc/Ribz1o6GEMSkPZW8vvc03IzrY9FQ4JrBJCbBdC5Pyg15BS5tz7TwZy/mv0A07nOTfemGehdSkLTMAJ4Bhw3PjXx5hfAdhl6dw8STq7+pqkPiFD5KHDR2Vc3HH5zrufSGdXX/nBh1NlvwHDpbOrryxXIUAuXrJcHjlyTEZH75B172tttp0c9KDh7n6PdHe/Ry5cuFQmJqbImzdvyvj4RPnss6/JihXvlb/99ofct++g3LFjr+zR4wnp7n6PDAhoLiMi1uae26/fcHn48FF59OgJ+d57n+Xmu7vfI6WU0s2tpnRzq5lP4/TpRPnss+NkXNxxefp0gty1a5/ctWufDAubK93casratZvLiIjI3HP79h2WR+PT3PwcGlRvKRtUbym/+XymPHr4uDx8IE4uW7RSPuzfTn701hcyKSFFZmRkyJSkM3LxvKWyQfWWcmC3YbnHDaq3lG+//IE8eeyUPHnslHzrpUm5+Xqyt7n8kqShJ1soeyt7a6BRmN/Hu5bSxwRLWxOGOxwxeVLo7e0Cfsa/1YHdQAfg4m11Uo1/w4HAPPmRQHNL/S6S23YhRDnjTOh4IapLvXi/Ux5TLaM8ptqmoTxoli4NZe9Sp2FXl+iX/hds8495xe//tqmPQoiJwGVgNNBJSplkvN2yXkp5vxDiB+PxfGP9Qzn1CmqzSI/oSimvFnIColAoFAqFogQihCgvhKiYc4xhP+g+4C8gx5nVcGCZ8fgvYJjxKZnWQJqlCQgot+0KhUKhUJR4inJXoxDUAP4UQoBhvvCblPJvIcQ2YJEQYiRwEhhkrL8S6AXEAVeBp60JqEmIQqFQKBQlHQ08oEopjwEPm8k/D3Qxky8BU1fbFijSnhAbcQzfsAqFQqFQ2A+77glJH9nN5t9aj59W27WP5rDLSohONhmpjWuFaB/sY4t2fkGaaWxOWAsoexemfdDHZ88eGsrepU/DntjofMxhULdjFAqFQqEo6ZTQSUixBLAD/YRlVhrF0/7cyJ9yjzv36ci8tT+z6fQa6je6Lzffo5IHXy2ewurDKxj7oXkPsAAVvSoyff5nLIiaw/T5n9l1HHrV0MMYlIbjtK8nDc3ILkJyAIplEqKXsMxKwzHaP3bwOG+NnsCuLXvy5d+8fpOZn83imw++t3j+0OefJCZqJ08EDiMmamexjUMvGnoYg9JQ9tZCQ0s0jh2jGcUyCdFLWGal4Rjtn4w7xamjp03yr1+7zp5t+7h546bF89v3aEfE4n8Acv8Wxzj0oqGHMSgNZW8tNDTFvrFj7hrFMgnRS1hmpeE4ob7vhEpVK3H+jCEOT85fc+jBFvbQ0MMYlIayt6N9T1mlhN6OsbgxVQjRCjggpUwXQpTFEK63KRALTJZSptmhjwqFQqFQKCzgKLdXbMXaSsjPGLyeAXwJeAKfGvNmFXSSECJUCBEjhIgJCwszKddLWGal4Tihvu+E1HOpVKleGSD3rzn0YAt7aOhhDEpD2dvRvqesUkJXQqxNQpyklJnG4+ZSyleklFFSyveBOgWdJKUMk1I2l1I2Dw0NNSnXS1hmpeEY7d8pUav+pedAw73fnL/m0IMt7KGhhzEoDWVvR/ueskZJ3ZhqMTQwsBh42ng8C2NIXuA+YFshQwzrJSxziQ7DrbdQ3xk3M2RK4hk5eexn8o1n3pUpiWfkjes35Pkz5+WWddGyrW9n2da3s0w8lSTTLqTJK5evypTEM/KpjiNkW9/O8q9fw+Uzwc/Ktr6dZfCD/eS2TdvlqWOnZfTGGGVvB7S3HjSUvR3HFnbSKMzv411L5/t2kLYme/fRXLLotl0I4YnhNkx74ByG/SCnjeklKeXuwsxz9OL9TnlUtN4+KI+phUHZu/RpKHuXOg27ukQ/H9LR5qWNKss3OLbbdmnYeDpCCOEBBBjrx0spU+zROYVCoVAoFIXAQfZ42Eqh3LZLKdOBwqx6KBQKhUKhsDOyhE5Cis1tu0KhUCgUitKNxT0hdwkH2YKrUCgUCoXdsOt+i3M9bN8TUvUfB98TctdE9LHJSG1cK0T7YB9bVPO8XzONs2mHAKjqcZ+VmkXnXPphXDW2d4aO7K0HDfX5Ln0a9qSk3o6xyyREoVAoFAqFdpTUSUix7QmZGTaFxPjd7NoZWWCdaVMncTA2ih3bV9OkcUOb2vf392XNqsXs2b2O3bvW8uILI++6BugnvLTWGlrY282tDP+sXcy6qGVs2hLO62++CED7jq2J3PgH6zYtJfzv3wioc4/Z818eG0r0zlX8F/M3nbuYD0Tl5laGVeuWsH7zX0RtXcH4t14C4KvvPmH7nkjWRS1jXdQyGj70gNnzH39qANE7VxG9cxWPPzXA6pgAjhzews4da4jZtoot/600W2fa1EkccOD3rR7es0rDcdrXk4ZWyGzbkyNQbJOQOXMW0bvP4ALLewYHUa9uAPUbBDJmzHi++fpjm9rPzMzktdffp9HDnWkXGMKYMSNMwjLfqYZewkvbQ0MLe9+4cZNHQobTObAfnQP7E9S1Pc2aP8znUyfyv1Hj6Ny+P78vCWfsuDEm5953/730f6Q3ga168/ijo/h0ygScnEw/Djdu3GRAn2F0ateXTu36GTRaPAzAxHc/M2r3Y9/eAybnelXy5LXxL9A9aCDdOj/Ga+NfwNPLw+q4ALp2G0jzFt1p3aaXSVlwcBB16wbwgPFafe1g71u9vGeVhmO0rycNTZHC9uQAFNskZFPUVi6kXiywPCSkB3N/XQLA1ugdeHp54u1dvdDtJyefYeeufQBcvnyFgweP4HdbRMQ71dBLeGl7aGhl7ytXDKGNXF1dcHV1MXrhg4oVKwDg4VGB5OQzJuf17N2FpX+s4ObNDE6djOfEsZM0bdbIuoaLC4XdzB3UJZAN6zZzMTWNtIvpbFi3mS5d2xfqXEv0DenBPAd+3+rlPas0HKN9PWloiVoJucv4+XoTf/pWWOWE+CSTSURhqVXLn8YPN2Rr9M67qqGX8NKOEMK6qLZwcnJi3aalHIj7l/Xr/mXH9j28+uLbzF8Sxu7YDQx8vB9fTjMNoujjU4OE+FvBqRITU/DxrVGwRtQyDhz9j/XrNrMjZg8Ab7/3Khv+/YsPP36TMmVczWskJOXRSMbHx7xGXqSURKycz9YtEYwaabp65Ovg71u9vGeVhrK3vb8H7wSZLWxOjoDFSYgQ4iUhRE17dUYLypcvx6KFMxk7bgKXLl0u7u4o7jLZ2dl0bt+fRg060rRpI+o/UI9nnx/Bk4+F8nCDjsz/9Q8+mPzmnWsE9qPRAx1o2syg8eHEKbRuFky3To/iVcmLl141DdRYVDp1HkDLVsH0CRnCmDEjCAxsddfaVigU+kSvKyEfAFuFEJuEEM8JIaoVplEhRKgQIkYIERMWZvpfaGFISEzGv+atsMp+/j4k3BZW2RouLi4sXjiT+fP/ZOnSiLuuoZfw0o4QwvpObZGedomoTVvp0q0DDzasz47thtWKpX+spEXLJib1k5JS8PO/9V+Or28NkhItRyPI1ejanpSUswDcvJnB/Hm/m72Vk5SUgp+fTx4Nb5KSrEc8yLn2Z8+eZ+myCFq0aGxS7sjvW728Z5WGsre9vwfvBCmFzckRsDYJOQb4Y5iMNANihRB/CyGGCyEqFnSSlDJMStlcStk8NLRo/yGGh69i6ODHAGjVsinpaelm7+1bYmbYFA4cjGP6l+YnQneqoZfw0o4QwrootqhSpRIenoa3obu7G506t+XwoaN4eFSkzr21AejUuR1HDh81OffvlWvp/0hvypRx5Z5a/gTcWzt34mJJo2Pndhw5cowaNW7Nx3v26cqB2CMm566NjKJTUDs8vTzw9PKgU1A71kZGWRxTuXJlqVChfO5xt64d2b//UL46y8NXMcSB37d6ec8qDcdoX08aWlJSV0Ks+QmRUspsYBWwSgjhCvQEngS+AAq1MmKOeXO/oWOHNlStWpkTx2J4f9IXuLoa7quHzZzLyohIgoODOHRgM1evXWPUqLE2td+ubQuGDnmMPXtjidlmeCO9++4n1Kzpd9c0srKyePmVd1i54jecnZz4ZfZCYmMPM3HCOGK27yY8fDU/z1rA7F9mcDA2itTUizw15LlSqaGFvWt4V+fr7z/ByckZJyfBsj//ZvU/6xn70jvMmjuD7GxJ2sU0Xn7hLQB69AyicZOGfDp5BocOxvHX0giioleSlZnFG/83iexs00+lQeNTnJ2dcHJyYtmfEaz6ez1/Lp9NlaqVEUKwb+8Bxr0yAYDGTRoy4pkneeXFt7mYmsaUz75l9frfAfji02+4mJpmeUw1qrFk8U8AOLs4s2DBUlatWk/o6KG51yoiIpKewUEcPLCZaw74vtXLe1ZpOEb7etLQEkfZ42ErFt22CyF2SilN17INZeWklFcLoSH14v1OeVS03j4oj6mFQXlMLX0a6vNd6jTsOis41byLzW7b74mJLPaZi7WVkMcLKijkBEShUCgUCoXGlNSVEIt7QqSUh+3VEYVCoVAoFEVDy0d0hRDOQoidQohw4+sAIcRWIUScEGKhEKKMMd/N+DrOWF7bWtsO6ydEoVAoFApF4ZDS9mQDLwN53UJ/CkyTUtYFUoGcuCgjgVRj/jRjPYtY3BNyl9BcQKFQKBQKB8Ou90eOPdTd5t/aOntXWe2jEMIfmA18BIwFQoCzgLeUMlMI0QaYKKXsIYT4x3j8nxDCBUgGqkkLEw21EqJQKBQKhaIgpgOvAzmPD1YBLkopM42v44GcXb5+wGkAY3masX6BWNuYelfQyU5ntXu+EO2DPmxhDw13d/PRfe8W16+f0sV10ouG+nyXPg17UhTnY0KIUCCvM68wKWVYnvI+wBkp5XYhRKc77qQZ7DIJUSgUCoVCoR1FcT5mnHBYcmveDugrhOgFuAMewJeAlxDCxbja4Q/kzLoSgJpAvPF2jCdw3lIfiu12TI/undi/byMHY6N4/bXnTcrLlCnDb79+x8HYKP6NWk6tWv5KowRrzAybQmL8bnbtjCywzrSpkzgYG8WO7atp0rihzWOwh4YW1+mHHz7n1KkdbN++2qTs5ZdHc/36qQKDZA0Z8hj79m1g374NDBnyWLGOw57tKw3H0tDDGOyloRXZUticrCGlfFNK6S+lrA08AayVUg4G1gE5XzjDgWXG47+MrzGWr7W0HwSKaRLi5OTEjC8/ok/IEB56uDOPP96fBx6ol6/OM08/SWpqGvUbBDJ9xkw+nvy20ijBGnPmLKJ3H9OIsDn0DA6iXt0A6jcIZMyY8Xzz9cc2tW8PDa2u09y5i+nbd5hJvr+/D127duDUqXiz51Wq5Mnbb79C+/Z9CQzsy9tvv4KXl2exjcNe7SsNx9LQwxjspaEldo4dMx4YK4SIw7Dn4ydj/k9AFWP+WOANaw0VyySkZYsmHD16guPHT5GRkcGiRcvoG9IjX52+Id2ZO3cxAL//voKgzoFKowRrbIrayoXUiwWWh4T0YO6vSwDYGr0DTy9PvL2rO5SGVtcpKiqaVDP9/uyzCbz11mQK+keiW7eOREZuIjU1jYsX04iM3ET37h2LbRz2al9pOJaGHsZgLw0t0dJPCICUcr2Uso/x+JiUsqWUsq6UcqCU8oYx/7rxdV1j+TFr7VqchAghygghhgkhuhpfPyWE+FoI8bwxjkyR8PXz5nR8Yu7r+IQkfH29C6yTlZVFWlp6gUvSSsPxNazh5+tN/OlbfUiIT8Lvtj4Ut4Y9r1OfPt1ITExm794DBdbx9fUmPk9/Esz0x+x5Go9DL+9ZpaHsbe/vwTtBYz8hmmFtY+osY51yQojhQAXgD6AL0JJb937ykXfH7Q8//HDXOqtQlAbKlnXn9ddfoE+fIcXdFYVCUULQpdt24CEp5ePAAKA78JiUci7wNGA2sB0YdtxKKZtLKZuHhoaalCcmJFPT3zf3tb+fD4mJyQXWcXZ2xtPTg/PnUws3KqXhcBrWSEhMxr/mrT74+fuQcFsfilvDXtepTp1a1K5dk23b/ubQoc34+fmwZctKatTIH7Q6MTEZ/zz98TPTn+IYh17es0pD2dve34N3ghYbU+2BtUmIk9EnfEWgHIbHbQDcgCLfjtkWs4u6dQOoXbsmrq6uDBrUj+Xhq/LVWR6+iqFDBwLw6KO9Wbd+s9IowRrWCA9fxdDBhs3WrVo2JT0tneTkMw6lYa/rtH//Ie65pyn339+O++9vR0JCEq1b9yIl5Wy+eqtXb6Br1/Z4eXni5eVJ167tWb16Q7GPQy/vWaXhGO3rSUNL7Lwx9e4hpSwwAa8Cx4CTwEtAJDAT2AtMsHRuniSdXX1NUp+QIfLQ4aMyLu64fOfdT6Szq6/84MOpst+A4dLZ1VeWqxAgFy9ZLo8cOSajo3fIuve1NttODnrQMJdfkjQsXaf5C/6UiYnJ8ubNm/L06UQ5avRYOea58XLMc+Nz63zz7SwZF3dc7tkbK1u2CrbZFvbQuJu2cHOrKd3casqFC5fKxMSU3H4/++y43DI3t5ryxIlT0te3kXRzqynbtOktf/75t9yy0ND/k3Fxx2Vc3HE5evTYfOcVp71L2mdPfb6VvTXQKMzv411Lu2v1kbYme/fRXLIaO0YI4WucrCQKIbyArsApKWV0Yec5evF+pzwqWm8f9GELe2goj6mlS0N9vkudhl2XGnbV6mvzVtPGJ/8q9uUQqx5TpZSJeY4vAks07ZFCoVAoFAqbcJjbKzai3LYrFAqFQlHCcZRHbm3F6u2Yu0AJvTQKhUKhUBQZuy5NxPj3t/m3tnn80mJfPlErIQqFQqFQlHDU7RhLIvrYZKQ2rhWifdCHLeyhYQ97h9zTR7P2l58KB/RhC3toqM936dOwJ47i98NWii2KrkKhUCgUitJNsU1C9BKWWWk4RvtKwzxzd8zj69XfmOT3Hz2A5afC8ajkkZvXsPVDfBkxg2/WfMPHi8xHGK5RswZfLJvCDxvD7DYGpeH4GnoYg700tEIWITkCxTIJ0UtYZqXhGO0rjYI1Jg6bYJJX1acqTTo04Uz8LW+x5T3KM+ajMXw48gOe7/o8n4z5xGx7I94cwbIfl/FsB9NwDFqNQWk4toYexmAvDS3Rq9t2TdBLWGal4RjtK42CNS5dvGSSN2rCaGZNnkXeJ+M69uvIfxH/cjbR4Bo+7Xya2fYatW3E5pVRdh2D0nBsDT2MwV4aWlJS3bZbnYQIIeoIIcYJIb4UQkwVQvxPCOFh7TxL6CUss9JQob5Lmkarbq04n3yeEweO52+zjh8VPCsweeHHTFsxnc6PBpmc61HJg8vpV8jOyi7WMSgNx9LQwxjspaEl2UVIjoDFSYgQ4iXge8AdaIEhcF1NYIsQopOF80KFEDFCiJiwMMv3jhUKhX1wc3dj4AuD+HXKPJMyZ2dn7n2oLu+PmMiEIe/xxEtP4Bvga6YVhULhiEiEzckRsLYSMhroKaX8EEPMmAellG8DwcC0gk6SUoZJKZtLKZuHhpreO9ZLWGaloUJ9lyQN71re1KhZgxl/f8WPm3+iqk9Vpq+cjlc1L84nn2Pnxh3cuHaD9NR09m3dR0CDgHznp6emU8GjPE7Olr82Svp1Uhrq862VhpZkS9uTI1CYPSE5vkTcgAoAUspTgGtRRfUSlllpOEb7SqNwGicPnWRo0yGMajeSUe1Gci7pHK/0eoWLZy+yZdUWGrR4ECdnJ9zc3bi/yf2cPhJv0sae//bSrpfl++Al/TopDfX51kpDS7IRNieHwFKIXeBlYA8wEzgIPG3MrwZsLGSoXr2EZS7RYbhVqG/H07CHvc+nnJcZNzPk2cSz8stx02Wfmr1zU/KpZPlUoydzX//04U/y5OGT8sTBEzJs4g+5+dsit8lhzYfKPjV7y5HtnpGHdh6SCccTdGULvdhbfb4dSuOuh723lNZUHyRtTfbuo7lkNXaMEOJB4AFgn5TyYFHmOXrxfqc8KlpvH/RhC3toKI+p1lH2dhwNPdnCThp2XWpYXeNxm2+wdEtZWOzLIVbdtksp9wP77dAXhUKhUCgURcBRNpraigpgp1AoFApFCcdRHrm1Fau3Y+4CDrIHV6FQKBQKu2HXpYmVNZ6w+be2V8qCYl8+USshCoVCoVCUcNTtGEsi+thkpDauFaJ9sI8tXDXUyNCRvf0qPahZ+wmphq1iLXw7aKaxLXEjAGXctAsUdvOG4VFkPdhbL59vvWjYk+ySOQdRKyEKhUKhUJR0HMbvh40USwA70E9YZq01/P19WbNqMXt2r2P3rrW8+MJIs/WmTZ3EwdgodmxfTZPGDR1uHPawxZHDW9i5Yw0x21ax5b+VZutMmzqJAw58nbTUcHJy4p8NS5i94BsA2rVvxd/rFxP571KmfzsZZ2dns+cNfKIfUTEriYpZycAn+pmUL1j7S+6xh1dFvl4whd+jfuPrBVOo6FkBgFp17+Gnv75l8/E1DPnfEwX20bemD7PCv+ePzb8x+fuJFsfj6enBgvk/sHfPevbsXkerVk1N6kydOonY2Ci2x6ymcSmztz019DAGe2lohSxCcgSKZRKil7DM9tDIzMzktdffp9HDnWkXGMKYMSNMNHoGB1GvbgD1GwQyZsx4vvn6Y4cahz1DZHftNpDmLbrTuk0vk7Lg4CDq1g3gAeN1+trBrpPWGqP+N5Qjh48BIIRg+ncf8dzIcXRp25/404kMfNJ0guHl5cmr48fQp+uT9O7yBK+OH4OnZ8HxK4e/MJhtUTt4NPAptkXtYPgLQwCDy/cp785g3vcLLPbxhbef5beZi3ik3VOkm4kAnJepU97nn1XreahRJ5o1787Bg3H5ynPs3aBBIGOeG8/XX5Uue9tLQw9jsJeGwhRrAew8hRCfCCEOCiEuCCHOCyEOGPO8iiqql7DM9tBITj7Dzl37ALh8+QoHDx7B77bIgBfojQAAIABJREFUjiEhPZj76xIAtkbvwNPLE2/v6g4zDkcJkd03pAfzHPg6aanh41uDLt07MH/O7wBUquzFzZsZHDt6EoCN6/+lV99uJud17NKOTev/4+LFNNLS0tm0/j86dS1Yr2OPQMIX/Q1A+KK/6RRsqJt6/iKxuw+SmZllsZ8tApuyNnwDACsW/11gPQ+PigS2b8WsWfMByMjIIC0tPV+dkJDu/DrPYO/o6B14eXmUGnvbU0MPY7CXhpZoEUVXCOEuhIgWQuwWQuwXQrxvzA8QQmwVQsQJIRYKIcoY892Mr+OM5bWtaVhbCVkEpAKdpJSVpZRVgM7GvEWFGINZ9BKW2d6hn2vV8qfxww3ZGr0zX76frzfxp2/1IyE+yWSiYgk9hPoGQwiCiJXz2bolglEjB5v2w8Gvk5Ya709+gw8nTCE72/DVc+F8Ki4uLjRqbNi42rtvd3z9TK+Ft091EuNvBfFKSkjB26fgH/LKVStx/sx5AM6fOU/lqoUfu2dlTy6lXSYryzBROZN0tsC6AbVrcu7sBX6cOZXorX/z/XefU65c2Xx1fH2tX0tLlGR721NDD2Owl4aWZAthcyoEN4AgKeXDQGMgWAjRGvgUmCalrIthPpCzT2AkkGrMn2asZxFrk5DaUspPpZS530JSymQp5adArcKMQHF3KF++HIsWzmTsuAlcunS5uLvjkHTqPICWrYLpEzKEMWNGEBjYqri75BB07dGRc+cusHd3bL7850aOY+Lk8YSvWcCVy1fJzrr77o60ckPk7OJCkyYN+SFsLi1bBXPl6lWz9/AVitKCFntCjDFwcn5wXI1JAkHAEmP+bKC/8bif8TXG8i5CWJ7tWJuEnBRCvC6EqJGTIYSoIYQYD5wu6CQhRKgQIkYIERMWFmZSrpewzPYK/ezi4sLihTOZP/9Pli6NMClPSEzGv+atfvj5+5BwWz+Kcxz2uk45bZ49e56lyyJo0aKxSbkjXyetNJq3akL34E5s2b2Kb3/6gnbtWzHjh0/Yvm03j/QaRp+uT7Dl3xiOxZ0wOTc56Qy+/rf+G/Txq0Fy0pkCtS6cS6VK9SoAVKlehVQbxp52IY2KnhVyN8hW96lWYN2EhCTi45PYts2wKvjHHyto3OShfHUSE61fS0uUVHvbW0MPY7CXhpYU5XZM3t9qYwq9vV0hhLMQYhdwBlgNHAUuSikzjVXigZznnf0wzg2M5WlAFUv9tjYJedzYwAbjnpALwHqgMjCwoJOklGFSyuZSyuahoSZj0k1YZnuFfp4ZNoUDB+OY/qXphA4gPHwVQwc/BkCrlk1JT0snObngHwp7j8Me16lcubJUqFA+97hb147s33/IRGOIA18nrTQ+mTSd5g270Prh7jw3chybN23lpWffoErVygCUKePK8y+PZO4s0zusGyI306FzWzw9PfD09KBD57ZsiCxYb+OqzfQZFAxAn0HBbPgnyqbxx2zeSVCfjgD0HhhcYL2UlLPExydy3311AAjqHMiBA0fy1QkPX8XgIQZ7t2zZlLS0S6XC3vbW0MMY7KWhJdnC9pT3t9qYTH5kpJRZUsrGgD/QEqh/N/tt0U+IlDIVGG9M+RBCPA3MKopoVlYWL7/yDitX/IazkxO/zF5IbOxhJk4YR8z23YSHr+bnWQuY/csMDsZGkZp6kaeGPFcqNdq1bcHQIY+xZ28sMdsMH4h33/2EmjUNE8+wmXNZGRFJcHAQhw5s5uq1a4waNdahxmGP61SjRjWWLP4JAGcXZxYsWMqqVesJHT0UMFyniIhIegYHcfDAZq454HWyl0YOY156mq7dO+Lk5MScnxeyedNWABo1fpChTw/itZcncPFiGtM//54VaxcCMO2z77h4MS1fO7XuvYfwmCWETZnF7K9/5ePv36fvE71JTkjmzWcnAFClWmVmR4RRvmJ5ZHY2T4x6jMc7DePK5atMn/sZH477lHMp5/n6o+/56LuJjHl9FIf25Z9U3M6rr77L7F++okyZMhw/fpJRo/+P0aMNT+PMnDmPiIi1BAcHceBAFNeuXmfU6NJpbz18vvWioSVa+wmRUl4UQqwD2gBeQggX42qHP5DjnS0BqAnECyFcAE/gvKV2ixw7RghxSkp5T2H6rhfvd8qjovX2QXlMLQzKY2rhUB5THUdDT9+1dtKwq/eweb5DbP4xH5I4z2IfhRDVgAzjBKQssArDZtPhwO9SygVCiO+BPVLKb4UQzwMPSSn/J4R4Anjk/9s78/goquxvP4dFoygERCELm+Iy6qgwUVAWhx2RRWfUUUFxRXF/FbdBZXT8KaPiII5bGARBBERHRiIqq2wOhLAEkEXCnoQQkRBERUDO+0c3MaS700u6Op3iPHzuJ9V1q863Tp1eLlW3zlHV68rTKPdKiIisDNQFNAjQZxiGYRhGDHEobXsS8J6IVMczfeNDVc0QkTXARBF5HlgOjPJuPwoYJyI5wG4gcGZCL8HStjcAuuF5BKc0AnwdshuGYRiGYThG9J9tA1VdCbTws34TnvkhZdfvp5z5ov4o93aMiIwCRquqz+wyEflAVW8MQSNessMahmEYRqyI6e2Y0Snh3465Na/82zGxINjEVP+FSjx9oQxADMMwDMNwGKuiW56IOyYZ2cS1EOyDOyaNxkLDLfGOhUZCQihz4CNj//5tgMU7FPvgjs9erDRiiRO3Y2JBTAYhhmEYhmE4R1UdhFRKFV1wT1lmpzVGpg8jPzebFctnBdzmn68+x7oKlKcHZ/04/vjj+XphBkuzZrBixWyeeeYRv/bHj3+LtWsWsDBOY+EWjdTUZGZOn8zK7Dlkr5jN/ff5v+sa6fvKKfvvvPMy27YtY+nSGT59Dz54J/v3bwtYx6Nfv2tYvXouq1fPpZ83gVkouCHesdBwgw+x0nAKlfBbPFApgxC3lGWOhcbYsR9yZU/fYmxHuKJ7R85s3oxzvOXp3wizPH0s/Pjll1/o0vU6/pDWhbS0rnTr+kdaXdLSx/6eomJ+d25bXhsxkhfiMBZu0Th06BCPPvYsF1zYgTZtezFw4C0+GhV5Xzllf9y4yfTufbPP+tTUJDp3bs+2bbl+96tbtw6DBz9Eu3a9adu2N4MHP0RiYp2gem6Jt9MabvAhVhpO4kQV3VgQ8SBERHyLmISIW8oyx0Jj/oLF7C7aE7C/V69ujKtAefpY+fHjjz8BULNmDWrWrEnZp7J6VYFYuEWjoKCQ5StWA7Bv34+sW7fBp5pwRd5XTtlfsCCTIj+fhZdeGsJf//qCz3vqCF26XM6sWfMpKipmz55iZs2aT9eulwf1wy3xdlrDDT7ESsNJXDkIEZGWAdof8JT1jQi3lGWOh9LPKRUsT1/2GMEZP6pVq0bWkunk561k5qx5ZHoLj0XLvlviHev3VJMmqVx04fkszjw6HtF4X8XCfs+eXcjPL2DVqrUBt0lObkhuqXOa5+ec+t3PJfF2WsMNPsRKw0mcqKIbC4JNTF0CzMX/886J0T8cw60cPnyYtIu7UqdObT6aPIrzzjvbp8CcEVtq1TqRDyeN5OFBQ/jhh33Bd4gz+yeckMBjj91Hz579om7bMIzYEOx2zFrgLlXtULYBuwLtVLo8cHq6b+VXt5RljofSz3kVLE9f9hjBWT+Ki/fy1dyFdO36x6jad0u8YxWLGjVqMHnSSCZM+IQpU3zvrFb0feW0fYDTT29C06aNWLLkC9avX0hKShKLFk2jQYNTj9ouP7+A1FLnNMXPOfWHW+LttIYbfIiVhpNEUkU3Hgg2CPlbOdvcH2in0uWBBwwY4NPvlrLM8VD6OSNjOjdVoDw9OO9H/fr1qFOnNgAJCQl07tSe9es3+voR57FwiwZ4nrpauy6H4a/5/icBKv6+cto+wDffrKdx45acfXYbzj67DXl5O2jdugc7d3531HYzZsylc+d2JCbWITGxDp07t2PGjLlB7bsl3k5ruMGHWGk4SVWdExIsY+pH5XRHfCPMLWWZY6Hx/rg3uLz9pdSvX48tm7J49rlXqFmzJuApTz/t81l0796R9WsX8lME5elj4UdSUgPeHTWc6tWrIdWq8dFHU5k2bSZDhgxiaSn7Y8aMYK3Xft84jIVbNNpcdjE39buGlavWkLXE8yX79NNDadTIk7ypou8rp+yPHfs67dpdSv36dcnJWczzz7/KmDGT/G7bsuUF3HlnXwYOfJyiomJefHEECxdOBeCFF16jqKg4qJ5b4u20hht8iJWGk8TLoCJcyq0dU+6OIttUNZQ0huqW7HeWUTG4fbCMqaFquCXeljE1OBbvY1Ijpjc8Xmkcfu2YQdvivHaMiKwM1IWnwq5hGIZhGJVMvMzxCJdgT8c0ALoBZWfeCPC1I0dkGIZhGEZYVNXbMcEGIRnASaq6omyHiHwVqkgsivm4QcMNPsBvt0ycxA3nyg0+xErjyC0TJ7F4m0ZVJl7yfoRLsImp/os+ePpujP7hGIZhGIYRLoer6DAkJlV0XTLJyCauhWAf3BGLWGhYvONLo01KR8c0FubNtngfgxqxxK23YwzDMAzDiHOq5nWQSqqiC+4py2wa8WHfNOJLoyr6MG7WqJLlDj0v5/3Z7zJ/+0zOueCskvW169bm9cnDmPHtZzz8/AMBbZ2ceDLDJ7zExAVjGT7hpZj6URkabvAhVhpOUVWTlVXKIMQtZZlNIz7sm0Z8abjBh03rNvPXO4ewYtHRWQoO7D/AyJdG88bf3y53/5vuvYGsBcu5vu3NZC1YHnA7N5wrN/gQKw0ncWXadhGpLSIvisg4EbmxTN+bkYq6pSyzacSHfdOILw03+LA1ZxvbNm73Wb//5/2sXLKaA78cKHf/dt3a8PnkLwFK/laGH7HQcIMPsdJwksNo2C0eCHYlZDSenCAfA9eLyMcicry3r3Wkom4py2waVurbNNzpQ0WpW78u3xfuBij56w83nCs3+BArDSfRCFo8EGxi6hmq+mfv8hQRGQzMFpHeDh+XYRiGYRghEi9zPMIl2JWQ40WkZBtV/T9gJDAPOCXQTiIyQESyRCQrPd23iqZbyjKbhpX6Ng13+lBRinYVccpp9QBK/vrDDefKDT7ESsNJ3Ho7Zipw1MPzqjoGeAQIeFNUVdNVNU1V0wYMGODT75ayzKYRH/ZNI7403OBDRVkw/WuuuNYzn+DIX3+44Vy5wYdYaRh+UNWIGnBriNtq9ZrJPq1nr366/tuNmpOzWZ96eqhWr5msf3/+Ve1zdX+tXjNZTzypmU7+aKpu2LBJMzOXafOzWvu1cwQ3aPhbX5U03BQLi/exF++DBw7qzvxCfeHhl/SJ257WnfmF+sv+X/T7wu910ZxMvSy5g16W3EHzt+3Q4t3F+uO+n3RnfqHeePktellyB/10fIbe1v0uvSy5g3Y/r48umb9Ut23arpnzsizecRjvGGhE/PsaSXu0yfUabov1MfprohrZJRkR2aaqodTXVrdkv7MMmsHtgztiEQsNi3d8aVjG1OD2wT3xjoFGTB+CHdT0hrB/zF/ZMqHSH9Qtd2KqiKwM1IWnwq5hGIZhGJWME3M8RKQRMBbP770C6ar6mojUAyYBTYEtwHWqWiQiArwG9AB+Am5R1WXlaQR7OqYB0A0oO/NGgK/D8sYwDMMwDEdwaJrpIeARVV0mIicDS0VkBnALMEtVh4rIE8ATwOPAFcCZ3tYKeMv7NyDBBiEZwEmquqJsh4h8FZ4vhmEYhmE4gROP6KrqDmCHd/kHEVkLpAB9gD96N3sP+ArPIKQPMFY98zwWiUiiiCR57fgl4jkhYRAfzwEZhmEYRuyI6XyLB5r+Jezf2hFbJoV8jCLSFE96jvOBbaqa6F0vQJGqJopIBjBUVRd4+2YBj6tqViC7Mami65JJRjZRMQT74I5YxELD4h1fGgkJocyzj4z9+7fR7JQLHbMPsPn7bGo6eJ4OuizesdCIJZFcCRGRAUDpPBrpquqT3EtETsKTOf0hVd3rGXd4UFUVkYgvNsRkEGIYhmEYhnNEMjHVO+DwzShaChGpiWcAMl5V/+NdvfPIbRYRSQIKvevzgEaldk/1rgtIpVTRBedLJqemJjNz+mRWZs8he8Vs7r/vdr/b/fPV51i3ZgHLls6gxUXnx50fbtEYmT6M/NxsViyfFXAbi4V7NKqqD++88zLbti1j6dIZJeuGDHmEJUu+ZPHiz8nIeJ+kJP8PBvbrdw2rV89l9eq59Ot3Tbk6J9c+mTdHv8LMRVOY8b9PaJF2AXUSazPu47eZnfkp4z5+m9p1Tva775+u78XszE+Znfkpf7q+V1Cfjj/+eL5emMHSrBmsWDGbZ555xGeb4447jvHj32LtmgUsjMN4u+n73CmcqB3jvdUyClirqq+W6voU6O9d7g/8t9T6m8VDa6C4vPkgUEmDkFiUTD506BCPPvYsF1zYgTZtezFw4C0+Gld078iZzZtxzrltGTjwcd7414tx54dbNMaO/ZAre/YN2G+xcI9GVfZh3LjJ9O5981HrXn31HS6+uButWl3BtGmz+OtfH/TZr27dOgwe/BDt2vWmbdveDB78EImJdQLqDHnxMebOWkjn1lfRo/215Hy7mYEP3sbCeZl0vKQ3C+dlMvAh3x/aOom1efDRu7m6az+u6tKXBx+9O+Bg5Qi//PILXbpexx/SupCW1pVuXf9Iq0taHrXNbbfewJ6iYn53blteGzGSF+Is3m75PncSh9K2twFuAjqKyApv6wEMBbqIyAags/c1wDRgE5CDp8TLPcEEyh2EiEhDEXlLRN4QkVNE5G8iskpEPvRegomIWJRMLigoZPmK1QDs2/cj69ZtIKVMRcRevboxbvxHACzOXEadxDo0bHhaXPnhFo35Cxazu2hPwH6LhXs0qrIPCxZkUlTmffrDD/tKlmvVOhF/k/m7dLmcWbPmU1RUzJ49xcyaNZ+uXS/3q3HyySdxyaV/YNL7nwBw8OAhftj7A116dODjiZ96jnfip3Tt0cFn3/YdL2PBV4so3rOXvcU/sOCrRVzeqU1Qv3788ScAatasQc2aNX186BXn8XbL97mTHI6gBUNVF6iqqOoFqnqRt01T1e9VtZOqnqmqnVV1t3d7VdV7VfUMVf19eRNSjxDsSsgYYA2wHZgD/IwnCcl84O0QfPBLrEsmN2mSykUXns/izOVHrU9Jbkju9t+OIy93h88buzzcUl46HkpYWyzco+EGH8ry7LOPkpOziOuvv4rnnhvmezzJDcktdTx5fo7nCKlNUtj9fREv/+s5MuZMYujwIZxw4gnUP7Ue3+3cBcB3O3dR/1TfwncNk05jR6miagX5O2mYFPyHtlq1amQtmU5+3kpmzppH5pKjvwvjPd6lqcrf506iEfyLB4INQhqo6uuqOhRIVNV/qOp2VX0daBKD46swtWqdyIeTRvLwoCFH/Y/GMAwjVIYMeZnmzVszceIUBg68pUK2atSoznkXnMP40ZPp2eEv/PTTzwx88Daf7aKZPeHw4cOkXdyVps3SuDitBeedd3b0jMcQ+z4PjBNXQmJBsEFI6f6xZfqqB9pJRAaISJaIZKWn+068jVXJ5Bo1ajB50kgmTPiEKVM+9+nPyy8gtdFvx5GSmkRemeMoD7eUl46HEtYWC/douMGHQEyc+AlXXXWF7/HkF5Ba6nhS/BzPEXbk76Qgfycrlq4C4PNPZ3DeBeew67vdnNqgPgCnNqjP97t2++xbsKOQpFL/O2+Y3ICCHYU+2wWiuHgvX81dSNeufzz6+OM83uCO73MnceuVkP96nw9GVZ86slJEmgPrA+2kqumqmqaqaQMGDPDpj1XJ5JHpw1i7Lofhr/l/AikjYzo39fXMYm91SUv2Fu+loCD0D7RbykvHQwlri4V7NNzgQ2nOOKNpyXLPnl1Zv36jzzYzZsylc+d2JCbWITGxDp07t2PGjLl+7e0q/J4deTs5vbnnYvJl7VuRs34TMz//ij9f39tzvNf3Zsa0OT77zpv9Ne06XErtOidTu87JtOtwKfNml19Bo379etSpUxuAhIQEOndq7+NDRpzHG9zxfe4kVfVKSLl5QlT1mQDrc0Tks0hFf/31Vx586CmmffYB1atVY8x7k1iz5lv+NmQQWUuzyciYwbujJ/LemBGsW7OAoqI93Ngv6CTbo2hz2cXc1O8aVq5aQ9YSzxvp6aeH0qiRJ0FN+shxTPt8Ft27d2T92oX89PPP3HHHw3Hnh1s03h/3Bpe3v5T69euxZVMWzz73CjVr1gQsFm7TqMo+jB37Ou3aXUr9+nXJyVnM88+/SrduHTjrrDM4fPgw27blcf/9TwLQsuUF3HlnXwYOfJyiomJefHEECxdOBeCFF16jqKg4oM6QJ4byz3de5LiaNdm2NZdH73uGatWq8a93X+a6vleRl7uD+257FIDfX3QufW+5liceepbiPXt5/ZV0/jvzAwBGvPIOxXv2lutTUlID3h01nOrVqyHVqvHRR1OZNm0mQ4YMYmmpczVmzAjWes9V3ziLt1u+z53ksPPZzx0h4rTtIrJNVUNJMahuyX5nGTSD2wd3xCIWGhbv+NKwjKnlYxlTw9aIadr2m5r8Kewf83Fb/xPTY/RHuVdCRGRloC48FXYNwzAMw6hkquZ1kOBp2xsA3YCyM28EKP9GpGEYhmEYMSGStO3xQLBBSAZwkqquKNshIl85ckSGYRiGYYRFvDztEi4RzwkJg6p5ZgzDMAwjcmI63+IvTa4K+7d20tYp8T0nJGoi7phkZBMVQ7AP7ohFLDQs3seWRizifcIJzuWQ/PnnrYA7YhErjVji1tsxhmEYhmHEOVX1dkylVNGFqlvq2zQi0xiZPoz83GxWLJ8VcJuqUIbbNOLDvls0nPpcvP32y2zdupSsrN+SbQ0e/BAbNy5m0aJpLFo0jW7dfAvkgacYX3b2bFavnsugQQND0nNDLGKl4RRVNVlZ2IMQEQm9LGEg0Spc6ts0ItMYO/ZDruzZN2B/VSjDbRrxYd9NGk59LsaNm0yfPv191r/++ihat+5B69Y9+PJL34ys1apVY/jwv9OnT39atOjMtdf25pxzzvTZruw+bohFLDScRFXDbvFAuYMQEalXpp0CZIpIXRHxLfEYIlW51LdpRKYxf8FidpcpkV6aqlCG2zTiw76bNJz6XCxcmMnu3YHtBuLiiy9i48YtbNmynYMHDzJ58lR69uxS7j5uiUUsNJzkMBp2iweCXQnZBSwt1bKAFGCZdzki3FLq2zSiV8K6KpThNo34Ke3uFo1gVPRzUZa7776ZzMwvePvtl0lMrO3Tn5zckNzcHb/p5e0gJaV8PbfEIh7iXRHcejvmUTyF6nqrajNVbQbkepdPd/7wDMMwjGgwcuT7nHtue1q1uoKCgkKGDn26sg/JiCKurKKrqsOAO4BnRORVETmZEPJ+iMgAEckSkaz0dN+Kh24p9W0a0SthXRXKcJtG/JR2d4tGMCr6uShNYeEuDh8+jKry7rsTSEvzrWWTn19AamrSb3opSeTlla/nlljEQ7wrgltvx6Cquap6LfAVMAM4MYR90lU1TVXTBgwY4NPvllLfphE9qkIZbtOID/tu0ghGRT8XpSk9l6RPn26sWbPeZ5usrGyaN29GkyYen6+9theffTajXLtuiUU8xLsiVNWJqeEe8AnA+d7lW0PcT6vXTPZpPXv10/XfbtScnM361NNDtXrNZP37869qn6v7a/WayXriSc108kdTdcOGTZqZuUybn9Xar50juEHD3/qqpFHeeZow8RPNzy/QAwcO6Pbt+XrHnQ/rwHse14H3PF6yzRtvjtacnM26ctUavaRVd4t3nGu4KRaVFe9ofS6OaCQkNNaEhMY6adIUzc/fqQcOHNDc3Hy9665Hdfz4j3XVqrW6cuUanTp1ujZtmqYJCY21WbM0/fzz2SX79unTX7/9dqNu3LhFn3nmpZL1bopFjDQiGhhE2rqmdtdwW6yP0V+LOG27iGxT1VBqX6tbst+5IaOiG86TWzQs3seWhmVMDY6b4k2M07Z3bdQ97B/z6du/iO+07SKyMlAXngq7hmEYhmFUMvEyxyNcgqVtbwB0A8rOvBHga0eOyDAMwzCMY4Jgg5AM4CRVXVG2Q0S+cuSIDMMwDMMIi0inVlQ2Ec8JCYOqeWYMwzAMI3JiOt+iQ2qXsH9r5+TOiO85IVETccckI1dMXHPDeXKLhsX72NJwS7x7Ne7pmMbUbRmAO+Ida+Il+Vi4xGQQYhiGYRiGcxyuordjwq6iGy3cUpbZNOLDvmnEl4YbfDAN//xrxhs+666682qmbsugdl1PPZrzW/+eiasn8drnI3jt8xFc/+D1fm01aNSAV/47jHfmpfPYG4/FzIfK1HAKjaDFA5UyCHFLWWbTiA/7phFfGm7wwTRC16ifVJ8W7VtQmHt0Jtc1S77hwSse4MErHmDiaxP97nvLk7fw33//l7vaD2Bf8Y+V5kOsNJzEtWnbncAtZZlNIz7sm0Z8abjBB9MIXeOOIXcy+oXRET2dccFlF7Bw2gIAZn00q9J8iJWGkzgxCBGRd0WkUERWl1pXT0RmiMgG79+63vUiIiNEJEdEVopIy1COu9xBiIh0L7VcR0RGeY1/ICIRJytzS1lm07DS7qbhTh9MIzSNVl1a8X3B92xZu9mn7+yW5zDii9f523t/o/FZvsm1a9etzb69P3L4V09R+e937KoUH2Kp4SSRpEwPgTFA9zLrngBmqeqZwCzva4ArgDO9bQDwVigCwa6EvFBqeRiwA+gFLAHeCUXAMAzDcB/HJxzPtfddx/hh7/v0bVydw+2X3sYD3e9n6pgMBo98qhKO8NjCiSshqjoP2F1mdR/gPe/ye8BVpdaP9dbNWQQkikgSQQjndkyaqj6lqltV9Z9A00AbisgAEckSkaz09HSffreUZTYNK+1uGu70wTSCazRs0pAGjRow4ovX+ffCUdRPqs/wacNJPDWRn/f9zP6f9gOwdE56Mu8XAAAV60lEQVQW1WtUL5m0eoS9RXs5qXYtqlX3/AydklQ/5j7EWsNJNIJ/pX+rvc237L0vDVR1h3e5gN9KuKQA20ttl+tdVy7BBiGnicjDIvIIUFtESic2Cbivqqarapqqpg0Y4OuTW8oym0Z82DeN+NJwgw+mEVxj6/qt3NSyH3e0uZ072tzOrh27eKjHQ+z5bg+JpyaWbHfmhWdRrZqwt2ivj42V/1tFmx6eeRWdrukUcx9ireEkEVaxLfmt9jbfqwbla1b8QZsg94uGlGmnetc3xHPZJRQn3VKWuVJKfVclDTfFwuJt8a5KsYhlvA8eOKjf5X+nrw0arj0bXVnSCrYV6I0X3KA9G12pbz31lm5dv0U3fbNJ1y5dq4OueqRkuyWzlujNaTdpz0ZX6u1tbtP1y9dr3uY8nZ8x31XxDvH3MWqtRcM2Gm4LxS6eux6rS71eDyR5l5OA9d7ld4Ab/G1XXos4bbuI3Kqqo0MZ57gl+51lVAxuH9wRi1hoWLyPLQ23xNsypoasEdOU6C0atgn7x3x5wcKgxygiTYEMVT3f+/pl4HtVHSoiTwD1VPUxEbkSuA/oAbQCRqjqJcHsV+QR3WcrsK9hGIZhGFHCoUd0JwD/A84WkVwRuR0YCnQRkQ1AZ+9rgGnAJiAHGAncE8pxl5u2XURWBurit8kohmEYhmFUIk7UjlHVGwJ0+UzgUc9tFd80s0EIVjumAdANKDv9V4CvwxUzDMMwDCP6VNXaMeXOCRGRUcBoVV3gp+8DVb0xBI2qeWYMwzAMI3JiOifk/Aatw/6tXb1zUUyP0R/lXglR1dvL6QtlAOIRccckI5u4FoJ9cEcsYqFh8T62NNwS79q1TndMY++PmwDo2qhsks7oMX37FwAcn9DIMY1f9m8PvlGUceJ2TCwIdjvGMAzDMIw4p6rejqmUAnbgnrLMphEf9k0jvjTc4INpBCYlJYmMaePJzPqSxUu+YOA9txzVf98Dt7P3x03UC1BX5ca+f2J59myWZ8/mxr5/8ulPn/l2yXL/QTfz9vS3eOuLN3hx/P9Rr0E9ABqdkcrwKf8kI+dTrrnrzwGPtWGjBoz4dDij57/LX998sly/7rv3NpYtncnyZTO5/z7/NwJeHfYsa76ZT9aS6Vx00fnl2oslkWRMjQcqZRDilrLMphEf9k0jvjTc4INplK9x6NdDDP7rC1yS1o1OHf7MnQNu4uxzmgOeAUqnTu3Yti3P775169bh8ScfoOMfr6bD5Vfx+JMPkJhY2++2AJPf/oi7uw5kYPd7WTwzk34P9gXghz0/8OaQt/go/eNyj/X2J2/nP//+hFvb3ca+PfsCbnfuuWdz22030qZtT9Iu7kaPHp044/SmR23TvVsHmjdvxrnnteOeex/n9REv+DdWCRxWDbvFA2EPQkTklIqKuqUss2nEh33TiC8NN/hgGuVr7Cz4juwV3wCwb9+PrF+fU1Jx9sV/PMXTTw0NWKW1U+f2zJm9gKKiYvbs2cuc2Qvo3OXygFo/7fupZDnhxISS/8Hv+b6Yb7O/5deDv5Z7rBe1uZB5n80HYMZHMwNud845zclcspyff97Pr7/+yrz5i7nqqqPnpvTq1ZX3x3sGPZmZy0lMrE3DhqeVqx8rXHklRESGikh973KaiGwCFovIVhEJ/K4JglvKMpuGlXY3DXf6YBqhazRunMIFF55H1pIV9LiyMzt2FLB61bqA2yclNyAvd0fJ6/y8ApKSy087dctj/Rm/eBwdr+7A2FfGhXRcALXr1mbf3h85/OthAHbt+C7gtmu+WU/bNpdQr14iJ5yQQPduHUgtVdAOIDm5IbmlzmWen3NZWbj1SsiVqrrLu/wy8BdVbQ50AYY5emSGYRhGXFOr1omM++BNnnjs7xw6dIhBj97D//19eNR1xrz0Hn1b3cTsT+bQ+5ZeUbcPsG59Dq8Me5PPMsYzder7rFy5hl9/Lf8qSzzhyishQA0ROfIEzQmqugRAVb8Fjg+0U+nywOnpvkX53FKW2TSstLtpuNMH0wiuUaNGDd7/4E0+nPQpUz/9kmanN6FJ01QWLvqMVWvmkZLSkPkLp3Jag/pH7bcjfycpqUklr5NTGrIjf2dIvsz6ZDbteoR+O2pv0V5Oql2LatU9P3X1k04td/sxYyZx6WVX0rnzNRTtKWbDhs1H9efnFxx1dSTFz7msLFQPh93igWCDkDeBaSLSEfhCRF4TkctF5FlgRaCdtFR54AEDBvj0u6Uss2nEh33TiC8NN/hgGsE13nhrKOvXb+SN10cBntsZZzS9hN+f257fn9uevLwC2rXpReHOXUftN2vmPDp2akdiYm0SE2vTsVM7Zs2cF1AnuelvP/qXdb2U7Tnh5eDI/nol7a9sB0CXazqXu+2pp3qmPDZqlMxVfbozcdKUo/ozMmbQr6/nSZxLLmlBcfEPFBQUhnU8TuFE7ZiYEEIZ3z8Ck4DlwCo8RWoGADVCLDHslrLMVboMdyxLfbshFhZvi3dVikUs433yic20S6drVVV11aq1mp39jWZnf6N/vvpWPfnEZiVty5bt2qRRSz35xGbavk1vHTN6YknfwLsf0405m3Vjzma9+65HS9Yf4eCBg1qYX6jDHnlV5302Xzev26wb12zS/03/n16fdqN2Se2m17W4XgvzC3Xf3n36w54ftDC/UPucc7V2Se2mi2ct1r/84QbtktpNb7qsv65dvk5zN+fp3KnzSjSOOz7Vp81fsFjXrFmv2dnfaLfuf9Hjjk/Ve+99Qu+994mSbd56a4xu3LhFV61aq60v7eHXjpdQfh+j1hrVPV/DbbE+Rn+t3LTt5SEit6rq6FDGOW7IdhgLDbdkVDSN0DQs3seWhlvibRlTg+PNmBrTlOip9c4P+8c8d/fqSk/bXpE8Ic9G7SgMwzAMw4iYSK5CxAPlpm0XkZWBuvBU2DUMwzAMo5KJl0duwyVY7ZgGQDeg7DRpAb525IgMwzAMwwiLeHnkNlzKnRMiIqOA0aq6wE/fBxpaJd2qeWYMwzAMI3JiOt+iQZ1zwv6t3Vm8rtLnhEQ8MTUMbGJqiBpumbhmGqFpWLyPLQ2Ld+gaNR3UOOjVOOGEJo5p/PzzVojxIOTUOmeH/WP+XfH6Sh+EBLsdYxiGYRhGnBMvE03DpVKq6ELVLF9dGRoj04eRn5vNiuWzAm7zz1efY92aBSxbOoMWEZaWdtKP1NRkZk6fzMrsOWSvmB2wRHZF/XBDvN2i4QYfTCN+7B+hWrVqLMn8kimfvOdXY/z4t1i7ZgELQ9R4++2X2bp1KVlZvyVvGzz4ITZuXMyiRdNYtGga3bp18Ltvly6Xk509m9Wr5zJo0MCI/DEqaRBSVctXV4bG2LEfcmXPvgH7r+jekTObN+Occ9sycODjvPGvF8OyHws/Dh06xKOPPcsFF3agTdteDBx4i4/9ivrhlni7QcMNPphGfMX7CA/cfwdr123w23fbrTewp6iY353bltdGjOSFEDTGjZtMnz79fda//vooWrfuQevWPfjyyzk+/dWqVWP48L/Tp09/WrTozLXX9uacc8702S6WuLWAnSNU1fLVlaExf8FidhftCdjfq1c3xo3/CIDFmcuok1gn7NLSTvtRUFDI8hWrAU/Z73XrNpBSpvJkRf1wS7zdoOEGH0wjvuINnjotV1zRiXffneC3v1cEGgsXZrJ7d+Dv10BcfPFFbNy4hS1btnPw4EEmT55Kz55dwrYTTapqnpByByEiskxEnhKRM6Ip6oby1bHSCEZKckNyt5cqLZ27w+cHPhix9KNJk1QuuvB8FmcuP2p9Rf1wS7zdoOEGH0wjvuINMGzYszz55PMcPuy/8Fo0v2vvvvtmMjO/4O23XyYxsbavVnJDcnN3lLzOy9tBSkp437vRpqrWjgl2JaQukAjMEZFMEfl/IpIcZB/D8EutWify4aSRPDxoCD/8sK+yD8cwjCpCjx6d+a5wF8uWr3Jca+TI9zn33Pa0anUFBQWFDB36tOOa0cCVV0KAIlUdpKqNgUeAM4FlIjJHRHzL43oRkQEikiUiWenp6T79Vbl8daw1gpGXX0Bqo1KlpVOTyAuztHQs/KhRowaTJ41kwoRPmDLl86j74ZZ4u0HDDT6YRnzF+7LL0ujZsysbvl3E+PffpEOHNrw3ZkRUNY5QWLiLw4cPo6q8++4E0tIu9NkmP7+A1NSkktcpKUnk5YX3vRttXD8nRFXnq+o9QArwD+DScrZNV9U0VU0bMMB3rFKVy1fHWiMYGRnTuanvNQC0uqQle4v3hl1aOhZ+jEwfxtp1OQx/zXdQGg0/3BJvN2i4wQfTiK94P/XUUJqdnsaZZ7Wmb797mDNnIf1veeCobTKi9F1bei5anz7dWLNmvc82WVnZNG/ejCZNPD5fe20vPvtsRkR60UIj+BcXBLlUMzEKpXpdUYY7Fhr+1k+Y+Inm5xfogQMHdPv2fL3jzod14D2P68B7Hi/Z5o03R2tOzmZduWqNXtKqe8By3oE0nC7t3v7yPqqqmr3yG12+YrUuX7Fae/bqF5Efbo93VdJwUyws3vEV7xo1kwO2jp3+rBkZM7SGV+Oqq/trjZrJWquMxplntfa7/xESEhrrpElTND9/px44cEBzc/P1rrse1fHjP9ZVq9bqypVrdOrU6dq0aZomJDTWZs3S9PPPZ2tCQmNNSGisffr012+/3agbN27RZ555qWR9QkLjIxJRL3tfXiutH2qL9TH6axFnTBWRW1V1dCjjHLdk8bOMisHtgztiEQsNi/expWHxDl3DMqaGT0JC47B/zPfv31bpGVMr8ojus1E7CsMwDMMwIsap2zEi0l1E1otIjog8Ee3jLjdtu4isDNSFp8KuYRiGYRiVTKR3NcpDRKoDbwBdgFxgiYh8qqproqURrHZMA6AbUHaKsQBfR+sgDMMwDMOIHCcGIcAlQI6qbgIQkYlAHyBmg5AM4CRVXVG2Q0S+ClXkyH0+J3GDhht8MI34sW8a8aXhBh9ipXEwBhreeRuuwaFnXVKA7aVe5wKtoilQ7pwQVb1dVRcE6LsxRA0Jt4nIXZHsFy/2TSO+NNzgg2nEj33TiC+NOPYhphw6kCfhttI5vbwtYP4vp6i0KrpBcPpExOJEm0b8aLjBB9OIH/umEV8abvChUtBSOb28rWwipzygUanXqd51USNeByGGYRiGYVQuS4AzRaSZiBwHXA98Gk2BYHNCDMMwDMM4BlHVQyJyH/AlUB14V1W/iaZGvA5C/Of2rjr2TSO+NNzgg2nEj33TiC8NN/gQt6jqNGCaU/YjzphqGIZhGIZREWxOiGEYhmEYlUJcDUKcTg8rIu+KSKGIrI627VIajURkjoisEZFvRORBBzQSRCRTRLK9Gs9GW8OrU11ElotIhkP2t4jIKhFZISJZDmkkishHIrJORNaKSMDqzxHaP9t7/EfaXhF5KJoaXp3/5431ahGZICIJUbb/oNf2N9E6fn+fNxGpJyIzRGSD929dBzSu9fpxWETSKmK/HI2Xve+plSLyiYgkOqDxd6/9FSIyXUSSo61Rqu8REVERqR9N+yLyNxHJK/X56BGp/UAa3vX3e+PxjYi8FG0NEZlUyoctIuKTO8uIkMquoHek4Zn0shE4HTgOyAbOjbJGe6AlsNpBP5KAlt7lk4FvHfBD8CSRA6gJLAZaO+DLw8AHQIZD52oLUN/h99V7wB3e5eOARAe1qgMFQJMo200BNgMneF9/CNwSRfvnA6uBE/HME5sJNI+CXZ/PG/AS8IR3+QngHw5o/A44G/gKSHPIj65ADe/yPxzyo3ap5QeAt6Ot4V3fCM/Ew60V+TwG8OFvwKAovlf9aXTwvmeP974+zYnzVKp/GPBMtHw61ls8XQkpSQ+rqgeAI+lho4aqzgN2R9OmH40dqrrMu/wDsBbPj0g0NVRV93lf1vS2qE7uEZFU4Erg39G0G0tEpA6eL5RRAKp6QFX3OCjZCdioqlsdsF0DOEFEauAZLORH0fbvgMWq+pOqHgLmAn+qqNEAn7c+eAaGeP9eFW0NVV2rqusrYjcEjenecwWwCE/+hGhr7C31shYV/IyX8/33T+AxB+1HjQAaA4GhqvqLd5tCBzQAT9Yy4DpgQkU0jN+Ip0GIv/Swzta+dhgRaQq0wHOlItq2q3svCRYCM1Q12hrD8XwxHY6y3dIoMF1EljqUqa8Z8B0w2ntb6d8iUssBnSNcjwNfTqqaB7wCbAN2AMWqOj2KEquBdiJyioicCPTg6ARF0aSBqu7wLhfgjkKYtwGfO2FYRP5PRLYDfYFnHLDfB8hT1exo2y7Ffd7bSu9W9PZbAM7C8/5dLCJzReRiBzSO0A7YqaobHNQ4poinQYirEJGTgI+Bh8r8jyYqqOqvqnoRnv+BXSIi50fLtoj0BApVdWm0bAagraq2BK4A7hWR9lG2XwPPZdW3VLUF8COeWwBRRzyJfHoDkx2wXRfPFYRmQDJQS0T6Rcu+qq7Fc0thOvAFsAL4NVr2y9FVHCt5ERtEZDBwCBjvhH1VHayqjbz274umbe+A8684MLgpxVvAGcBFeAbQwxzQqAHUA1oDjwIfeq9YOMEN2FWQqBJPgxDH08PGChGpiWcAMl5V/+Oklvf2whygexTNtgF6i8gWPLfFOorI+1G0D5T8D//I5dNP8NySiya5QG6pq0Qf4RmUOMEVwDJV3emA7c7AZlX9TlUPAv8BLoumgKqOUtU/qGp7PFWzv42m/VLsFJEkAO/fCl06r0xE5BagJ9DXO6BykvHAn6Ns8ww8A9ts72c9FVgmIg2jJaCqO73/YToMjCT6n3HwfM7/471NnYnn6m3EE2wD4b0V+idgUrRtH8vE0yDE8fSwscA7Ah8FrFXVVx3SOPXIbHwROQHoAqyLln1VfVJVU1W1KZ44zFbVqP3PG0BEaonIyUeW8Uz0i+pTS6paAGwXkbO9qzoRxRLUZXDyf0jbgNYicqL3/dUJz1yjqCEip3n/NsbzRftBNO2X4lOgv3e5P/Bfh3QcRUS647ld2VtVf3JI48xSL/sQxc84gKquUtXTVLWp97Oei2dSfUG0NI4MOL1cTZQ/416m4JmcioichWcC+i4HdDoD61Q11wHbxy6VPTO2dMNzL/pbPE/JDHbA/gQ8lwQP4vnA3e6ARls8l5hX4rmsvQLoEWWNC4DlXo3VODhTG/gjDjwdg+cpqGxv+8aJeHt1LgKyvOdqClDXAY1awPdAHQfj8CyeH6HVwDi8TwJE0f58PAO0bKBTlGz6fN6AU4BZwAY8TzTUc0Djau/yL8BO4EsHNHLwzGE78hmv6JMr/jQ+9sZ7JTAVSIm2Rpn+LVTs6Rh/PowDVnl9+BRIcuA8HQe87z1Xy4COTpwnYAxwdzQ+G9Z+a5Yx1TAMwzCMSiGebscYhmEYhnEMYYMQwzAMwzAqBRuEGIZhGIZRKdggxDAMwzCMSsEGIYZhGIZhVAo2CDEMwzAMo1KwQYhhGIZhGJWCDUIMwzAMw6gU/j/OsRqT3U/lqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf64055-0028-4ab5-b34f-9bf6e7e399f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4abe317e-6b21-49e6-b0f7-22cd4a7fc9e2",
   "metadata": {},
   "source": [
    "데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8298cf4c-f313-45cd-8549-7ecae3f11cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f83d0ba-da1a-4058-bbf0-c4b0b0ad828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "test_dir = 'input/data/eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f74389-3912-4679-85c2-ce268e266dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    ToTensor(),\n",
    "#     Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "\n",
    "])\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "# model = MyModel(num_classes=18).to(device)\n",
    "PATH = '/input'\n",
    "model = torch.load(PATH)\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c7477-c27f-4857-9b8b-c87c1f02647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('input/data/eval/submission.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ec98e2-26fc-4d3c-add1-a8cb7f92a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = dict()\n",
    "\n",
    "for cla in test_data['ans']:\n",
    "    if cla in classes:\n",
    "        classes[cla] += 1\n",
    "    else:\n",
    "        classes[cla] = 1\n",
    "        \n",
    "classes = sorted(classes.items())\n",
    "print(classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
